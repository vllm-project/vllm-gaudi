Calling add_step_closure function does not have any effect. It's lazy mode only functionality. (warning logged once)
Calling mark_step function does not have any effect. It's lazy mode only functionality. (warning logged once)
Calling iter_mark_step function does not have any effect. It's lazy mode only functionality. (warning logged once)
INFO 02-05 00:23:19 [plugins/__init__.py:43] Available plugins for group vllm.platform_plugins:
INFO 02-05 00:23:19 [plugins/__init__.py:45] - hpu -> vllm_gaudi:register
INFO 02-05 00:23:19 [plugins/__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
DEBUG 02-05 00:23:19 [platforms/__init__.py:36] Checking if TPU platform is available.
DEBUG 02-05 00:23:19 [platforms/__init__.py:55] TPU platform is not available because: No module named 'libtpu'
DEBUG 02-05 00:23:19 [platforms/__init__.py:61] Checking if CUDA platform is available.
DEBUG 02-05 00:23:19 [platforms/__init__.py:88] Exception happens when checking CUDA platform: NVML Shared Library Not Found
DEBUG 02-05 00:23:19 [platforms/__init__.py:105] CUDA platform is not available because: NVML Shared Library Not Found
DEBUG 02-05 00:23:19 [platforms/__init__.py:112] Checking if ROCm platform is available.
DEBUG 02-05 00:23:19 [platforms/__init__.py:126] ROCm platform is not available because: No module named 'amdsmi'
DEBUG 02-05 00:23:19 [platforms/__init__.py:133] Checking if XPU platform is available.
DEBUG 02-05 00:23:19 [platforms/__init__.py:153] XPU platform is not available because: No module named 'intel_extension_for_pytorch'
DEBUG 02-05 00:23:19 [platforms/__init__.py:160] Checking if CPU platform is available.
INFO 02-05 00:23:19 [platforms/__init__.py:217] Platform plugin hpu is activated
INFO 02-05 00:23:20 [triton_utils/importing.py:44] Triton is installed but 0 active driver(s) found (expected 1). Disabling Triton to prevent runtime errors.
INFO 02-05 00:23:20 [triton_utils/importing.py:68] Triton not installed or not compatible; certain GPU-related functions will not be available.
DEBUG 02-05 00:23:22 [entrypoints/utils.py:183] Setting VLLM_WORKER_MULTIPROC_METHOD to 'spawn'
DEBUG 02-05 00:23:22 [plugins/__init__.py:43] Available plugins for group vllm.general_plugins:
DEBUG 02-05 00:23:22 [plugins/__init__.py:45] - 01.hpu_custom_ops -> vllm_gaudi:register_ops
DEBUG 02-05 00:23:22 [plugins/__init__.py:45] - 02.hpu_custom_models -> vllm_gaudi:register_models
DEBUG 02-05 00:23:22 [plugins/__init__.py:45] - lora_filesystem_resolver -> vllm.plugins.lora_resolvers.filesystem_resolver:register_filesystem_resolver
DEBUG 02-05 00:23:22 [plugins/__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
WARNING 02-05 00:23:22 [platforms/interface.py:222] Failed to import from vllm._C: ModuleNotFoundError("No module named 'vllm._C'")
WARNING 02-05 00:23:22 [distributed/.../v1/nixl_connector.py:99] NIXL is not available
WARNING 02-05 00:23:22 [distributed/.../v1/nixl_connector.py:111] NIXL agent config is not available
DEBUG 02-05 00:23:22 [utils/flashinfer.py:55] FlashInfer unavailable since package was not found
WARNING 02-05 00:23:23 [platform.py:163] Pin memory is not supported on HPU.
WARNING 02-05 00:23:23 [model_executor/models/registry.py:801] Model architecture Gemma3ForConditionalGeneration is already registered, and will be overwritten by the new model class vllm_gaudi.models.gemma3_mm:HpuGemma3ForConditionalGeneration.
WARNING 02-05 00:23:23 [model_executor/models/registry.py:801] Model architecture Qwen2_5_VLForConditionalGeneration is already registered, and will be overwritten by the new model class vllm_gaudi.models.qwen2_5_vl:HpuQwen2_5_VLForConditionalGeneration.
WARNING 02-05 00:23:23 [model_executor/models/registry.py:801] Model architecture Qwen3VLForConditionalGeneration is already registered, and will be overwritten by the new model class vllm_gaudi.models.qwen3_vl:HpuQwen3_VLForConditionalGeneration.
DEBUG 02-05 00:23:23 [compilation/decorators.py:202] Inferred dynamic dimensions for forward method of <class 'vllm.model_executor.models.qwen3_moe.Qwen3MoeModel'>: ['input_ids', 'positions', 'intermediate_tensors', 'inputs_embeds']
WARNING 02-05 00:23:23 [model_executor/models/registry.py:801] Model architecture Qwen3VLMoeForConditionalGeneration is already registered, and will be overwritten by the new model class vllm_gaudi.models.qwen3_vl_moe:HpuQwen3_VLMoeForConditionalGeneration.
WARNING 02-05 00:23:23 [utils/argparse_utils.py:342] Found duplicate keys --trust-remote-code
[0;36m(APIServer pid=399008)[0;0m INFO 02-05 00:23:23 [entrypoints/openai/api_server.py:1272] vLLM API server version 0.14.0
[0;36m(APIServer pid=399008)[0;0m INFO 02-05 00:23:23 [entrypoints/utils.py:263] non-default args: {'host': 'localhost', 'port': 12346, 'model': '/root/.cache/huggingface/hub/models--Qwen--Qwen3-VL-32B-Instruct-FP8/snapshots/4bf2c2f39c37c0fede78bede4056e1f18cdf8109/', 'trust_remote_code': True, 'max_model_len': 32768, 'gpu_memory_utilization': 0.75, 'limit_mm_per_prompt': {'image': {'count': 20, 'width': 864, 'height': 480}}, 'mm_processor_kwargs': {'size': {'shortest_edge': 65536, 'longest_edge': 1048576}}, 'max_num_batched_tokens': 32768}
[0;36m(APIServer pid=399008)[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
[0;36m(APIServer pid=399008)[0;0m loading configuration file /root/.cache/huggingface/hub/models--Qwen--Qwen3-VL-32B-Instruct-FP8/snapshots/4bf2c2f39c37c0fede78bede4056e1f18cdf8109/config.json
[0;36m(APIServer pid=399008)[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
[0;36m(APIServer pid=399008)[0;0m loading configuration file /root/.cache/huggingface/hub/models--Qwen--Qwen3-VL-32B-Instruct-FP8/snapshots/4bf2c2f39c37c0fede78bede4056e1f18cdf8109/config.json
[0;36m(APIServer pid=399008)[0;0m loading configuration file /root/.cache/huggingface/hub/models--Qwen--Qwen3-VL-32B-Instruct-FP8/snapshots/4bf2c2f39c37c0fede78bede4056e1f18cdf8109/config.json
[0;36m(APIServer pid=399008)[0;0m Model config Qwen3VLConfig {
[0;36m(APIServer pid=399008)[0;0m   "architectures": [
[0;36m(APIServer pid=399008)[0;0m     "Qwen3VLForConditionalGeneration"
[0;36m(APIServer pid=399008)[0;0m   ],
[0;36m(APIServer pid=399008)[0;0m   "image_token_id": 151655,
[0;36m(APIServer pid=399008)[0;0m   "model_type": "qwen3_vl",
[0;36m(APIServer pid=399008)[0;0m   "quantization_config": {
[0;36m(APIServer pid=399008)[0;0m     "activation_scheme": "dynamic",
[0;36m(APIServer pid=399008)[0;0m     "fmt": "e4m3",
[0;36m(APIServer pid=399008)[0;0m     "ignored_layers": [
[0;36m(APIServer pid=399008)[0;0m       "lm_head",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.merger.linear_fc1",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.merger.linear_fc2",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.merger.norm",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.patch_embed.proj",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.pos_embed",
[0;36m(APIServer pid=399008)[0;0m       "visual.merger.linear_fc1",
[0;36m(APIServer pid=399008)[0;0m       "visual.merger.linear_fc2",
[0;36m(APIServer pid=399008)[0;0m       "visual.merger.norm",
[0;36m(APIServer pid=399008)[0;0m       "visual.patch_embed.proj",
[0;36m(APIServer pid=399008)[0;0m       "visual.pos_embed",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.blocks.0.attn.proj",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.blocks.0.attn.qkv",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.blocks.0.mlp.linear_fc1",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.blocks.0.mlp.linear_fc2",
[0;36m(APIServer pid=399008)[0;0m       "visual.blocks.0.attn.proj",
[0;36m(APIServer pid=399008)[0;0m       "visual.blocks.0.attn.qkv_proj",
[0;36m(APIServer pid=399008)[0;0m       "visual.blocks.0.mlp.linear_fc1",
[0;36m(APIServer pid=399008)[0;0m       "visual.blocks.0.mlp.linear_fc2",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.blocks.1.attn.proj",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.blocks.1.attn.qkv",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.blocks.1.mlp.linear_fc1",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.blocks.1.mlp.linear_fc2",
[0;36m(APIServer pid=399008)[0;0m       "visual.blocks.1.attn.proj",
[0;36m(APIServer pid=399008)[0;0m       "visual.blocks.1.attn.qkv_proj",
[0;36m(APIServer pid=399008)[0;0m       "visual.blocks.1.mlp.linear_fc1",
[0;36m(APIServer pid=399008)[0;0m       "visual.blocks.1.mlp.linear_fc2",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.blocks.2.attn.proj",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.blocks.2.attn.qkv",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.blocks.2.mlp.linear_fc1",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.blocks.2.mlp.linear_fc2",
[0;36m(APIServer pid=399008)[0;0m       "visual.blocks.2.attn.proj",
[0;36m(APIServer pid=399008)[0;0m       "visual.blocks.2.attn.qkv_proj",
[0;36m(APIServer pid=399008)[0;0m       "visual.blocks.2.mlp.linear_fc1",
[0;36m(APIServer pid=399008)[0;0m       "visual.blocks.2.mlp.linear_fc2",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.blocks.3.attn.proj",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.blocks.3.attn.qkv",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.blocks.3.mlp.linear_fc1",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.blocks.3.mlp.linear_fc2",
[0;36m(APIServer pid=399008)[0;0m       "visual.blocks.3.attn.proj",
[0;36m(APIServer pid=399008)[0;0m       "visual.blocks.3.attn.qkv_proj",
[0;36m(APIServer pid=399008)[0;0m       "visual.blocks.3.mlp.linear_fc1",
[0;36m(APIServer pid=399008)[0;0m       "visual.blocks.3.mlp.linear_fc2",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.blocks.4.attn.proj",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.blocks.4.attn.qkv",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.blocks.4.mlp.linear_fc1",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.blocks.4.mlp.linear_fc2",
[0;36m(APIServer pid=399008)[0;0m       "visual.blocks.4.attn.proj",
[0;36m(APIServer pid=399008)[0;0m       "visual.blocks.4.attn.qkv_proj",
[0;36m(APIServer pid=399008)[0;0m       "visual.blocks.4.mlp.linear_fc1",
[0;36m(APIServer pid=399008)[0;0m       "visual.blocks.4.mlp.linear_fc2",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.blocks.5.attn.proj",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.blocks.5.attn.qkv",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.blocks.5.mlp.linear_fc1",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.blocks.5.mlp.linear_fc2",
[0;36m(APIServer pid=399008)[0;0m       "visual.blocks.5.attn.proj",
[0;36m(APIServer pid=399008)[0;0m       "visual.blocks.5.attn.qkv_proj",
[0;36m(APIServer pid=399008)[0;0m       "visual.blocks.5.mlp.linear_fc1",
[0;36m(APIServer pid=399008)[0;0m       "visual.blocks.5.mlp.linear_fc2",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.blocks.6.attn.proj",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.blocks.6.attn.qkv",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.blocks.6.mlp.linear_fc1",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.blocks.6.mlp.linear_fc2",
[0;36m(APIServer pid=399008)[0;0m       "visual.blocks.6.attn.proj",
[0;36m(APIServer pid=399008)[0;0m       "visual.blocks.6.attn.qkv_proj",
[0;36m(APIServer pid=399008)[0;0m       "visual.blocks.6.mlp.linear_fc1",
[0;36m(APIServer pid=399008)[0;0m       "visual.blocks.6.mlp.linear_fc2",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.blocks.7.attn.proj",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.blocks.7.attn.qkv",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.blocks.7.mlp.linear_fc1",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.blocks.7.mlp.linear_fc2",
[0;36m(APIServer pid=399008)[0;0m       "visual.blocks.7.attn.proj",
[0;36m(APIServer pid=399008)[0;0m       "visual.blocks.7.attn.qkv_proj",
[0;36m(APIServer pid=399008)[0;0m       "visual.blocks.7.mlp.linear_fc1",
[0;36m(APIServer pid=399008)[0;0m       "visual.blocks.7.mlp.linear_fc2",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.blocks.8.attn.proj",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.blocks.8.attn.qkv",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.blocks.8.mlp.linear_fc1",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.blocks.8.mlp.linear_fc2",
[0;36m(APIServer pid=399008)[0;0m       "visual.blocks.8.attn.proj",
[0;36m(APIServer pid=399008)[0;0m       "visual.blocks.8.attn.qkv_proj",
[0;36m(APIServer pid=399008)[0;0m       "visual.blocks.8.mlp.linear_fc1",
[0;36m(APIServer pid=399008)[0;0m       "visual.blocks.8.mlp.linear_fc2",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.blocks.9.attn.proj",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.blocks.9.attn.qkv",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.blocks.9.mlp.linear_fc1",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.blocks.9.mlp.linear_fc2",
[0;36m(APIServer pid=399008)[0;0m       "visual.blocks.9.attn.proj",
[0;36m(APIServer pid=399008)[0;0m       "visual.blocks.9.attn.qkv_proj",
[0;36m(APIServer pid=399008)[0;0m       "visual.blocks.9.mlp.linear_fc1",
[0;36m(APIServer pid=399008)[0;0m       "visual.blocks.9.mlp.linear_fc2",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.blocks.10.attn.proj",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.blocks.10.attn.qkv",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.blocks.10.mlp.linear_fc1",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.blocks.10.mlp.linear_fc2",
[0;36m(APIServer pid=399008)[0;0m       "visual.blocks.10.attn.proj",
[0;36m(APIServer pid=399008)[0;0m       "visual.blocks.10.attn.qkv_proj",
[0;36m(APIServer pid=399008)[0;0m       "visual.blocks.10.mlp.linear_fc1",
[0;36m(APIServer pid=399008)[0;0m       "visual.blocks.10.mlp.linear_fc2",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.blocks.11.attn.proj",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.blocks.11.attn.qkv",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.blocks.11.mlp.linear_fc1",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.blocks.11.mlp.linear_fc2",
[0;36m(APIServer pid=399008)[0;0m       "visual.blocks.11.attn.proj",
[0;36m(APIServer pid=399008)[0;0m       "visual.blocks.11.attn.qkv_proj",
[0;36m(APIServer pid=399008)[0;0m       "visual.blocks.11.mlp.linear_fc1",
[0;36m(APIServer pid=399008)[0;0m       "visual.blocks.11.mlp.linear_fc2",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.blocks.12.attn.proj",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.blocks.12.attn.qkv",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.blocks.12.mlp.linear_fc1",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.blocks.12.mlp.linear_fc2",
[0;36m(APIServer pid=399008)[0;0m       "visual.blocks.12.attn.proj",
[0;36m(APIServer pid=399008)[0;0m       "visual.blocks.12.attn.qkv_proj",
[0;36m(APIServer pid=399008)[0;0m       "visual.blocks.12.mlp.linear_fc1",
[0;36m(APIServer pid=399008)[0;0m       "visual.blocks.12.mlp.linear_fc2",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.blocks.13.attn.proj",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.blocks.13.attn.qkv",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.blocks.13.mlp.linear_fc1",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.blocks.13.mlp.linear_fc2",
[0;36m(APIServer pid=399008)[0;0m       "visual.blocks.13.attn.proj",
[0;36m(APIServer pid=399008)[0;0m       "visual.blocks.13.attn.qkv_proj",
[0;36m(APIServer pid=399008)[0;0m       "visual.blocks.13.mlp.linear_fc1",
[0;36m(APIServer pid=399008)[0;0m       "visual.blocks.13.mlp.linear_fc2",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.blocks.14.attn.proj",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.blocks.14.attn.qkv",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.blocks.14.mlp.linear_fc1",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.blocks.14.mlp.linear_fc2",
[0;36m(APIServer pid=399008)[0;0m       "visual.blocks.14.attn.proj",
[0;36m(APIServer pid=399008)[0;0m       "visual.blocks.14.attn.qkv_proj",
[0;36m(APIServer pid=399008)[0;0m       "visual.blocks.14.mlp.linear_fc1",
[0;36m(APIServer pid=399008)[0;0m       "visual.blocks.14.mlp.linear_fc2",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.blocks.15.attn.proj",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.blocks.15.attn.qkv",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.blocks.15.mlp.linear_fc1",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.blocks.15.mlp.linear_fc2",
[0;36m(APIServer pid=399008)[0;0m       "visual.blocks.15.attn.proj",
[0;36m(APIServer pid=399008)[0;0m       "visual.blocks.15.attn.qkv_proj",
[0;36m(APIServer pid=399008)[0;0m       "visual.blocks.15.mlp.linear_fc1",
[0;36m(APIServer pid=399008)[0;0m       "visual.blocks.15.mlp.linear_fc2",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.blocks.16.attn.proj",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.blocks.16.attn.qkv",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.blocks.16.mlp.linear_fc1",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.blocks.16.mlp.linear_fc2",
[0;36m(APIServer pid=399008)[0;0m       "visual.blocks.16.attn.proj",
[0;36m(APIServer pid=399008)[0;0m       "visual.blocks.16.attn.qkv_proj",
[0;36m(APIServer pid=399008)[0;0m       "visual.blocks.16.mlp.linear_fc1",
[0;36m(APIServer pid=399008)[0;0m       "visual.blocks.16.mlp.linear_fc2",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.blocks.17.attn.proj",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.blocks.17.attn.qkv",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.blocks.17.mlp.linear_fc1",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.blocks.17.mlp.linear_fc2",
[0;36m(APIServer pid=399008)[0;0m       "visual.blocks.17.attn.proj",
[0;36m(APIServer pid=399008)[0;0m       "visual.blocks.17.attn.qkv_proj",
[0;36m(APIServer pid=399008)[0;0m       "visual.blocks.17.mlp.linear_fc1",
[0;36m(APIServer pid=399008)[0;0m       "visual.blocks.17.mlp.linear_fc2",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.blocks.18.attn.proj",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.blocks.18.attn.qkv",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.blocks.18.mlp.linear_fc1",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.blocks.18.mlp.linear_fc2",
[0;36m(APIServer pid=399008)[0;0m       "visual.blocks.18.attn.proj",
[0;36m(APIServer pid=399008)[0;0m       "visual.blocks.18.attn.qkv_proj",
[0;36m(APIServer pid=399008)[0;0m       "visual.blocks.18.mlp.linear_fc1",
[0;36m(APIServer pid=399008)[0;0m       "visual.blocks.18.mlp.linear_fc2",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.blocks.19.attn.proj",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.blocks.19.attn.qkv",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.blocks.19.mlp.linear_fc1",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.blocks.19.mlp.linear_fc2",
[0;36m(APIServer pid=399008)[0;0m       "visual.blocks.19.attn.proj",
[0;36m(APIServer pid=399008)[0;0m       "visual.blocks.19.attn.qkv_proj",
[0;36m(APIServer pid=399008)[0;0m       "visual.blocks.19.mlp.linear_fc1",
[0;36m(APIServer pid=399008)[0;0m       "visual.blocks.19.mlp.linear_fc2",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.blocks.20.attn.proj",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.blocks.20.attn.qkv",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.blocks.20.mlp.linear_fc1",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.blocks.20.mlp.linear_fc2",
[0;36m(APIServer pid=399008)[0;0m       "visual.blocks.20.attn.proj",
[0;36m(APIServer pid=399008)[0;0m       "visual.blocks.20.attn.qkv_proj",
[0;36m(APIServer pid=399008)[0;0m       "visual.blocks.20.mlp.linear_fc1",
[0;36m(APIServer pid=399008)[0;0m       "visual.blocks.20.mlp.linear_fc2",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.blocks.21.attn.proj",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.blocks.21.attn.qkv",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.blocks.21.mlp.linear_fc1",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.blocks.21.mlp.linear_fc2",
[0;36m(APIServer pid=399008)[0;0m       "visual.blocks.21.attn.proj",
[0;36m(APIServer pid=399008)[0;0m       "visual.blocks.21.attn.qkv_proj",
[0;36m(APIServer pid=399008)[0;0m       "visual.blocks.21.mlp.linear_fc1",
[0;36m(APIServer pid=399008)[0;0m       "visual.blocks.21.mlp.linear_fc2",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.blocks.22.attn.proj",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.blocks.22.attn.qkv",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.blocks.22.mlp.linear_fc1",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.blocks.22.mlp.linear_fc2",
[0;36m(APIServer pid=399008)[0;0m       "visual.blocks.22.attn.proj",
[0;36m(APIServer pid=399008)[0;0m       "visual.blocks.22.attn.qkv_proj",
[0;36m(APIServer pid=399008)[0;0m       "visual.blocks.22.mlp.linear_fc1",
[0;36m(APIServer pid=399008)[0;0m       "visual.blocks.22.mlp.linear_fc2",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.blocks.23.attn.proj",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.blocks.23.attn.qkv",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.blocks.23.mlp.linear_fc1",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.blocks.23.mlp.linear_fc2",
[0;36m(APIServer pid=399008)[0;0m       "visual.blocks.23.attn.proj",
[0;36m(APIServer pid=399008)[0;0m       "visual.blocks.23.attn.qkv_proj",
[0;36m(APIServer pid=399008)[0;0m       "visual.blocks.23.mlp.linear_fc1",
[0;36m(APIServer pid=399008)[0;0m       "visual.blocks.23.mlp.linear_fc2",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.blocks.24.attn.proj",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.blocks.24.attn.qkv",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.blocks.24.mlp.linear_fc1",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.blocks.24.mlp.linear_fc2",
[0;36m(APIServer pid=399008)[0;0m       "visual.blocks.24.attn.proj",
[0;36m(APIServer pid=399008)[0;0m       "visual.blocks.24.attn.qkv_proj",
[0;36m(APIServer pid=399008)[0;0m       "visual.blocks.24.mlp.linear_fc1",
[0;36m(APIServer pid=399008)[0;0m       "visual.blocks.24.mlp.linear_fc2",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.blocks.25.attn.proj",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.blocks.25.attn.qkv",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.blocks.25.mlp.linear_fc1",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.blocks.25.mlp.linear_fc2",
[0;36m(APIServer pid=399008)[0;0m       "visual.blocks.25.attn.proj",
[0;36m(APIServer pid=399008)[0;0m       "visual.blocks.25.attn.qkv_proj",
[0;36m(APIServer pid=399008)[0;0m       "visual.blocks.25.mlp.linear_fc1",
[0;36m(APIServer pid=399008)[0;0m       "visual.blocks.25.mlp.linear_fc2",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.blocks.26.attn.proj",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.blocks.26.attn.qkv",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.blocks.26.mlp.linear_fc1",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.blocks.26.mlp.linear_fc2",
[0;36m(APIServer pid=399008)[0;0m       "visual.blocks.26.attn.proj",
[0;36m(APIServer pid=399008)[0;0m       "visual.blocks.26.attn.qkv_proj",
[0;36m(APIServer pid=399008)[0;0m       "visual.blocks.26.mlp.linear_fc1",
[0;36m(APIServer pid=399008)[0;0m       "visual.blocks.26.mlp.linear_fc2",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.deepstack_merger_list.0.linear_fc1",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.deepstack_merger_list.0.linear_fc2",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.deepstack_merger_list.0.norm",
[0;36m(APIServer pid=399008)[0;0m       "visual.deepstack_merger_list.0.linear_fc1",
[0;36m(APIServer pid=399008)[0;0m       "visual.deepstack_merger_list.0.linear_fc2",
[0;36m(APIServer pid=399008)[0;0m       "visual.deepstack_merger_list.0.norm",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.deepstack_merger_list.1.linear_fc1",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.deepstack_merger_list.1.linear_fc2",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.deepstack_merger_list.1.norm",
[0;36m(APIServer pid=399008)[0;0m       "visual.deepstack_merger_list.1.linear_fc1",
[0;36m(APIServer pid=399008)[0;0m       "visual.deepstack_merger_list.1.linear_fc2",
[0;36m(APIServer pid=399008)[0;0m       "visual.deepstack_merger_list.1.norm",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.deepstack_merger_list.2.linear_fc1",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.deepstack_merger_list.2.linear_fc2",
[0;36m(APIServer pid=399008)[0;0m       "model.visual.deepstack_merger_list.2.norm",
[0;36m(APIServer pid=399008)[0;0m       "visual.deepstack_merger_list.2.linear_fc1",
[0;36m(APIServer pid=399008)[0;0m       "visual.deepstack_merger_list.2.linear_fc2",
[0;36m(APIServer pid=399008)[0;0m       "visual.deepstack_merger_list.2.norm"
[0;36m(APIServer pid=399008)[0;0m     ],
[0;36m(APIServer pid=399008)[0;0m     "quant_method": "fp8",
[0;36m(APIServer pid=399008)[0;0m     "weight_block_size": [
[0;36m(APIServer pid=399008)[0;0m       128,
[0;36m(APIServer pid=399008)[0;0m       128
[0;36m(APIServer pid=399008)[0;0m     ]
[0;36m(APIServer pid=399008)[0;0m   },
[0;36m(APIServer pid=399008)[0;0m   "text_config": {
[0;36m(APIServer pid=399008)[0;0m     "attention_bias": false,
[0;36m(APIServer pid=399008)[0;0m     "attention_dropout": 0.0,
[0;36m(APIServer pid=399008)[0;0m     "bos_token_id": 151643,
[0;36m(APIServer pid=399008)[0;0m     "dtype": "bfloat16",
[0;36m(APIServer pid=399008)[0;0m     "eos_token_id": 151645,
[0;36m(APIServer pid=399008)[0;0m     "head_dim": 128,
[0;36m(APIServer pid=399008)[0;0m     "hidden_act": "silu",
[0;36m(APIServer pid=399008)[0;0m     "hidden_size": 5120,
[0;36m(APIServer pid=399008)[0;0m     "initializer_range": 0.02,
[0;36m(APIServer pid=399008)[0;0m     "intermediate_size": 25600,
[0;36m(APIServer pid=399008)[0;0m     "max_position_embeddings": 262144,
[0;36m(APIServer pid=399008)[0;0m     "model_type": "qwen3_vl_text",
[0;36m(APIServer pid=399008)[0;0m     "num_attention_heads": 64,
[0;36m(APIServer pid=399008)[0;0m     "num_hidden_layers": 64,
[0;36m(APIServer pid=399008)[0;0m     "num_key_value_heads": 8,
[0;36m(APIServer pid=399008)[0;0m     "rms_norm_eps": 1e-06,
[0;36m(APIServer pid=399008)[0;0m     "rope_scaling": {
[0;36m(APIServer pid=399008)[0;0m       "mrope_interleaved": true,
[0;36m(APIServer pid=399008)[0;0m       "mrope_section": [
[0;36m(APIServer pid=399008)[0;0m         24,
[0;36m(APIServer pid=399008)[0;0m         20,
[0;36m(APIServer pid=399008)[0;0m         20
[0;36m(APIServer pid=399008)[0;0m       ],
[0;36m(APIServer pid=399008)[0;0m       "rope_type": "default"
[0;36m(APIServer pid=399008)[0;0m     },
[0;36m(APIServer pid=399008)[0;0m     "rope_theta": 5000000,
[0;36m(APIServer pid=399008)[0;0m     "use_cache": true,
[0;36m(APIServer pid=399008)[0;0m     "vocab_size": 151936
[0;36m(APIServer pid=399008)[0;0m   },
[0;36m(APIServer pid=399008)[0;0m   "tie_word_embeddings": false,
[0;36m(APIServer pid=399008)[0;0m   "transformers_version": "4.57.6",
[0;36m(APIServer pid=399008)[0;0m   "video_token_id": 151656,
[0;36m(APIServer pid=399008)[0;0m   "vision_config": {
[0;36m(APIServer pid=399008)[0;0m     "deepstack_visual_indexes": [
[0;36m(APIServer pid=399008)[0;0m       8,
[0;36m(APIServer pid=399008)[0;0m       16,
[0;36m(APIServer pid=399008)[0;0m       24
[0;36m(APIServer pid=399008)[0;0m     ],
[0;36m(APIServer pid=399008)[0;0m     "depth": 27,
[0;36m(APIServer pid=399008)[0;0m     "hidden_act": "gelu_pytorch_tanh",
[0;36m(APIServer pid=399008)[0;0m     "hidden_size": 1152,
[0;36m(APIServer pid=399008)[0;0m     "in_channels": 3,
[0;36m(APIServer pid=399008)[0;0m     "initializer_range": 0.02,
[0;36m(APIServer pid=399008)[0;0m     "intermediate_size": 4304,
[0;36m(APIServer pid=399008)[0;0m     "model_type": "qwen3_vl",
[0;36m(APIServer pid=399008)[0;0m     "num_heads": 16,
[0;36m(APIServer pid=399008)[0;0m     "num_position_embeddings": 2304,
[0;36m(APIServer pid=399008)[0;0m     "out_hidden_size": 5120,
[0;36m(APIServer pid=399008)[0;0m     "patch_size": 16,
[0;36m(APIServer pid=399008)[0;0m     "spatial_merge_size": 2,
[0;36m(APIServer pid=399008)[0;0m     "temporal_patch_size": 2
[0;36m(APIServer pid=399008)[0;0m   },
[0;36m(APIServer pid=399008)[0;0m   "vision_end_token_id": 151653,
[0;36m(APIServer pid=399008)[0;0m   "vision_start_token_id": 151652
[0;36m(APIServer pid=399008)[0;0m }
[0;36m(APIServer pid=399008)[0;0m 
[0;36m(APIServer pid=399008)[0;0m DEBUG 02-05 00:23:23 [model_executor/models/registry.py:668] Cached model info file for class vllm_gaudi.models.qwen3_vl.HpuQwen3_VLForConditionalGeneration is stale
[0;36m(APIServer pid=399008)[0;0m DEBUG 02-05 00:23:23 [model_executor/models/registry.py:720] Cache model info for class vllm_gaudi.models.qwen3_vl.HpuQwen3_VLForConditionalGeneration miss. Loading model instead.
[0;36m(APIServer pid=399008)[0;0m DEBUG 02-05 00:23:30 [model_executor/models/registry.py:730] Loaded model info for class vllm_gaudi.models.qwen3_vl.HpuQwen3_VLForConditionalGeneration
[0;36m(APIServer pid=399008)[0;0m DEBUG 02-05 00:23:30 [logging_utils/log_time.py:29] Registry inspect model class: Elapsed time 6.8375343 secs
[0;36m(APIServer pid=399008)[0;0m INFO 02-05 00:23:30 [config/model.py:530] Resolved architecture: Qwen3VLForConditionalGeneration
[0;36m(APIServer pid=399008)[0;0m INFO 02-05 00:23:30 [config/model.py:1545] Using max model len 32768
[0;36m(APIServer pid=399008)[0;0m DEBUG 02-05 00:23:30 [_ipex_ops.py:15] Import error msg: No module named 'intel_extension_for_pytorch'
[0;36m(APIServer pid=399008)[0;0m DEBUG 02-05 00:23:30 [config/model.py:1609] Generative models support chunked prefill.
[0;36m(APIServer pid=399008)[0;0m DEBUG 02-05 00:23:30 [config/model.py:1667] Generative models support prefix caching.
[0;36m(APIServer pid=399008)[0;0m DEBUG 02-05 00:23:30 [engine/arg_utils.py:1909] Enabling chunked prefill by default
[0;36m(APIServer pid=399008)[0;0m DEBUG 02-05 00:23:30 [engine/arg_utils.py:1939] Enabling prefix caching by default
[0;36m(APIServer pid=399008)[0;0m WARNING 02-05 00:23:30 [platform.py:95] This is a workaround! Please check the NOTE in the get_device_total_memory definition.
[0;36m(APIServer pid=399008)[0;0m DEBUG 02-05 00:23:30 [engine/arg_utils.py:2027] Defaulting max_num_seqs to 256 for OPENAI_API_SERVER usage context.
[0;36m(APIServer pid=399008)[0;0m DEBUG 02-05 00:23:30 [config/parallel.py:689] Disabled the custom all-reduce kernel because it is not supported on current platform.
[0;36m(APIServer pid=399008)[0;0m INFO 02-05 00:23:30 [config/scheduler.py:229] Chunked prefill is enabled with max_num_batched_tokens=32768.
[0;36m(APIServer pid=399008)[0;0m DEBUG 02-05 00:23:30 [config/parallel.py:689] Disabled the custom all-reduce kernel because it is not supported on current platform.
[0;36m(APIServer pid=399008)[0;0m INFO 02-05 00:23:30 [config/vllm.py:630] Asynchronous scheduling is enabled.
[0;36m(APIServer pid=399008)[0;0m INFO 02-05 00:23:30 [config/vllm.py:637] Disabling NCCL for DP synchronization when using async scheduling.
[0;36m(APIServer pid=399008)[0;0m WARNING 02-05 00:23:30 [platform.py:143] Using Contiguous PA, disabling prefix caching
[0;36m(APIServer pid=399008)[0;0m INFO 02-05 00:23:30 [platform.py:147] [HPU] Forcing CompilationMode.NONE compilation mode
[0;36m(APIServer pid=399008)[0;0m =========compilation_config.custom_ops=['all']===========
[0;36m(APIServer pid=399008)[0;0m DEBUG 02-05 00:23:30 [plugins/__init__.py:35] No plugins for group vllm.stat_logger_plugins found.
[0;36m(APIServer pid=399008)[0;0m DEBUG 02-05 00:23:30 [tokenizers/registry.py:64] Loading CachedHfTokenizer for tokenizer_mode='hf'
[0;36m(APIServer pid=399008)[0;0m loading file vocab.json
[0;36m(APIServer pid=399008)[0;0m loading file merges.txt
[0;36m(APIServer pid=399008)[0;0m loading file tokenizer.json
[0;36m(APIServer pid=399008)[0;0m loading file added_tokens.json
[0;36m(APIServer pid=399008)[0;0m loading file special_tokens_map.json
[0;36m(APIServer pid=399008)[0;0m loading file tokenizer_config.json
[0;36m(APIServer pid=399008)[0;0m loading file chat_template.jinja
[0;36m(APIServer pid=399008)[0;0m Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[0;36m(APIServer pid=399008)[0;0m loading configuration file /root/.cache/huggingface/hub/models--Qwen--Qwen3-VL-32B-Instruct-FP8/snapshots/4bf2c2f39c37c0fede78bede4056e1f18cdf8109/generation_config.json
[0;36m(APIServer pid=399008)[0;0m Generate config GenerationConfig {
[0;36m(APIServer pid=399008)[0;0m   "bos_token_id": 151643,
[0;36m(APIServer pid=399008)[0;0m   "do_sample": true,
[0;36m(APIServer pid=399008)[0;0m   "eos_token_id": [
[0;36m(APIServer pid=399008)[0;0m     151645,
[0;36m(APIServer pid=399008)[0;0m     151643
[0;36m(APIServer pid=399008)[0;0m   ],
[0;36m(APIServer pid=399008)[0;0m   "pad_token_id": 151643,
[0;36m(APIServer pid=399008)[0;0m   "temperature": 0.7,
[0;36m(APIServer pid=399008)[0;0m   "top_k": 20,
[0;36m(APIServer pid=399008)[0;0m   "top_p": 0.8
[0;36m(APIServer pid=399008)[0;0m }
[0;36m(APIServer pid=399008)[0;0m 
[0;36m(APIServer pid=399008)[0;0m DEBUG 02-05 00:23:31 [plugins/io_processors/__init__.py:33] No IOProcessor plugins requested by the model
Calling add_step_closure function does not have any effect. It's lazy mode only functionality. (warning logged once)
Calling mark_step function does not have any effect. It's lazy mode only functionality. (warning logged once)
Calling iter_mark_step function does not have any effect. It's lazy mode only functionality. (warning logged once)
INFO 02-05 00:23:34 [plugins/__init__.py:43] Available plugins for group vllm.platform_plugins:
INFO 02-05 00:23:34 [plugins/__init__.py:45] - hpu -> vllm_gaudi:register
INFO 02-05 00:23:34 [plugins/__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
DEBUG 02-05 00:23:34 [platforms/__init__.py:36] Checking if TPU platform is available.
DEBUG 02-05 00:23:34 [platforms/__init__.py:55] TPU platform is not available because: No module named 'libtpu'
DEBUG 02-05 00:23:34 [platforms/__init__.py:61] Checking if CUDA platform is available.
DEBUG 02-05 00:23:34 [platforms/__init__.py:88] Exception happens when checking CUDA platform: NVML Shared Library Not Found
DEBUG 02-05 00:23:34 [platforms/__init__.py:105] CUDA platform is not available because: NVML Shared Library Not Found
DEBUG 02-05 00:23:34 [platforms/__init__.py:112] Checking if ROCm platform is available.
DEBUG 02-05 00:23:34 [platforms/__init__.py:126] ROCm platform is not available because: No module named 'amdsmi'
DEBUG 02-05 00:23:34 [platforms/__init__.py:133] Checking if XPU platform is available.
DEBUG 02-05 00:23:34 [platforms/__init__.py:153] XPU platform is not available because: No module named 'intel_extension_for_pytorch'
DEBUG 02-05 00:23:34 [platforms/__init__.py:160] Checking if CPU platform is available.
INFO 02-05 00:23:34 [platforms/__init__.py:217] Platform plugin hpu is activated
INFO 02-05 00:23:35 [triton_utils/importing.py:44] Triton is installed but 0 active driver(s) found (expected 1). Disabling Triton to prevent runtime errors.
INFO 02-05 00:23:35 [triton_utils/importing.py:68] Triton not installed or not compatible; certain GPU-related functions will not be available.
WARNING 02-05 00:23:37 [platforms/interface.py:222] Failed to import from vllm._C: ModuleNotFoundError("No module named 'vllm._C'")
DEBUG 02-05 00:23:37 [utils/flashinfer.py:55] FlashInfer unavailable since package was not found
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:37 [v1/engine/core.py:862] Waiting for init message from front-end.
[0;36m(APIServer pid=399008)[0;0m DEBUG 02-05 00:23:37 [v1/engine/utils.py:1081] HELLO from local core engine process 0.
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:37 [v1/engine/core.py:873] Received init message: EngineHandshakeMetadata(addresses=EngineZmqAddresses(inputs=['ipc:///tmp/e83af5b7-780d-4b89-8643-7b23ab44405c'], outputs=['ipc:///tmp/9b4dad77-3ca8-4056-be36-0399981e9fd7'], coordinator_input=None, coordinator_output=None, frontend_stats_publish_address=None), parallel_config={})
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:37 [v1/engine/core.py:677] Has DP Coordinator: False, stats publish address: None
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:37 [plugins/__init__.py:43] Available plugins for group vllm.general_plugins:
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:37 [plugins/__init__.py:45] - 01.hpu_custom_ops -> vllm_gaudi:register_ops
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:37 [plugins/__init__.py:45] - 02.hpu_custom_models -> vllm_gaudi:register_models
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:37 [plugins/__init__.py:45] - lora_filesystem_resolver -> vllm.plugins.lora_resolvers.filesystem_resolver:register_filesystem_resolver
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:37 [plugins/__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
[0;36m(EngineCore_DP0 pid=399683)[0;0m WARNING 02-05 00:23:37 [distributed/.../v1/nixl_connector.py:99] NIXL is not available
[0;36m(EngineCore_DP0 pid=399683)[0;0m WARNING 02-05 00:23:37 [distributed/.../v1/nixl_connector.py:111] NIXL agent config is not available
[0;36m(EngineCore_DP0 pid=399683)[0;0m WARNING 02-05 00:23:37 [platform.py:163] Pin memory is not supported on HPU.
[0;36m(EngineCore_DP0 pid=399683)[0;0m WARNING 02-05 00:23:37 [model_executor/models/registry.py:801] Model architecture Gemma3ForConditionalGeneration is already registered, and will be overwritten by the new model class vllm_gaudi.models.gemma3_mm:HpuGemma3ForConditionalGeneration.
[0;36m(EngineCore_DP0 pid=399683)[0;0m WARNING 02-05 00:23:37 [model_executor/models/registry.py:801] Model architecture Qwen2_5_VLForConditionalGeneration is already registered, and will be overwritten by the new model class vllm_gaudi.models.qwen2_5_vl:HpuQwen2_5_VLForConditionalGeneration.
[0;36m(EngineCore_DP0 pid=399683)[0;0m WARNING 02-05 00:23:37 [model_executor/models/registry.py:801] Model architecture Qwen3VLForConditionalGeneration is already registered, and will be overwritten by the new model class vllm_gaudi.models.qwen3_vl:HpuQwen3_VLForConditionalGeneration.
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:37 [compilation/decorators.py:202] Inferred dynamic dimensions for forward method of <class 'vllm.model_executor.models.qwen3_moe.Qwen3MoeModel'>: ['input_ids', 'positions', 'intermediate_tensors', 'inputs_embeds']
[0;36m(EngineCore_DP0 pid=399683)[0;0m WARNING 02-05 00:23:37 [model_executor/models/registry.py:801] Model architecture Qwen3VLMoeForConditionalGeneration is already registered, and will be overwritten by the new model class vllm_gaudi.models.qwen3_vl_moe:HpuQwen3_VLMoeForConditionalGeneration.
[0;36m(EngineCore_DP0 pid=399683)[0;0m INFO 02-05 00:23:37 [v1/engine/core.py:97] Initializing a V1 LLM engine (v0.14.0) with config: model='/root/.cache/huggingface/hub/models--Qwen--Qwen3-VL-32B-Instruct-FP8/snapshots/4bf2c2f39c37c0fede78bede4056e1f18cdf8109/', speculative_config=None, tokenizer='/root/.cache/huggingface/hub/models--Qwen--Qwen3-VL-32B-Instruct-FP8/snapshots/4bf2c2f39c37c0fede78bede4056e1f18cdf8109/', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=32768, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=fp8, enforce_eager=False, enable_return_routed_experts=False, kv_cache_dtype=auto, device_config=hpu, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01, cudagraph_metrics=False, enable_layerwise_nvtx_tracing=False, enable_mfu_metrics=False, enable_mm_processor_stats=False, enable_logging_iteration_details=False), seed=0, served_model_name=/root/.cache/huggingface/hub/models--Qwen--Qwen3-VL-32B-Instruct-FP8/snapshots/4bf2c2f39c37c0fede78bede4056e1f18cdf8109/, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.NONE: 0>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'hpu_backend', 'custom_ops': ['all', '+quant_fp8'], 'splitting_ops': [], 'compile_mm_encoder': False, 'compile_sizes': None, 'compile_ranges_split_points': [32768], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.NONE: 0>, 'cudagraph_num_of_warmups': 0, 'cudagraph_capture_sizes': [], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': True, 'fuse_act_quant': True, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': None, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>, 'evaluate_guards': False, 'assume_32_bit_indexing': True}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:37 [compilation/decorators.py:202] Inferred dynamic dimensions for forward method of <class 'vllm.model_executor.models.deepseek_v2.DeepseekV2Model'>: ['input_ids', 'positions', 'intermediate_tensors', 'inputs_embeds']
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:37 [compilation/decorators.py:202] Inferred dynamic dimensions for forward method of <class 'vllm.model_executor.models.llama.LlamaModel'>: ['input_ids', 'positions', 'intermediate_tensors', 'inputs_embeds']
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:37 [tokenizers/registry.py:64] Loading CachedHfTokenizer for tokenizer_mode='hf'
[0;36m(EngineCore_DP0 pid=399683)[0;0m loading file vocab.json
[0;36m(EngineCore_DP0 pid=399683)[0;0m loading file merges.txt
[0;36m(EngineCore_DP0 pid=399683)[0;0m loading file tokenizer.json
[0;36m(EngineCore_DP0 pid=399683)[0;0m loading file added_tokens.json
[0;36m(EngineCore_DP0 pid=399683)[0;0m loading file special_tokens_map.json
[0;36m(EngineCore_DP0 pid=399683)[0;0m loading file tokenizer_config.json
[0;36m(EngineCore_DP0 pid=399683)[0;0m loading file chat_template.jinja
[0;36m(EngineCore_DP0 pid=399683)[0;0m Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:38 [distributed/parallel_state.py:1172] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://172.26.46.50:38395 backend=hccl
[0;36m(EngineCore_DP0 pid=399683)[0;0m INFO 02-05 00:23:38 [distributed/parallel_state.py:1214] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://172.26.46.50:38395 backend=hccl
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:38 [distributed/parallel_state.py:1258] Detected 1 nodes in the distributed environment
============================= HPU PT BRIDGE CONFIGURATION ON RANK = 0 ============= 
 PT_HPU_LAZY_MODE = 0
 PT_HPU_RECIPE_CACHE_CONFIG = ,false,1024,false
 PT_HPU_MAX_COMPOUND_OP_SIZE = 9223372036854775807
 PT_HPU_LAZY_ACC_PAR_MODE = 1
 PT_HPU_ENABLE_REFINE_DYNAMIC_SHAPES = 0
 PT_HPU_EAGER_PIPELINE_ENABLE = 1
 PT_HPU_EAGER_COLLECTIVE_PIPELINE_ENABLE = 1
 PT_HPU_ENABLE_LAZY_COLLECTIVES = 1
---------------------------: System Configuration :---------------------------
Num CPU Cores : 224
CPU RAM       : 1007 GB
------------------------------------------------------------------------------
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[0;36m(EngineCore_DP0 pid=399683)[0;0m INFO 02-05 00:23:38 [distributed/parallel_state.py:1425] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank N/A
[0;36m(EngineCore_DP0 pid=399683)[0;0m INFO 02-05 00:23:39 [runtime.py:28] Environment:
[0;36m(EngineCore_DP0 pid=399683)[0;0m INFO 02-05 00:23:39 [runtime.py:32]     hw: gaudi3
[0;36m(EngineCore_DP0 pid=399683)[0;0m INFO 02-05 00:23:39 [runtime.py:32]     build: 1.23.0.695
[0;36m(EngineCore_DP0 pid=399683)[0;0m INFO 02-05 00:23:39 [runtime.py:32]     engine_version: v1
[0;36m(EngineCore_DP0 pid=399683)[0;0m INFO 02-05 00:23:39 [runtime.py:32]     bridge_mode: eager
[0;36m(EngineCore_DP0 pid=399683)[0;0m INFO 02-05 00:23:39 [runtime.py:32]     model_type: qwen3_vl
[0;36m(EngineCore_DP0 pid=399683)[0;0m INFO 02-05 00:23:39 [runtime.py:32]     prefix_caching: False
[0;36m(EngineCore_DP0 pid=399683)[0;0m INFO 02-05 00:23:39 [runtime.py:32]     vllm_gaudi_commit: releases/v0.14.1+c4ecd71
[0;36m(EngineCore_DP0 pid=399683)[0;0m INFO 02-05 00:23:39 [runtime.py:28] Features:
[0;36m(EngineCore_DP0 pid=399683)[0;0m INFO 02-05 00:23:39 [runtime.py:32]     fp32_alibi_biases: True
[0;36m(EngineCore_DP0 pid=399683)[0;0m INFO 02-05 00:23:39 [runtime.py:32]     fp32_softmax: False
[0;36m(EngineCore_DP0 pid=399683)[0;0m INFO 02-05 00:23:39 [runtime.py:32]     fused_block_softmax_adjustment: False
[0;36m(EngineCore_DP0 pid=399683)[0;0m INFO 02-05 00:23:39 [runtime.py:32]     fused_block_softmax: False
[0;36m(EngineCore_DP0 pid=399683)[0;0m INFO 02-05 00:23:39 [runtime.py:32]     prompt_attn_impl: fsdpa_impl
[0;36m(EngineCore_DP0 pid=399683)[0;0m INFO 02-05 00:23:39 [runtime.py:32]     skip_warmup: False
[0;36m(EngineCore_DP0 pid=399683)[0;0m INFO 02-05 00:23:39 [runtime.py:32]     merged_prefill: False
[0;36m(EngineCore_DP0 pid=399683)[0;0m INFO 02-05 00:23:39 [runtime.py:32]     use_contiguous_pa: True
[0;36m(EngineCore_DP0 pid=399683)[0;0m INFO 02-05 00:23:39 [runtime.py:32]     use_bucketing: True
[0;36m(EngineCore_DP0 pid=399683)[0;0m INFO 02-05 00:23:39 [runtime.py:32]     bucketing_strategy: linear_bucketing
[0;36m(EngineCore_DP0 pid=399683)[0;0m INFO 02-05 00:23:39 [runtime.py:32]     defrag: True
[0;36m(EngineCore_DP0 pid=399683)[0;0m INFO 02-05 00:23:39 [runtime.py:32]     regional_compilation: True
[0;36m(EngineCore_DP0 pid=399683)[0;0m INFO 02-05 00:23:39 [runtime.py:32]     dynamic_shapes_compilation: True
[0;36m(EngineCore_DP0 pid=399683)[0;0m INFO 02-05 00:23:39 [runtime.py:32]     fullgraph_compilation: False
[0;36m(EngineCore_DP0 pid=399683)[0;0m INFO 02-05 00:23:39 [runtime.py:32]     unified_attn: False
[0;36m(EngineCore_DP0 pid=399683)[0;0m INFO 02-05 00:23:39 [runtime.py:32]     unified_attn_softmax_fa2: False
[0;36m(EngineCore_DP0 pid=399683)[0;0m INFO 02-05 00:23:39 [runtime.py:32]     scale_adjustment: True
[0;36m(EngineCore_DP0 pid=399683)[0;0m INFO 02-05 00:23:39 [runtime.py:32]     flatten_input: False
[0;36m(EngineCore_DP0 pid=399683)[0;0m INFO 02-05 00:23:39 [runtime.py:32]     unified_attn_shared_cache_ratio: 0.8
[0;36m(EngineCore_DP0 pid=399683)[0;0m INFO 02-05 00:23:39 [runtime.py:32]     high_level_profiler_enabled: False
[0;36m(EngineCore_DP0 pid=399683)[0;0m INFO 02-05 00:23:39 [runtime.py:32]     track_graph_compilation: False
[0;36m(EngineCore_DP0 pid=399683)[0;0m INFO 02-05 00:23:39 [runtime.py:32]     use_output_tensor_in_matmulqk: False
[0;36m(EngineCore_DP0 pid=399683)[0;0m INFO 02-05 00:23:39 [runtime.py:32]     per_token_kv_scaling_support: False
[0;36m(EngineCore_DP0 pid=399683)[0;0m INFO 02-05 00:23:39 [runtime.py:32]     moe_chunk: 
[0;36m(EngineCore_DP0 pid=399683)[0;0m INFO 02-05 00:23:39 [runtime.py:32]     moe_token_boundary: 
[0;36m(EngineCore_DP0 pid=399683)[0;0m INFO 02-05 00:23:39 [runtime.py:32]     use_dispatch_fn: False
[0;36m(EngineCore_DP0 pid=399683)[0;0m INFO 02-05 00:23:39 [runtime.py:32]     use_hpu_aligned_scale: False
[0;36m(EngineCore_DP0 pid=399683)[0;0m INFO 02-05 00:23:39 [runtime.py:28] User flags:
[0;36m(EngineCore_DP0 pid=399683)[0;0m INFO 02-05 00:23:39 [runtime.py:32]     VLLM_EXPONENTIAL_BUCKETING: False
[0;36m(EngineCore_DP0 pid=399683)[0;0m INFO 02-05 00:23:39 [runtime.py:32]     VLLM_PROMPT_BS_BUCKET_MIN: 1
[0;36m(EngineCore_DP0 pid=399683)[0;0m INFO 02-05 00:23:39 [runtime.py:32]     VLLM_PROMPT_BS_BUCKET_STEP: 1
[0;36m(EngineCore_DP0 pid=399683)[0;0m INFO 02-05 00:23:39 [runtime.py:32]     VLLM_PROMPT_BS_BUCKET_MAX: 1
[0;36m(EngineCore_DP0 pid=399683)[0;0m INFO 02-05 00:23:39 [runtime.py:32]     VLLM_PROMPT_SEQ_BUCKET_MIN: 1024
[0;36m(EngineCore_DP0 pid=399683)[0;0m INFO 02-05 00:23:39 [runtime.py:32]     VLLM_PROMPT_SEQ_BUCKET_STEP: 1024
[0;36m(EngineCore_DP0 pid=399683)[0;0m INFO 02-05 00:23:39 [runtime.py:32]     VLLM_PROMPT_SEQ_BUCKET_MAX: 20480
[0;36m(EngineCore_DP0 pid=399683)[0;0m INFO 02-05 00:23:39 [runtime.py:32]     VLLM_PROMPT_CTX_BUCKET_MIN: 0
[0;36m(EngineCore_DP0 pid=399683)[0;0m INFO 02-05 00:23:39 [runtime.py:32]     VLLM_PROMPT_CTX_BUCKET_STEP: 12
[0;36m(EngineCore_DP0 pid=399683)[0;0m INFO 02-05 00:23:39 [runtime.py:32]     VLLM_PROMPT_CTX_BUCKET_MAX: 24
[0;36m(EngineCore_DP0 pid=399683)[0;0m INFO 02-05 00:23:39 [runtime.py:32]     VLLM_DECODE_BS_BUCKET_MIN: 1
[0;36m(EngineCore_DP0 pid=399683)[0;0m INFO 02-05 00:23:39 [runtime.py:32]     VLLM_DECODE_BS_BUCKET_STEP: 4
[0;36m(EngineCore_DP0 pid=399683)[0;0m INFO 02-05 00:23:39 [runtime.py:32]     VLLM_DECODE_BS_BUCKET_MAX: 64
[0;36m(EngineCore_DP0 pid=399683)[0;0m INFO 02-05 00:23:39 [runtime.py:32]     VLLM_DECODE_BLOCK_BUCKET_MIN: 256
[0;36m(EngineCore_DP0 pid=399683)[0;0m INFO 02-05 00:23:39 [runtime.py:32]     VLLM_DECODE_BLOCK_BUCKET_STEP: 128
[0;36m(EngineCore_DP0 pid=399683)[0;0m INFO 02-05 00:23:39 [runtime.py:32]     VLLM_DECODE_BLOCK_BUCKET_MAX: 1152
[0;36m(EngineCore_DP0 pid=399683)[0;0m INFO 02-05 00:23:39 [runtime.py:32]     EXPERIMENTAL_WEIGHT_SHARING: 0
[0;36m(EngineCore_DP0 pid=399683)[0;0m INFO 02-05 00:23:39 [runtime.py:32]     PT_HPU_WEIGHT_SHARING: 0
[0;36m(EngineCore_DP0 pid=399683)[0;0m INFO 02-05 00:23:39 [runtime.py:32]     RUNTIME_SCALE_PATCHING: 1
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744] model config: ModelConfig(model='/root/.cache/huggingface/hub/models--Qwen--Qwen3-VL-32B-Instruct-FP8/snapshots/4bf2c2f39c37c0fede78bede4056e1f18cdf8109/', model_weights='', runner='auto', convert='auto', tokenizer='/root/.cache/huggingface/hub/models--Qwen--Qwen3-VL-32B-Instruct-FP8/snapshots/4bf2c2f39c37c0fede78bede4056e1f18cdf8109/', tokenizer_mode='auto', trust_remote_code=True, dtype=torch.bfloat16, seed=0, hf_config=Qwen3VLConfig {
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]   "architectures": [
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]     "Qwen3VLForConditionalGeneration"
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]   ],
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]   "image_token_id": 151655,
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]   "model_type": "qwen3_vl",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]   "quantization_config": {
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]     "activation_scheme": "dynamic",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]     "fmt": "e4m3",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]     "ignored_layers": [
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "lm_head",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.merger.linear_fc1",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.merger.linear_fc2",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.merger.norm",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.patch_embed.proj",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.pos_embed",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.merger.linear_fc1",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.merger.linear_fc2",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.merger.norm",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.patch_embed.proj",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.pos_embed",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.blocks.0.attn.proj",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.blocks.0.attn.qkv",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.blocks.0.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.blocks.0.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.blocks.0.attn.proj",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.blocks.0.attn.qkv_proj",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.blocks.0.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.blocks.0.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.blocks.1.attn.proj",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.blocks.1.attn.qkv",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.blocks.1.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.blocks.1.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.blocks.1.attn.proj",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.blocks.1.attn.qkv_proj",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.blocks.1.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.blocks.1.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.blocks.2.attn.proj",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.blocks.2.attn.qkv",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.blocks.2.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.blocks.2.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.blocks.2.attn.proj",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.blocks.2.attn.qkv_proj",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.blocks.2.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.blocks.2.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.blocks.3.attn.proj",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.blocks.3.attn.qkv",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.blocks.3.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.blocks.3.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.blocks.3.attn.proj",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.blocks.3.attn.qkv_proj",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.blocks.3.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.blocks.3.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.blocks.4.attn.proj",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.blocks.4.attn.qkv",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.blocks.4.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.blocks.4.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.blocks.4.attn.proj",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.blocks.4.attn.qkv_proj",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.blocks.4.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.blocks.4.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.blocks.5.attn.proj",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.blocks.5.attn.qkv",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.blocks.5.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.blocks.5.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.blocks.5.attn.proj",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.blocks.5.attn.qkv_proj",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.blocks.5.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.blocks.5.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.blocks.6.attn.proj",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.blocks.6.attn.qkv",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.blocks.6.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.blocks.6.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.blocks.6.attn.proj",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.blocks.6.attn.qkv_proj",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.blocks.6.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.blocks.6.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.blocks.7.attn.proj",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.blocks.7.attn.qkv",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.blocks.7.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.blocks.7.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.blocks.7.attn.proj",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.blocks.7.attn.qkv_proj",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.blocks.7.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.blocks.7.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.blocks.8.attn.proj",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.blocks.8.attn.qkv",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.blocks.8.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.blocks.8.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.blocks.8.attn.proj",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.blocks.8.attn.qkv_proj",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.blocks.8.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.blocks.8.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.blocks.9.attn.proj",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.blocks.9.attn.qkv",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.blocks.9.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.blocks.9.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.blocks.9.attn.proj",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.blocks.9.attn.qkv_proj",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.blocks.9.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.blocks.9.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.blocks.10.attn.proj",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.blocks.10.attn.qkv",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.blocks.10.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.blocks.10.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.blocks.10.attn.proj",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.blocks.10.attn.qkv_proj",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.blocks.10.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.blocks.10.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.blocks.11.attn.proj",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.blocks.11.attn.qkv",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.blocks.11.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.blocks.11.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.blocks.11.attn.proj",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.blocks.11.attn.qkv_proj",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.blocks.11.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.blocks.11.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.blocks.12.attn.proj",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.blocks.12.attn.qkv",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.blocks.12.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.blocks.12.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.blocks.12.attn.proj",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.blocks.12.attn.qkv_proj",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.blocks.12.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.blocks.12.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.blocks.13.attn.proj",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.blocks.13.attn.qkv",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.blocks.13.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.blocks.13.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.blocks.13.attn.proj",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.blocks.13.attn.qkv_proj",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.blocks.13.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.blocks.13.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.blocks.14.attn.proj",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.blocks.14.attn.qkv",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.blocks.14.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.blocks.14.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.blocks.14.attn.proj",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.blocks.14.attn.qkv_proj",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.blocks.14.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.blocks.14.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.blocks.15.attn.proj",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.blocks.15.attn.qkv",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.blocks.15.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.blocks.15.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.blocks.15.attn.proj",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.blocks.15.attn.qkv_proj",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.blocks.15.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.blocks.15.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.blocks.16.attn.proj",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.blocks.16.attn.qkv",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.blocks.16.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.blocks.16.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.blocks.16.attn.proj",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.blocks.16.attn.qkv_proj",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.blocks.16.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.blocks.16.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.blocks.17.attn.proj",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.blocks.17.attn.qkv",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.blocks.17.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.blocks.17.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.blocks.17.attn.proj",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.blocks.17.attn.qkv_proj",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.blocks.17.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.blocks.17.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.blocks.18.attn.proj",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.blocks.18.attn.qkv",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.blocks.18.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.blocks.18.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.blocks.18.attn.proj",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.blocks.18.attn.qkv_proj",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.blocks.18.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.blocks.18.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.blocks.19.attn.proj",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.blocks.19.attn.qkv",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.blocks.19.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.blocks.19.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.blocks.19.attn.proj",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.blocks.19.attn.qkv_proj",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.blocks.19.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.blocks.19.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.blocks.20.attn.proj",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.blocks.20.attn.qkv",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.blocks.20.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.blocks.20.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.blocks.20.attn.proj",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.blocks.20.attn.qkv_proj",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.blocks.20.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.blocks.20.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.blocks.21.attn.proj",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.blocks.21.attn.qkv",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.blocks.21.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.blocks.21.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.blocks.21.attn.proj",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.blocks.21.attn.qkv_proj",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.blocks.21.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.blocks.21.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.blocks.22.attn.proj",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.blocks.22.attn.qkv",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.blocks.22.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.blocks.22.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.blocks.22.attn.proj",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.blocks.22.attn.qkv_proj",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.blocks.22.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.blocks.22.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.blocks.23.attn.proj",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.blocks.23.attn.qkv",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.blocks.23.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.blocks.23.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.blocks.23.attn.proj",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.blocks.23.attn.qkv_proj",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.blocks.23.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.blocks.23.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.blocks.24.attn.proj",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.blocks.24.attn.qkv",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.blocks.24.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.blocks.24.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.blocks.24.attn.proj",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.blocks.24.attn.qkv_proj",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.blocks.24.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.blocks.24.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.blocks.25.attn.proj",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.blocks.25.attn.qkv",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.blocks.25.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.blocks.25.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.blocks.25.attn.proj",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.blocks.25.attn.qkv_proj",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.blocks.25.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.blocks.25.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.blocks.26.attn.proj",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.blocks.26.attn.qkv",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.blocks.26.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.blocks.26.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.blocks.26.attn.proj",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.blocks.26.attn.qkv_proj",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.blocks.26.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.blocks.26.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.deepstack_merger_list.0.linear_fc1",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.deepstack_merger_list.0.linear_fc2",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.deepstack_merger_list.0.norm",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.deepstack_merger_list.0.linear_fc1",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.deepstack_merger_list.0.linear_fc2",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.deepstack_merger_list.0.norm",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.deepstack_merger_list.1.linear_fc1",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.deepstack_merger_list.1.linear_fc2",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.deepstack_merger_list.1.norm",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.deepstack_merger_list.1.linear_fc1",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.deepstack_merger_list.1.linear_fc2",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.deepstack_merger_list.1.norm",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.deepstack_merger_list.2.linear_fc1",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.deepstack_merger_list.2.linear_fc2",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "model.visual.deepstack_merger_list.2.norm",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.deepstack_merger_list.2.linear_fc1",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.deepstack_merger_list.2.linear_fc2",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "visual.deepstack_merger_list.2.norm"
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]     ],
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]     "quant_method": "fp8",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]     "weight_block_size": [
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       128,
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       128
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]     ]
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]   },
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]   "text_config": {
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]     "attention_bias": false,
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]     "attention_dropout": 0.0,
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]     "bos_token_id": 151643,
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]     "dtype": "bfloat16",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]     "eos_token_id": 151645,
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]     "head_dim": 128,
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]     "hidden_act": "silu",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]     "hidden_size": 5120,
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]     "initializer_range": 0.02,
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]     "intermediate_size": 25600,
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]     "max_position_embeddings": 262144,
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]     "model_type": "qwen3_vl_text",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]     "num_attention_heads": 64,
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]     "num_hidden_layers": 64,
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]     "num_key_value_heads": 8,
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]     "rms_norm_eps": 1e-06,
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]     "rope_parameters": {
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "mrope_interleaved": true,
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "mrope_section": [
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]         24,
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]         20,
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]         20
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       ],
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "rope_theta": 5000000,
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "rope_type": "default"
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]     },
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]     "rope_scaling": {
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "mrope_interleaved": true,
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "mrope_section": [
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]         24,
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]         20,
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]         20
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       ],
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "rope_theta": 5000000,
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       "rope_type": "default"
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]     },
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]     "rope_theta": 5000000,
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]     "use_cache": true,
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]     "vocab_size": 151936
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]   },
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]   "tie_word_embeddings": false,
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]   "transformers_version": "4.57.6",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]   "video_token_id": 151656,
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]   "vision_config": {
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]     "deepstack_visual_indexes": [
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       8,
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       16,
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       24
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]     ],
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]     "depth": 27,
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]     "hidden_act": "gelu_pytorch_tanh",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]     "hidden_size": 1152,
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]     "in_channels": 3,
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]     "initializer_range": 0.02,
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]     "intermediate_size": 4304,
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]     "model_type": "qwen3_vl",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]     "num_heads": 16,
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]     "num_position_embeddings": 2304,
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]     "out_hidden_size": 5120,
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]     "patch_size": 16,
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]     "spatial_merge_size": 2,
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]     "temporal_patch_size": 2
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]   },
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]   "vision_end_token_id": 151653,
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]   "vision_start_token_id": 151652
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744] }
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744] , hf_text_config=Qwen3VLTextConfig {
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]   "attention_bias": false,
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]   "attention_dropout": 0.0,
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]   "bos_token_id": 151643,
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]   "dtype": "bfloat16",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]   "eos_token_id": 151645,
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]   "head_dim": 128,
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]   "hidden_act": "silu",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]   "hidden_size": 5120,
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]   "initializer_range": 0.02,
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]   "intermediate_size": 25600,
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]   "max_position_embeddings": 262144,
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]   "model_type": "qwen3_vl_text",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]   "num_attention_heads": 64,
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]   "num_hidden_layers": 64,
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]   "num_key_value_heads": 8,
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]   "rms_norm_eps": 1e-06,
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]   "rope_parameters": {
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]     "mrope_interleaved": true,
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]     "mrope_section": [
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       24,
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       20,
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       20
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]     ],
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]     "rope_theta": 5000000,
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]     "rope_type": "default"
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]   },
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]   "rope_scaling": {
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]     "mrope_interleaved": true,
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]     "mrope_section": [
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       24,
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       20,
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]       20
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]     ],
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]     "rope_theta": 5000000,
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]     "rope_type": "default"
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]   },
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]   "rope_theta": 5000000,
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]   "tie_word_embeddings": false,
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]   "transformers_version": "4.57.6",
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]   "use_cache": true,
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744]   "vocab_size": 151936
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744] }
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [hpu_model_runner.py:744] , hf_config_path=None, allowed_local_media_path='', allowed_media_domains=None, revision=None, code_revision=None, tokenizer_revision=None, max_model_len=32768, spec_target_max_model_len=None, quantization='fp8', allow_deprecated_quantization=False, enforce_eager=False, enable_return_routed_experts=False, max_logprobs=20, logprobs_mode='raw_logprobs', disable_sliding_window=False, disable_cascade_attn=False, skip_tokenizer_init=False, enable_prompt_embeds=False, served_model_name='/root/.cache/huggingface/hub/models--Qwen--Qwen3-VL-32B-Instruct-FP8/snapshots/4bf2c2f39c37c0fede78bede4056e1f18cdf8109/', config_format='auto', hf_token=None, hf_overrides={}, logits_processor_pattern=None, generation_config='auto', override_generation_config={}, enable_sleep_mode=False, model_impl='auto', override_attention_dtype=None, logits_processors=None, io_processor_plugin=None, pooler_config=None, multimodal_config=MultiModalConfig(limit_per_prompt={'image': ImageDummyOptions(count=20, width=864, height=480)}, enable_mm_embeds=False, media_io_kwargs={}, mm_processor_kwargs={'size': {'shortest_edge': 65536, 'longest_edge': 1048576}}, mm_processor_cache_gb=4.0, mm_processor_cache_type='lru', mm_shm_cache_max_object_size_mb=128, mm_encoder_tp_mode='weights', mm_encoder_attn_backend=None, interleave_mm_strings=False, skip_mm_profiling=False, video_pruning_rate=None))
[0;36m(EngineCore_DP0 pid=399683)[0;0m INFO 02-05 00:23:39 [platform.py:65] Using HPUAttentionV1 backend.
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [v1/sample/logits_processor/__init__.py:63] No logitsprocs plugins installed (group vllm.logits_processors).
[0;36m(EngineCore_DP0 pid=399683)[0;0m INFO 02-05 00:23:39 [hpu_model_runner.py:862] Bucketing is ON.
[0;36m(EngineCore_DP0 pid=399683)[0;0m INFO 02-05 00:23:39 [hpu_model_runner.py:3984] Starting to load model /root/.cache/huggingface/hub/models--Qwen--Qwen3-VL-32B-Instruct-FP8/snapshots/4bf2c2f39c37c0fede78bede4056e1f18cdf8109/...
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: Conv3dLayer using <class 'vllm_gaudi.ops.hpu_conv.HPUConv3dLayer'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RotaryEmbedding using <class 'vllm_gaudi.ops.hpu_rotary_embedding.HPURotaryEmbedding'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m INFO 02-05 00:23:39 [platforms/interface.py:267] Using default backend AttentionBackendEnum.TORCH_SDPA for vit attention
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m INFO 02-05 00:23:39 [model_executor/.../attention/mm_encoder_attention.py:86] Using AttentionBackendEnum.TORCH_SDPA for MMEncoderAttention.
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [utils/deep_gemm.py:86] DeepGEMM E8M0 disabled: DeepGEMM not supported on this system.
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: MRotaryEmbedding using <class 'vllm_gaudi.ops.hpu_rotary_embedding.HPUMRotaryEmbedding'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m INFO 02-05 00:23:39 [platform.py:65] Using HPUAttentionV1 backend.
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: Conv3dLayer using <class 'vllm_gaudi.ops.hpu_conv.HPUConv3dLayer'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [config/compilation.py:1035] enabled custom ops: Counter({'column_parallel_linear': 325, 'row_parallel_linear': 325, 'RMSNorm': 257, 'quant_fp8': 256, 'apply_rotary_emb': 137, 'MMEncoderAttention': 108, 'silu_and_mul': 64, 'Conv3dLayer': 2, 'RotaryEmbedding': 1, 'vocab_parallel_embedding': 1, 'MRotaryEmbedding': 1, 'parallel_lm_head': 1, 'logits_processor': 1})
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [config/compilation.py:1036] disabled custom ops: Counter()
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:39 [model_executor/model_loader/base_loader.py:56] Loading weights on hpu ...
[0;36m(EngineCore_DP0 pid=399683)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/7 [00:00<?, ?it/s]
[0;36m(EngineCore_DP0 pid=399683)[0;0m Loading safetensors checkpoint shards:  14% Completed | 1/7 [00:00<00:04,  1.46it/s]
[0;36m(EngineCore_DP0 pid=399683)[0;0m Loading safetensors checkpoint shards:  29% Completed | 2/7 [00:01<00:04,  1.08it/s]
[0;36m(EngineCore_DP0 pid=399683)[0;0m Loading safetensors checkpoint shards:  43% Completed | 3/7 [00:02<00:03,  1.03it/s]
[0;36m(EngineCore_DP0 pid=399683)[0;0m DEBUG 02-05 00:23:43 [model_executor/models/utils.py:220] Loaded weight lm_head.weight with shape torch.Size([151936, 5120])
[0;36m(EngineCore_DP0 pid=399683)[0;0m Loading safetensors checkpoint shards:  57% Completed | 4/7 [00:03<00:03,  1.05s/it]
[0;36m(EngineCore_DP0 pid=399683)[0;0m Loading safetensors checkpoint shards:  71% Completed | 5/7 [00:04<00:02,  1.02s/it]
[0;36m(EngineCore_DP0 pid=399683)[0;0m Loading safetensors checkpoint shards:  86% Completed | 6/7 [00:06<00:01,  1.06s/it]
[0;36m(APIServer pid=399008)[0;0m DEBUG 02-05 00:23:47 [v1/engine/utils.py:970] Waiting for 1 local, 0 remote core engine proc(s) to start.
[0;36m(EngineCore_DP0 pid=399683)[0;0m Loading safetensors checkpoint shards: 100% Completed | 7/7 [00:07<00:00,  1.11s/it]
[0;36m(EngineCore_DP0 pid=399683)[0;0m Loading safetensors checkpoint shards: 100% Completed | 7/7 [00:07<00:00,  1.04s/it]
[0;36m(EngineCore_DP0 pid=399683)[0;0m 
[0;36m(EngineCore_DP0 pid=399683)[0;0m INFO 02-05 00:23:47 [model_executor/model_loader/default_loader.py:291] Loading weights took 7.37 seconds
[0;36m(EngineCore_DP0 pid=399683)[0;0m INFO 02-05 00:23:47 [hpu_model_runner.py:3990] Loading model weights took 33.8518 GB
[0;36m(EngineCore_DP0 pid=399683)[0;0m INFO 02-05 00:23:48 [hpu_model_runner.py:4032] Wrapping in HPUGraph took 0.0000 GB
[0;36m(EngineCore_DP0 pid=399683)[0;0m INFO 02-05 00:23:48 [hpu_model_runner.py:4060] Compilation took 0.0000 GB
[0;36m(EngineCore_DP0 pid=399683)[0;0m INFO 02-05 00:23:48 [hpu_worker.py:250] Model profiling run took 0 B of device memory (33.92 GiB/126.5 GiB used) and -2.578 MiB of host memory (135.6 GiB/1007 GiB used)
[0;36m(EngineCore_DP0 pid=399683)[0;0m INFO 02-05 00:23:48 [hpu_worker.py:274] Free device memory: 92.62 GiB, 69.46 GiB usable (gpu_memory_utilization=0.75), 27.79 GiB reserved for HPUGraphs (VLLM_GRAPH_RESERVED_MEM=0.4), 32 MiB reserved for KV cache dummy block 41.65 GiB reserved for usable KV cache
[0;36m(EngineCore_DP0 pid=399683)[0;0m INFO 02-05 00:23:48 [v1/core/kv_cache_utils.py:1305] GPU KV cache size: 170,496 tokens
[0;36m(EngineCore_DP0 pid=399683)[0;0m INFO 02-05 00:23:48 [v1/core/kv_cache_utils.py:1310] Maximum concurrency for 32,768 tokens per request: 5.20x
[0;36m(EngineCore_DP0 pid=399683)[0;0m INFO 02-05 00:23:49 [hpu_worker.py:302] Usable num_blocks: 1332, actual allocated num_blocks: 170624 (_PAD_BLOCK_ID=0, _PAD_SLOT_ID=-1)
[0;36m(EngineCore_DP0 pid=399683)[0;0m INFO 02-05 00:23:49 [hpu_worker.py:305] Initializing cache engine took 41.66 GiB of device memory (75.55 GiB/126.5 GiB used) and 22.88 MiB of host memory (135.7 GiB/1007 GiB used)
[0;36m(EngineCore_DP0 pid=399683)[0;0m INFO 02-05 00:23:49 [linear.py:116] VLLM_PROMPT_BS_BUCKET_MIN=1 (default:1)
[0;36m(EngineCore_DP0 pid=399683)[0;0m INFO 02-05 00:23:49 [linear.py:116] VLLM_PROMPT_BS_BUCKET_STEP=1 (default:1)
[0;36m(EngineCore_DP0 pid=399683)[0;0m INFO 02-05 00:23:49 [linear.py:116] VLLM_PROMPT_BS_BUCKET_MAX=1 (default:1)
[0;36m(EngineCore_DP0 pid=399683)[0;0m WARNING 02-05 00:23:49 [linear.py:113] VLLM_PROMPT_QUERY_BUCKET_MIN not set, using VLLM_PROMPT_SEQ_BUCKET_MIN value (1024) instead. This fallback behavior is deprecated and will be removed in v0.12.0.
[0;36m(EngineCore_DP0 pid=399683)[0;0m INFO 02-05 00:23:49 [linear.py:116] VLLM_PROMPT_QUERY_BUCKET_MIN=1024 (default:128)
[0;36m(EngineCore_DP0 pid=399683)[0;0m WARNING 02-05 00:23:49 [linear.py:113] VLLM_PROMPT_QUERY_BUCKET_STEP not set, using VLLM_PROMPT_SEQ_BUCKET_STEP value (1024) instead. This fallback behavior is deprecated and will be removed in v0.12.0.
[0;36m(EngineCore_DP0 pid=399683)[0;0m INFO 02-05 00:23:49 [linear.py:116] VLLM_PROMPT_QUERY_BUCKET_STEP=1024 (default:128)
[0;36m(EngineCore_DP0 pid=399683)[0;0m WARNING 02-05 00:23:49 [linear.py:113] VLLM_PROMPT_QUERY_BUCKET_MAX not set, using VLLM_PROMPT_SEQ_BUCKET_MAX value (20480) instead. This fallback behavior is deprecated and will be removed in v0.12.0.
[0;36m(EngineCore_DP0 pid=399683)[0;0m INFO 02-05 00:23:49 [linear.py:116] VLLM_PROMPT_QUERY_BUCKET_MAX=20480 (default:1024)
[0;36m(EngineCore_DP0 pid=399683)[0;0m INFO 02-05 00:23:49 [linear.py:116] VLLM_PROMPT_CTX_BUCKET_MIN=0 (default:0)
[0;36m(EngineCore_DP0 pid=399683)[0;0m INFO 02-05 00:23:49 [linear.py:116] VLLM_PROMPT_CTX_BUCKET_STEP=12 (default:1)
[0;36m(EngineCore_DP0 pid=399683)[0;0m INFO 02-05 00:23:49 [linear.py:116] VLLM_PROMPT_CTX_BUCKET_MAX=24 (default:248)
[0;36m(EngineCore_DP0 pid=399683)[0;0m INFO 02-05 00:23:49 [linear.py:52] Prompt bucket config (min, step, max_warmup) bs:[1, 1, 1], query:[1024, 1024, 20480], blocks:[0, 12, 24]
[0;36m(EngineCore_DP0 pid=399683)[0;0m INFO 02-05 00:23:49 [common.py:222] Generated 3 prompt buckets [bs, query, num_blocks]: [(1, 1024, 0), (1, 1024, 12), (1, 1024, 248)]
[0;36m(EngineCore_DP0 pid=399683)[0;0m INFO 02-05 00:23:49 [linear.py:116] VLLM_DECODE_BS_BUCKET_MIN=1 (default:1)
[0;36m(EngineCore_DP0 pid=399683)[0;0m INFO 02-05 00:23:49 [linear.py:116] VLLM_DECODE_BS_BUCKET_STEP=4 (default:32)
[0;36m(EngineCore_DP0 pid=399683)[0;0m INFO 02-05 00:23:49 [linear.py:116] VLLM_DECODE_BS_BUCKET_MAX=64 (default:32768)
[0;36m(EngineCore_DP0 pid=399683)[0;0m INFO 02-05 00:23:49 [linear.py:116] VLLM_DECODE_BLOCK_BUCKET_MIN=256 (default:1)
[0;36m(EngineCore_DP0 pid=399683)[0;0m INFO 02-05 00:23:49 [linear.py:116] VLLM_DECODE_BLOCK_BUCKET_STEP=128 (default:128)
[0;36m(EngineCore_DP0 pid=399683)[0;0m INFO 02-05 00:23:49 [linear.py:116] VLLM_DECODE_BLOCK_BUCKET_MAX=1152 (default:1332)
[0;36m(EngineCore_DP0 pid=399683)[0;0m INFO 02-05 00:23:49 [linear.py:81] Decode bucket config (min, step, max_warmup) bs:[1, 4, 64], blocks:[256, 128, 1152]
[0;36m(EngineCore_DP0 pid=399683)[0;0m INFO 02-05 00:23:49 [common.py:222] Generated 162 decode buckets [bs, query, num_blocks]: [(1, 1, 256), (1, 1, 384), (1, 1, 512), (1, 1, 640), (1, 1, 768), (1, 1, 896), (1, 1, 1024), (1, 1, 1152), (1, 1, 1332), (2, 1, 256), (2, 1, 384), (2, 1, 512), (2, 1, 640), (2, 1, 768), (2, 1, 896), (2, 1, 1024), (2, 1, 1152), (2, 1, 1332), (4, 1, 256), (4, 1, 384), (4, 1, 512), (4, 1, 640), (4, 1, 768), (4, 1, 896), (4, 1, 1024), (4, 1, 1152), (4, 1, 1332), (8, 1, 256), (8, 1, 384), (8, 1, 512), (8, 1, 640), (8, 1, 768), (8, 1, 896), (8, 1, 1024), (8, 1, 1152), (8, 1, 1332), (12, 1, 256), (12, 1, 384), (12, 1, 512), (12, 1, 640), (12, 1, 768), (12, 1, 896), (12, 1, 1024), (12, 1, 1152), (12, 1, 1332), (16, 1, 256), (16, 1, 384), (16, 1, 512), (16, 1, 640), (16, 1, 768), (16, 1, 896), (16, 1, 1024), (16, 1, 1152), (16, 1, 1332), (20, 1, 256), (20, 1, 384), (20, 1, 512), (20, 1, 640), (20, 1, 768), (20, 1, 896), (20, 1, 1024), (20, 1, 1152), (20, 1, 1332), (24, 1, 256), (24, 1, 384), (24, 1, 512), (24, 1, 640), (24, 1, 768), (24, 1, 896), (24, 1, 1024), (24, 1, 1152), (24, 1, 1332), (28, 1, 256), (28, 1, 384), (28, 1, 512), (28, 1, 640), (28, 1, 768), (28, 1, 896), (28, 1, 1024), (28, 1, 1152), (28, 1, 1332), (32, 1, 256), (32, 1, 384), (32, 1, 512), (32, 1, 640), (32, 1, 768), (32, 1, 896), (32, 1, 1024), (32, 1, 1152), (32, 1, 1332), (36, 1, 256), (36, 1, 384), (36, 1, 512), (36, 1, 640), (36, 1, 768), (36, 1, 896), (36, 1, 1024), (36, 1, 1152), (36, 1, 1332), (40, 1, 256), (40, 1, 384), (40, 1, 512), (40, 1, 640), (40, 1, 768), (40, 1, 896), (40, 1, 1024), (40, 1, 1152), (40, 1, 1332), (44, 1, 256), (44, 1, 384), (44, 1, 512), (44, 1, 640), (44, 1, 768), (44, 1, 896), (44, 1, 1024), (44, 1, 1152), (44, 1, 1332), (48, 1, 256), (48, 1, 384), (48, 1, 512), (48, 1, 640), (48, 1, 768), (48, 1, 896), (48, 1, 1024), (48, 1, 1152), (48, 1, 1332), (52, 1, 256), (52, 1, 384), (52, 1, 512), (52, 1, 640), (52, 1, 768), (52, 1, 896), (52, 1, 1024), (52, 1, 1152), (52, 1, 1332), (56, 1, 256), (56, 1, 384), (56, 1, 512), (56, 1, 640), (56, 1, 768), (56, 1, 896), (56, 1, 1024), (56, 1, 1152), (56, 1, 1332), (60, 1, 256), (60, 1, 384), (60, 1, 512), (60, 1, 640), (60, 1, 768), (60, 1, 896), (60, 1, 1024), (60, 1, 1152), (60, 1, 1332), (64, 1, 256), (64, 1, 384), (64, 1, 512), (64, 1, 640), (64, 1, 768), (64, 1, 896), (64, 1, 1024), (64, 1, 1152), (64, 1, 1332)]
[0;36m(EngineCore_DP0 pid=399683)[0;0m INFO 02-05 00:23:49 [hpu_model_runner.py:5018] Multimodal bucket : [196, 256, 441, 480, 576, 900, 1156]
[0;36m(EngineCore_DP0 pid=399683)[0;0m [rank0]:I0205 00:23:49.374000 399683 torch/_dynamo/utils.py:1749] [0/0] ChromiumEventLogger initialized with id 2b7083f0-8c80-44a4-b78c-dde8b43868b1
[0;36m(EngineCore_DP0 pid=399683)[0;0m [rank0]:I0205 00:23:49.378000 399683 torch/_dynamo/symbolic_convert.py:3842] [0/0] Step 1: torchdynamo start tracing forward /root/migration/vllm/vllm/model_executor/custom_op.py:46
[0;36m(EngineCore_DP0 pid=399683)[0;0m [rank0]:I0205 00:23:49.379000 399683 torch/fx/experimental/symbolic_shapes.py:3769] [0/0] create_env
[0;36m(EngineCore_DP0 pid=399683)[0;0m [rank0]:I0205 00:23:49.403000 399683 torch/_dynamo/symbolic_convert.py:4059] [0/0] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[0;36m(EngineCore_DP0 pid=399683)[0;0m [rank0]:I0205 00:23:49.405000 399683 torch/_dynamo/output_graph.py:2167] [0/0] Step 2: calling compiler function hpu_backend
[0;36m(EngineCore_DP0 pid=399683)[0;0m [rank0]:I0205 00:23:49.429000 399683 torch/_dynamo/output_graph.py:2172] [0/0] Step 2: done compiler function hpu_backend
[0;36m(EngineCore_DP0 pid=399683)[0;0m [rank0]:I0205 00:23:49.433000 399683 torch/fx/experimental/symbolic_shapes.py:5242] [0/0] produce_guards
[0;36m(EngineCore_DP0 pid=399683)[0;0m [rank0]:I0205 00:23:49.451000 399683 torch/_dynamo/pgo.py:893] [0/0] put_code_state: no cache key, skipping
[0;36m(EngineCore_DP0 pid=399683)[0;0m [rank0]:I0205 00:23:49.451000 399683 torch/_dynamo/convert_frame.py:1501] [0/0] run_gc_after_compile: running gc
[0;36m(EngineCore_DP0 pid=399683)[0;0m [rank0]:I0205 00:23:49.458000 399683 torch/_dynamo/symbolic_convert.py:3842] [1/0] Step 1: torchdynamo start tracing prepare_cos_sin /root/migration/vllm-gaudi/vllm_gaudi/ops/hpu_rotary_embedding.py:17
[0;36m(EngineCore_DP0 pid=399683)[0;0m [rank0]:I0205 00:23:49.458000 399683 torch/fx/experimental/symbolic_shapes.py:3769] [1/0] create_env
[0;36m(EngineCore_DP0 pid=399683)[0;0m [rank0]:I0205 00:23:49.488000 399683 torch/_dynamo/symbolic_convert.py:4059] [1/0] Step 1: torchdynamo done tracing prepare_cos_sin (RETURN_CONST)
[0;36m(EngineCore_DP0 pid=399683)[0;0m [rank0]:I0205 00:23:49.491000 399683 torch/_dynamo/output_graph.py:2167] [1/0] Step 2: calling compiler function hpu_backend
[0;36m(EngineCore_DP0 pid=399683)[0;0m [rank0]:I0205 00:23:49.524000 399683 torch/_dynamo/output_graph.py:2172] [1/0] Step 2: done compiler function hpu_backend
[0;36m(EngineCore_DP0 pid=399683)[0;0m [rank0]:I0205 00:23:49.527000 399683 torch/fx/experimental/symbolic_shapes.py:5242] [1/0] produce_guards
[0;36m(EngineCore_DP0 pid=399683)[0;0m [rank0]:I0205 00:23:49.546000 399683 torch/_dynamo/pgo.py:893] [1/0] put_code_state: no cache key, skipping
[0;36m(EngineCore_DP0 pid=399683)[0;0m [rank0]:I0205 00:23:49.546000 399683 torch/_dynamo/convert_frame.py:1501] [1/0] run_gc_after_compile: running gc
[0;36m(EngineCore_DP0 pid=399683)[0;0m [rank0]:I0205 00:23:49.552000 399683 torch/_dynamo/symbolic_convert.py:3842] [2/0] Step 1: torchdynamo start tracing forward /root/migration/vllm/vllm/model_executor/models/qwen3.py:208
[0;36m(EngineCore_DP0 pid=399683)[0;0m [rank0]:I0205 00:23:49.553000 399683 torch/fx/experimental/symbolic_shapes.py:3769] [2/0] create_env
[0;36m(EngineCore_DP0 pid=399683)[0;0m /usr/local/lib/python3.12/dist-packages/torch/_dynamo/variables/functions.py:1692: UserWarning: Dynamo detected a call to a `functools.lru_cache`-wrapped function. Dynamo ignores the cache wrapper and directly traces the wrapped function. Silent incorrectness is only a *potential* risk, not something we have observed. Enable TORCH_LOGS="+dynamo" for a DEBUG stack trace.
[0;36m(EngineCore_DP0 pid=399683)[0;0m   torch._dynamo.utils.warn_once(msg)
[0;36m(EngineCore_DP0 pid=399683)[0;0m [rank0]:I0205 00:23:49.799000 399683 torch/_dynamo/symbolic_convert.py:4059] [2/0] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[0;36m(EngineCore_DP0 pid=399683)[0;0m [rank0]:I0205 00:23:49.809000 399683 torch/_dynamo/output_graph.py:2167] [2/0] Step 2: calling compiler function hpu_backend
[0;36m(EngineCore_DP0 pid=399683)[0;0m [rank0]:I0205 00:23:49.998000 399683 torch/_dynamo/output_graph.py:2172] [2/0] Step 2: done compiler function hpu_backend
[0;36m(EngineCore_DP0 pid=399683)[0;0m [rank0]:I0205 00:23:50.023000 399683 torch/fx/experimental/symbolic_shapes.py:5242] [2/0] produce_guards
[0;36m(EngineCore_DP0 pid=399683)[0;0m [rank0]:I0205 00:23:50.066000 399683 torch/_dynamo/pgo.py:893] [2/0] put_code_state: no cache key, skipping
[0;36m(EngineCore_DP0 pid=399683)[0;0m [rank0]:I0205 00:23:50.066000 399683 torch/_dynamo/convert_frame.py:1501] [2/0] run_gc_after_compile: running gc
[0;36m(EngineCore_DP0 pid=399683)[0;0m [rank0]:I0205 00:23:50.074000 399683 torch/_dynamo/symbolic_convert.py:3842] [3/0] Step 1: torchdynamo start tracing forward_hook /root/migration/vllm-gaudi/vllm_gaudi/v1/worker/hpu_model_runner.py:348
[0;36m(EngineCore_DP0 pid=399683)[0;0m [rank0]:I0205 00:23:50.074000 399683 torch/fx/experimental/symbolic_shapes.py:3769] [3/0] create_env
[0;36m(EngineCore_DP0 pid=399683)[0;0m [rank0]:I0205 00:23:50.077000 399683 torch/_dynamo/pgo.py:893] [3/0] put_code_state: no cache key, skipping
[0;36m(EngineCore_DP0 pid=399683)[0;0m [rank0]:I0205 00:23:50.077000 399683 torch/_dynamo/convert_frame.py:1501] [3/0] run_gc_after_compile: running gc
[0;36m(EngineCore_DP0 pid=399683)[0;0m [rank0]:I0205 00:23:50.080000 399683 torch/_dynamo/symbolic_convert.py:3842] [2/1] Step 1: torchdynamo start tracing forward /root/migration/vllm/vllm/model_executor/models/qwen3.py:208
[0;36m(EngineCore_DP0 pid=399683)[0;0m [rank0]:I0205 00:23:50.081000 399683 torch/fx/experimental/symbolic_shapes.py:3769] [2/1] create_env
[0;36m(EngineCore_DP0 pid=399683)[0;0m [rank0]:I0205 00:23:50.238000 399683 torch/_dynamo/symbolic_convert.py:4059] [2/1] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[0;36m(EngineCore_DP0 pid=399683)[0;0m [rank0]:I0205 00:23:50.248000 399683 torch/_dynamo/output_graph.py:2167] [2/1] Step 2: calling compiler function hpu_backend
[0;36m(EngineCore_DP0 pid=399683)[0;0m [rank0]:I0205 00:23:50.427000 399683 torch/_dynamo/output_graph.py:2172] [2/1] Step 2: done compiler function hpu_backend
[0;36m(EngineCore_DP0 pid=399683)[0;0m [rank0]:I0205 00:23:50.451000 399683 torch/fx/experimental/symbolic_shapes.py:5242] [2/1] produce_guards
[0;36m(EngineCore_DP0 pid=399683)[0;0m [rank0]:I0205 00:23:50.494000 399683 torch/_dynamo/pgo.py:893] [2/1] put_code_state: no cache key, skipping
[0;36m(EngineCore_DP0 pid=399683)[0;0m [rank0]:I0205 00:23:50.494000 399683 torch/_dynamo/convert_frame.py:1501] [2/1] run_gc_after_compile: running gc
[0;36m(EngineCore_DP0 pid=399683)[0;0m [rank0]:I0205 00:23:50.507000 399683 torch/_dynamo/symbolic_convert.py:3842] [0/1] Step 1: torchdynamo start tracing forward /root/migration/vllm/vllm/model_executor/custom_op.py:46
[0;36m(EngineCore_DP0 pid=399683)[0;0m [rank0]:I0205 00:23:50.508000 399683 torch/fx/experimental/symbolic_shapes.py:3769] [0/1] create_env
[0;36m(EngineCore_DP0 pid=399683)[0;0m [rank0]:I0205 00:23:50.538000 399683 torch/fx/experimental/symbolic_shapes.py:5114] [0/1] create_symbol s33 = 1024 for L['args'][0].size()[0] [2, int_oo] orig_shape = x.shape  # oot/migration/vllm-gaudi/vllm_gaudi/ops/hpu_layernorm.py:18 in forward_oot (_dynamo/variables/builder.py:3508 in <lambda>), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_CREATE_SYMBOL="s33" or to suppress this message run with TORCHDYNAMO_EXTENDED_ADVICE="0"
[0;36m(EngineCore_DP0 pid=399683)[0;0m [rank0]:I0205 00:23:50.540000 399683 torch/fx/experimental/symbolic_shapes.py:5114] [0/1] create_symbol s50 = 5120 for L['args'][0].size()[1] [2, int_oo] orig_shape = x.shape  # oot/migration/vllm-gaudi/vllm_gaudi/ops/hpu_layernorm.py:18 in forward_oot (_dynamo/variables/builder.py:3508 in <lambda>), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_CREATE_SYMBOL="s50" or to suppress this message run with TORCHDYNAMO_EXTENDED_ADVICE="0"
[0;36m(EngineCore_DP0 pid=399683)[0;0m [rank0]:I0205 00:23:50.553000 399683 torch/fx/experimental/symbolic_shapes.py:7207] [0/1] eval Eq(s33*s50, 5242880) [guard added] residual = residual + x.view(residual.shape)  # oot/migration/vllm-gaudi/vllm_gaudi/ops/hpu_layernorm.py:19 in forward_oot (_prims_common/__init__.py:1044 in infer_size), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_GUARD_ADDED="Eq(s33*s50, 5242880)"
[0;36m(EngineCore_DP0 pid=399683)[0;0m [rank0]:I0205 00:23:50.564000 399683 torch/fx/experimental/symbolic_shapes.py:7207] [0/1] eval Eq(s33, 1024) [guard added] residual = residual + x.view(residual.shape)  # oot/migration/vllm-gaudi/vllm_gaudi/ops/hpu_layernorm.py:19 in forward_oot (_refs/__init__.py:3828 in _reshape_view_helper_core_alg), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_GUARD_ADDED="Eq(s33, 1024)"
[0;36m(EngineCore_DP0 pid=399683)[0;0m [rank0]:I0205 00:23:50.566000 399683 torch/fx/experimental/symbolic_shapes.py:6786] [0/1] set_replacement s33 = 1024 (range_refined_to_singleton) VR[1024, 1024]
[0;36m(EngineCore_DP0 pid=399683)[0;0m [rank0]:I0205 00:23:50.569000 399683 torch/fx/experimental/symbolic_shapes.py:7207] [0/1] eval Eq(s50, 5120) [guard added] residual = residual + x.view(residual.shape)  # oot/migration/vllm-gaudi/vllm_gaudi/ops/hpu_layernorm.py:19 in forward_oot (_refs/__init__.py:3828 in _reshape_view_helper_core_alg), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_GUARD_ADDED="Eq(s50, 5120)"
[0;36m(EngineCore_DP0 pid=399683)[0;0m [rank0]:I0205 00:23:50.570000 399683 torch/fx/experimental/symbolic_shapes.py:6786] [0/1] set_replacement s50 = 5120 (range_refined_to_singleton) VR[5120, 5120]
[0;36m(EngineCore_DP0 pid=399683)[0;0m [rank0]:I0205 00:23:50.576000 399683 torch/fx/experimental/symbolic_shapes.py:5114] [0/1] create_symbol s39 = 5120 for L['self']._parameters['weight'].size()[0] [2, int_oo] x = HPUFusedRMSNorm.apply(residual, self.weight, self.variance_epsilon)  # oot/migration/vllm-gaudi/vllm_gaudi/ops/hpu_layernorm.py:21 in forward_oot (_dynamo/variables/builder.py:3508 in <lambda>), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_CREATE_SYMBOL="s39" or to suppress this message run with TORCHDYNAMO_EXTENDED_ADVICE="0"
[0;36m(EngineCore_DP0 pid=399683)[0;0m [rank0]:I0205 00:23:50.581000 399683 torch/_dynamo/symbolic_convert.py:4059] [0/1] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[0;36m(EngineCore_DP0 pid=399683)[0;0m [rank0]:I0205 00:23:50.584000 399683 torch/_dynamo/output_graph.py:2167] [0/1] Step 2: calling compiler function hpu_backend
[0;36m(EngineCore_DP0 pid=399683)[0;0m [rank0]:I0205 00:23:50.618000 399683 torch/_dynamo/output_graph.py:2172] [0/1] Step 2: done compiler function hpu_backend
[0;36m(EngineCore_DP0 pid=399683)[0;0m [rank0]:I0205 00:23:50.623000 399683 torch/fx/experimental/symbolic_shapes.py:5242] [0/1] produce_guards
[0;36m(APIServer pid=399008)[0;0m DEBUG 02-05 00:23:57 [v1/engine/utils.py:970] Waiting for 1 local, 0 remote core engine proc(s) to start.
[0;36m(APIServer pid=399008)[0;0m DEBUG 02-05 00:24:07 [v1/engine/utils.py:970] Waiting for 1 local, 0 remote core engine proc(s) to start.
[0;36m(EngineCore_DP0 pid=399683)[0;0m [rank0]:I0205 00:24:11.880000 399683 torch/_dynamo/pgo.py:893] [0/1] put_code_state: no cache key, skipping
[0;36m(EngineCore_DP0 pid=399683)[0;0m [rank0]:I0205 00:24:11.881000 399683 torch/_dynamo/convert_frame.py:1501] [0/1] run_gc_after_compile: running gc
[0;36m(EngineCore_DP0 pid=399683)[0;0m [rank0]:I0205 00:24:11.960000 399683 torch/_dynamo/symbolic_convert.py:3842] [4/0] Step 1: torchdynamo start tracing forward /root/migration/vllm/vllm/v1/sample/sampler.py:67
[0;36m(EngineCore_DP0 pid=399683)[0;0m [rank0]:I0205 00:24:11.960000 399683 torch/fx/experimental/symbolic_shapes.py:3769] [4/0] create_env
[0;36m(EngineCore_DP0 pid=399683)[0;0m [rank0]:I0205 00:24:11.982000 399683 torch/_dynamo/symbolic_convert.py:4059] [4/0] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[0;36m(EngineCore_DP0 pid=399683)[0;0m [rank0]:I0205 00:24:11.984000 399683 torch/_dynamo/output_graph.py:2167] [4/0] Step 2: calling compiler function hpu_backend
[0;36m(EngineCore_DP0 pid=399683)[0;0m [rank0]:I0205 00:24:12.008000 399683 torch/_dynamo/output_graph.py:2172] [4/0] Step 2: done compiler function hpu_backend
[0;36m(EngineCore_DP0 pid=399683)[0;0m [rank0]:I0205 00:24:12.012000 399683 torch/fx/experimental/symbolic_shapes.py:5242] [4/0] produce_guards
[0;36m(EngineCore_DP0 pid=399683)[0;0m [rank0]:I0205 00:24:12.030000 399683 torch/_dynamo/pgo.py:893] [4/0] put_code_state: no cache key, skipping
[0;36m(EngineCore_DP0 pid=399683)[0;0m [rank0]:I0205 00:24:12.030000 399683 torch/_dynamo/convert_frame.py:1501] [4/0] run_gc_after_compile: running gc
[0;36m(APIServer pid=399008)[0;0m DEBUG 02-05 00:24:17 [v1/engine/utils.py:970] Waiting for 1 local, 0 remote core engine proc(s) to start.
[0;36m(APIServer pid=399008)[0;0m DEBUG 02-05 00:24:27 [v1/engine/utils.py:970] Waiting for 1 local, 0 remote core engine proc(s) to start.
[0;36m(EngineCore_DP0 pid=399683)[0;0m ERROR 02-05 00:24:33 [v1/engine/core.py:936] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=399683)[0;0m ERROR 02-05 00:24:33 [v1/engine/core.py:936] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=399683)[0;0m ERROR 02-05 00:24:33 [v1/engine/core.py:936]   File "/root/migration/vllm/vllm/v1/engine/core.py", line 927, in run_engine_core
[0;36m(EngineCore_DP0 pid=399683)[0;0m ERROR 02-05 00:24:33 [v1/engine/core.py:936]     engine_core = EngineCoreProc(*args, engine_index=dp_rank, **kwargs)
[0;36m(EngineCore_DP0 pid=399683)[0;0m ERROR 02-05 00:24:33 [v1/engine/core.py:936]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=399683)[0;0m ERROR 02-05 00:24:33 [v1/engine/core.py:936]   File "/root/migration/vllm/vllm/v1/engine/core.py", line 692, in __init__
[0;36m(EngineCore_DP0 pid=399683)[0;0m ERROR 02-05 00:24:33 [v1/engine/core.py:936]     super().__init__(
[0;36m(EngineCore_DP0 pid=399683)[0;0m ERROR 02-05 00:24:33 [v1/engine/core.py:936]   File "/root/migration/vllm/vllm/v1/engine/core.py", line 113, in __init__
[0;36m(EngineCore_DP0 pid=399683)[0;0m ERROR 02-05 00:24:33 [v1/engine/core.py:936]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[0;36m(EngineCore_DP0 pid=399683)[0;0m ERROR 02-05 00:24:33 [v1/engine/core.py:936]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=399683)[0;0m ERROR 02-05 00:24:33 [v1/engine/core.py:936]   File "/root/migration/vllm/vllm/v1/engine/core.py", line 270, in _initialize_kv_caches
[0;36m(EngineCore_DP0 pid=399683)[0;0m ERROR 02-05 00:24:33 [v1/engine/core.py:936]     self.model_executor.initialize_from_config(kv_cache_configs)
[0;36m(EngineCore_DP0 pid=399683)[0;0m ERROR 02-05 00:24:33 [v1/engine/core.py:936]   File "/root/migration/vllm/vllm/v1/executor/abstract.py", line 115, in initialize_from_config
[0;36m(EngineCore_DP0 pid=399683)[0;0m ERROR 02-05 00:24:33 [v1/engine/core.py:936]     self.collective_rpc("initialize_from_config", args=(kv_cache_configs,))
[0;36m(EngineCore_DP0 pid=399683)[0;0m ERROR 02-05 00:24:33 [v1/engine/core.py:936]   File "/root/migration/vllm/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[0;36m(EngineCore_DP0 pid=399683)[0;0m ERROR 02-05 00:24:33 [v1/engine/core.py:936]     result = run_method(self.driver_worker, method, args, kwargs)
[0;36m(EngineCore_DP0 pid=399683)[0;0m ERROR 02-05 00:24:33 [v1/engine/core.py:936]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=399683)[0;0m ERROR 02-05 00:24:33 [v1/engine/core.py:936]   File "/root/migration/vllm/vllm/v1/serial_utils.py", line 461, in run_method
[0;36m(EngineCore_DP0 pid=399683)[0;0m ERROR 02-05 00:24:33 [v1/engine/core.py:936]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=399683)[0;0m ERROR 02-05 00:24:33 [v1/engine/core.py:936]            ^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=399683)[0;0m ERROR 02-05 00:24:33 [v1/engine/core.py:936]   File "/root/migration/vllm/vllm/v1/worker/worker_base.py", line 320, in initialize_from_config
[0;36m(EngineCore_DP0 pid=399683)[0;0m ERROR 02-05 00:24:33 [v1/engine/core.py:936]     self.worker.initialize_from_config(kv_cache_config)  # type: ignore
[0;36m(EngineCore_DP0 pid=399683)[0;0m ERROR 02-05 00:24:33 [v1/engine/core.py:936]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=399683)[0;0m ERROR 02-05 00:24:33 [v1/engine/core.py:936]   File "/root/migration/vllm-gaudi/vllm_gaudi/v1/worker/hpu_worker.py", line 306, in initialize_from_config
[0;36m(EngineCore_DP0 pid=399683)[0;0m ERROR 02-05 00:24:33 [v1/engine/core.py:936]     self.compile_or_warm_up_model()
[0;36m(EngineCore_DP0 pid=399683)[0;0m ERROR 02-05 00:24:33 [v1/engine/core.py:936]   File "/root/migration/vllm-gaudi/vllm_gaudi/v1/worker/hpu_worker.py", line 311, in compile_or_warm_up_model
[0;36m(EngineCore_DP0 pid=399683)[0;0m ERROR 02-05 00:24:33 [v1/engine/core.py:936]     self.model_runner.warmup_model()
[0;36m(EngineCore_DP0 pid=399683)[0;0m ERROR 02-05 00:24:33 [v1/engine/core.py:936]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[0;36m(EngineCore_DP0 pid=399683)[0;0m ERROR 02-05 00:24:33 [v1/engine/core.py:936]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=399683)[0;0m ERROR 02-05 00:24:33 [v1/engine/core.py:936]            ^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=399683)[0;0m ERROR 02-05 00:24:33 [v1/engine/core.py:936]   File "/root/migration/vllm-gaudi/vllm_gaudi/v1/worker/hpu_model_runner.py", line 5047, in warmup_model
[0;36m(EngineCore_DP0 pid=399683)[0;0m ERROR 02-05 00:24:33 [v1/engine/core.py:936]     raise AssertionError("Finished profiling")
[0;36m(EngineCore_DP0 pid=399683)[0;0m ERROR 02-05 00:24:33 [v1/engine/core.py:936] AssertionError: Finished profiling
[0;36m(EngineCore_DP0 pid=399683)[0;0m Process EngineCore_DP0:
[0;36m(EngineCore_DP0 pid=399683)[0;0m Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=399683)[0;0m   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[0;36m(EngineCore_DP0 pid=399683)[0;0m     self.run()
[0;36m(EngineCore_DP0 pid=399683)[0;0m   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
[0;36m(EngineCore_DP0 pid=399683)[0;0m     self._target(*self._args, **self._kwargs)
[0;36m(EngineCore_DP0 pid=399683)[0;0m   File "/root/migration/vllm/vllm/v1/engine/core.py", line 940, in run_engine_core
[0;36m(EngineCore_DP0 pid=399683)[0;0m     raise e
[0;36m(EngineCore_DP0 pid=399683)[0;0m   File "/root/migration/vllm/vllm/v1/engine/core.py", line 927, in run_engine_core
[0;36m(EngineCore_DP0 pid=399683)[0;0m     engine_core = EngineCoreProc(*args, engine_index=dp_rank, **kwargs)
[0;36m(EngineCore_DP0 pid=399683)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=399683)[0;0m   File "/root/migration/vllm/vllm/v1/engine/core.py", line 692, in __init__
[0;36m(EngineCore_DP0 pid=399683)[0;0m     super().__init__(
[0;36m(EngineCore_DP0 pid=399683)[0;0m   File "/root/migration/vllm/vllm/v1/engine/core.py", line 113, in __init__
[0;36m(EngineCore_DP0 pid=399683)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[0;36m(EngineCore_DP0 pid=399683)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=399683)[0;0m   File "/root/migration/vllm/vllm/v1/engine/core.py", line 270, in _initialize_kv_caches
[0;36m(EngineCore_DP0 pid=399683)[0;0m     self.model_executor.initialize_from_config(kv_cache_configs)
[0;36m(EngineCore_DP0 pid=399683)[0;0m   File "/root/migration/vllm/vllm/v1/executor/abstract.py", line 115, in initialize_from_config
[0;36m(EngineCore_DP0 pid=399683)[0;0m     self.collective_rpc("initialize_from_config", args=(kv_cache_configs,))
[0;36m(EngineCore_DP0 pid=399683)[0;0m   File "/root/migration/vllm/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[0;36m(EngineCore_DP0 pid=399683)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[0;36m(EngineCore_DP0 pid=399683)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=399683)[0;0m   File "/root/migration/vllm/vllm/v1/serial_utils.py", line 461, in run_method
[0;36m(EngineCore_DP0 pid=399683)[0;0m     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=399683)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=399683)[0;0m   File "/root/migration/vllm/vllm/v1/worker/worker_base.py", line 320, in initialize_from_config
[0;36m(EngineCore_DP0 pid=399683)[0;0m     self.worker.initialize_from_config(kv_cache_config)  # type: ignore
[0;36m(EngineCore_DP0 pid=399683)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=399683)[0;0m   File "/root/migration/vllm-gaudi/vllm_gaudi/v1/worker/hpu_worker.py", line 306, in initialize_from_config
[0;36m(EngineCore_DP0 pid=399683)[0;0m     self.compile_or_warm_up_model()
[0;36m(EngineCore_DP0 pid=399683)[0;0m   File "/root/migration/vllm-gaudi/vllm_gaudi/v1/worker/hpu_worker.py", line 311, in compile_or_warm_up_model
[0;36m(EngineCore_DP0 pid=399683)[0;0m     self.model_runner.warmup_model()
[0;36m(EngineCore_DP0 pid=399683)[0;0m   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[0;36m(EngineCore_DP0 pid=399683)[0;0m     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=399683)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=399683)[0;0m   File "/root/migration/vllm-gaudi/vllm_gaudi/v1/worker/hpu_model_runner.py", line 5047, in warmup_model
[0;36m(EngineCore_DP0 pid=399683)[0;0m     raise AssertionError("Finished profiling")
[0;36m(EngineCore_DP0 pid=399683)[0;0m AssertionError: Finished profiling
[0;36m(EngineCore_DP0 pid=399683)[0;0m I0205 00:24:34.492000 399683 torch/_dynamo/eval_frame.py:563] TorchDynamo attempted to trace the following frames: [
[0;36m(EngineCore_DP0 pid=399683)[0;0m I0205 00:24:34.492000 399683 torch/_dynamo/eval_frame.py:563]   * forward /root/migration/vllm/vllm/model_executor/custom_op.py:46
[0;36m(EngineCore_DP0 pid=399683)[0;0m I0205 00:24:34.492000 399683 torch/_dynamo/eval_frame.py:563]   * prepare_cos_sin /root/migration/vllm-gaudi/vllm_gaudi/ops/hpu_rotary_embedding.py:17
[0;36m(EngineCore_DP0 pid=399683)[0;0m I0205 00:24:34.492000 399683 torch/_dynamo/eval_frame.py:563]   * forward /root/migration/vllm/vllm/model_executor/models/qwen3.py:208
[0;36m(EngineCore_DP0 pid=399683)[0;0m I0205 00:24:34.492000 399683 torch/_dynamo/eval_frame.py:563]   * forward_hook /root/migration/vllm-gaudi/vllm_gaudi/v1/worker/hpu_model_runner.py:348
[0;36m(EngineCore_DP0 pid=399683)[0;0m I0205 00:24:34.492000 399683 torch/_dynamo/eval_frame.py:563]   * forward /root/migration/vllm/vllm/model_executor/models/qwen3.py:208
[0;36m(EngineCore_DP0 pid=399683)[0;0m I0205 00:24:34.492000 399683 torch/_dynamo/eval_frame.py:563]   * forward /root/migration/vllm/vllm/model_executor/custom_op.py:46
[0;36m(EngineCore_DP0 pid=399683)[0;0m I0205 00:24:34.492000 399683 torch/_dynamo/eval_frame.py:563]   * forward /root/migration/vllm/vllm/v1/sample/sampler.py:67
[0;36m(EngineCore_DP0 pid=399683)[0;0m I0205 00:24:34.492000 399683 torch/_dynamo/eval_frame.py:563] ]
[0;36m(EngineCore_DP0 pid=399683)[0;0m I0205 00:24:34.498000 399683 torch/_dynamo/utils.py:845] TorchDynamo compilation metrics:
[0;36m(EngineCore_DP0 pid=399683)[0;0m I0205 00:24:34.498000 399683 torch/_dynamo/utils.py:845] Function                          Runtimes (s)
[0;36m(EngineCore_DP0 pid=399683)[0;0m I0205 00:24:34.498000 399683 torch/_dynamo/utils.py:845] ------------------------------  --------------
[0;36m(EngineCore_DP0 pid=399683)[0;0m I0205 00:24:34.498000 399683 torch/_dynamo/utils.py:845] _compile.compile_inner                 22.5544
[0;36m(EngineCore_DP0 pid=399683)[0;0m I0205 00:24:34.498000 399683 torch/_dynamo/utils.py:845] compile_attempt_0                       1.0894
[0;36m(EngineCore_DP0 pid=399683)[0;0m I0205 00:24:34.498000 399683 torch/_dynamo/utils.py:845] bytecode_tracing                        0.5503
[0;36m(EngineCore_DP0 pid=399683)[0;0m I0205 00:24:34.498000 399683 torch/_dynamo/utils.py:845] OutputGraph.call_user_compiler          0.4868
[0;36m(EngineCore_DP0 pid=399683)[0;0m I0205 00:24:34.498000 399683 torch/_dynamo/utils.py:845] create_aot_dispatcher_function          0.4636
[0;36m(EngineCore_DP0 pid=399683)[0;0m I0205 00:24:34.498000 399683 torch/_dynamo/utils.py:845] aot_collect_metadata                    0.0982
[0;36m(EngineCore_DP0 pid=399683)[0;0m I0205 00:24:34.498000 399683 torch/_dynamo/utils.py:845] build_guards                           21.4468
[0;36m(EngineCore_DP0 pid=399683)[0;0m I0205 00:24:34.498000 399683 torch/_dynamo/utils.py:845] gc                                      0.006
[0;36m(EngineCore_DP0 pid=399683)[0;0m I0205 00:24:34.498000 399683 torch/_dynamo/utils.py:845] pgo.dynamic_whitelist                   0.0001
[0;36m(APIServer pid=399008)[0;0m Traceback (most recent call last):
[0;36m(APIServer pid=399008)[0;0m   File "<frozen runpy>", line 198, in _run_module_as_main
[0;36m(APIServer pid=399008)[0;0m   File "<frozen runpy>", line 88, in _run_code
[0;36m(APIServer pid=399008)[0;0m   File "/root/migration/vllm/vllm/entrypoints/openai/api_server.py", line 1390, in <module>
[0;36m(APIServer pid=399008)[0;0m     uvloop.run(run_server(args))
[0;36m(APIServer pid=399008)[0;0m   File "/usr/local/lib/python3.12/dist-packages/uvloop/__init__.py", line 96, in run
[0;36m(APIServer pid=399008)[0;0m     return __asyncio.run(
[0;36m(APIServer pid=399008)[0;0m            ^^^^^^^^^^^^^^
[0;36m(APIServer pid=399008)[0;0m   File "/usr/lib/python3.12/asyncio/runners.py", line 194, in run
[0;36m(APIServer pid=399008)[0;0m     return runner.run(main)
[0;36m(APIServer pid=399008)[0;0m            ^^^^^^^^^^^^^^^^
[0;36m(APIServer pid=399008)[0;0m   File "/usr/lib/python3.12/asyncio/runners.py", line 118, in run
[0;36m(APIServer pid=399008)[0;0m     return self._loop.run_until_complete(task)
[0;36m(APIServer pid=399008)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(APIServer pid=399008)[0;0m   File "uvloop/loop.pyx", line 1518, in uvloop.loop.Loop.run_until_complete
[0;36m(APIServer pid=399008)[0;0m   File "/usr/local/lib/python3.12/dist-packages/uvloop/__init__.py", line 48, in wrapper
[0;36m(APIServer pid=399008)[0;0m     return await main
[0;36m(APIServer pid=399008)[0;0m            ^^^^^^^^^^
[0;36m(APIServer pid=399008)[0;0m   File "/root/migration/vllm/vllm/entrypoints/openai/api_server.py", line 1319, in run_server
[0;36m(APIServer pid=399008)[0;0m     await run_server_worker(listen_address, sock, args, **uvicorn_kwargs)
[0;36m(APIServer pid=399008)[0;0m   File "/root/migration/vllm/vllm/entrypoints/openai/api_server.py", line 1338, in run_server_worker
[0;36m(APIServer pid=399008)[0;0m     async with build_async_engine_client(
[0;36m(APIServer pid=399008)[0;0m   File "/usr/lib/python3.12/contextlib.py", line 210, in __aenter__
[0;36m(APIServer pid=399008)[0;0m     return await anext(self.gen)
[0;36m(APIServer pid=399008)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[0;36m(APIServer pid=399008)[0;0m   File "/root/migration/vllm/vllm/entrypoints/openai/api_server.py", line 173, in build_async_engine_client
[0;36m(APIServer pid=399008)[0;0m     async with build_async_engine_client_from_engine_args(
[0;36m(APIServer pid=399008)[0;0m   File "/usr/lib/python3.12/contextlib.py", line 210, in __aenter__
[0;36m(APIServer pid=399008)[0;0m     return await anext(self.gen)
[0;36m(APIServer pid=399008)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[0;36m(APIServer pid=399008)[0;0m   File "/root/migration/vllm/vllm/entrypoints/openai/api_server.py", line 214, in build_async_engine_client_from_engine_args
[0;36m(APIServer pid=399008)[0;0m     async_llm = AsyncLLM.from_vllm_config(
[0;36m(APIServer pid=399008)[0;0m                 ^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(APIServer pid=399008)[0;0m   File "/root/migration/vllm/vllm/v1/engine/async_llm.py", line 205, in from_vllm_config
[0;36m(APIServer pid=399008)[0;0m     return cls(
[0;36m(APIServer pid=399008)[0;0m            ^^^^
[0;36m(APIServer pid=399008)[0;0m   File "/root/migration/vllm/vllm/v1/engine/async_llm.py", line 132, in __init__
[0;36m(APIServer pid=399008)[0;0m     self.engine_core = EngineCoreClient.make_async_mp_client(
[0;36m(APIServer pid=399008)[0;0m                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(APIServer pid=399008)[0;0m   File "/root/migration/vllm/vllm/v1/engine/core_client.py", line 122, in make_async_mp_client
[0;36m(APIServer pid=399008)[0;0m     return AsyncMPClient(*client_args)
[0;36m(APIServer pid=399008)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(APIServer pid=399008)[0;0m   File "/root/migration/vllm/vllm/v1/engine/core_client.py", line 824, in __init__
[0;36m(APIServer pid=399008)[0;0m     super().__init__(
[0;36m(APIServer pid=399008)[0;0m   File "/root/migration/vllm/vllm/v1/engine/core_client.py", line 479, in __init__
[0;36m(APIServer pid=399008)[0;0m     with launch_core_engines(vllm_config, executor_class, log_stats) as (
[0;36m(APIServer pid=399008)[0;0m   File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
[0;36m(APIServer pid=399008)[0;0m     next(self.gen)
[0;36m(APIServer pid=399008)[0;0m   File "/root/migration/vllm/vllm/v1/engine/utils.py", line 921, in launch_core_engines
[0;36m(APIServer pid=399008)[0;0m     wait_for_engine_startup(
[0;36m(APIServer pid=399008)[0;0m   File "/root/migration/vllm/vllm/v1/engine/utils.py", line 980, in wait_for_engine_startup
[0;36m(APIServer pid=399008)[0;0m     raise RuntimeError(
[0;36m(APIServer pid=399008)[0;0m RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}
[0;36m(APIServer pid=399008)[0;0m I0205 00:24:36.688000 399008 torch/_dynamo/eval_frame.py:563] TorchDynamo attempted to trace the following frames: [
[0;36m(APIServer pid=399008)[0;0m I0205 00:24:36.688000 399008 torch/_dynamo/eval_frame.py:563] 
[0;36m(APIServer pid=399008)[0;0m I0205 00:24:36.688000 399008 torch/_dynamo/eval_frame.py:563] ]
[0;36m(APIServer pid=399008)[0;0m I0205 00:24:36.690000 399008 torch/_dynamo/utils.py:845] TorchDynamo compilation metrics:
[0;36m(APIServer pid=399008)[0;0m I0205 00:24:36.690000 399008 torch/_dynamo/utils.py:845] Function    Runtimes (s)
[0;36m(APIServer pid=399008)[0;0m I0205 00:24:36.690000 399008 torch/_dynamo/utils.py:845] ----------  --------------
