# Copyright (C) 2025 Habana Labs, Ltd. an Intel Company
# SPDX-License-Identifier: Apache-2.0

# Parameterize base image components for RHEL 9.4/9.6 and TencentOS 3.1
ARG DOCKER_URL=vault.habana.ai/gaudi-docker
ARG VERSION=1.21.5
ARG BASE_NAME=rhel9.4
ARG PT_VERSION=2.6.0
ARG REVISION=latest
ARG REPO_TYPE=habanalabs
ARG TORCH_TYPE_SUFFIX

FROM ${DOCKER_URL}/${VERSION}/${BASE_NAME}/${REPO_TYPE}/pytorch-${TORCH_TYPE_SUFFIX}installer-${PT_VERSION}:${REVISION}

# Parameterize commit/branch for vllm-plugin checkout
ARG VLLM_GAUDI_COMMIT=main
# leave empty to use last-good-commit-for-vllm-gaudi
ARG VLLM_PROJECT_COMMIT=

ARG BASE_NAME
ENV BASE_NAME=${BASE_NAME}

ENV OMPI_MCA_btl_vader_single_copy_mechanism=none

# Install required packages for RHEL 9.x and TencentOS 3.1
RUN if echo "$BASE_NAME" | grep -qi "tencentos"; then \
  yum remove -y mpitests_openmpi perftest openmpi opensm-libs || true && \
  yum update -y --exclude=openmpi --exclude=opensm-libs && \
  yum install -y gettext jq git --allowerasing --exclude=openmpi --exclude=opensm-libs && \
  ln -sf /usr/bin/python3 /usr/bin/python ; \
else \
  yum update -y --nobest && \
  yum install -y gettext jq git --allowerasing && \
  ln -sf /usr/bin/python3 /usr/bin/python ; \
fi

WORKDIR /root

ENV VLLM_PATH=/workspace/vllm-project
ENV VLLM_PATH2=/workspace/vllm-gaudi

# Clone the vllm-project repository and install inside the container
# --- START: COMBINED RUN COMMAND ---
RUN \
    # Clone vllm-gaudi and get the commit hash for the vllm-project/vllm
    set -e && \
    mkdir -p $VLLM_PATH2 && \
    git clone https://github.com/vllm-project/vllm-gaudi.git $VLLM_PATH2 && \
    cd $VLLM_PATH2 && \
    if [ -z "${VLLM_PROJECT_COMMIT}" ]; then \
       VLLM_PROJECT_COMMIT=$(git show "origin/vllm/last-good-commit-for-vllm-gaudi:VLLM_STABLE_COMMIT" 2>/dev/null) && \
       echo "Found vLLM commit hash: ${VLLM_PROJECT_COMMIT}"; \
    else \
       echo "Using vLLM commit : ${VLLM_PROJECT_COMMIT}"; \
    fi && \
    mkdir -p $VLLM_PATH && \
    # Clone vllm-project/vllm and use configured or last good commit hash
    git clone https://github.com/vllm-project/vllm.git $VLLM_PATH && \
    cd $VLLM_PATH && \
    git remote add upstream https://github.com/vllm-project/vllm.git && \
    git fetch upstream --tags || true && \
    git checkout ${VLLM_PROJECT_COMMIT} && \
    # Install vllm-project/vllm
    pip install -r <(sed '/^torch/d' requirements/build.txt) && \
    VLLM_TARGET_DEVICE=empty pip install --no-build-isolation . && \
    # Install vllm-gaudi plugin
    cd $VLLM_PATH2 && \
    git checkout ${VLLM_GAUDI_COMMIT} && \
    VLLM_TARGET_DEVICE=hpu pip install -v . --no-build-isolation
# --- END: COMBINED RUN COMMAND ---

# to be verified later PWolsza
# RUN pip3 install -v -e $VLLM_PATH/tests/vllm_test_utils

# Install additional Python packages
RUN pip3 install datasets pandas

# Copy utility scripts and configuration
RUN mkdir -p /root/scripts/
COPY templates /root/scripts/templates/
COPY entrypoints /root/scripts/entrypoints/
COPY server /root/scripts/server/
COPY benchmark /root/scripts/benchmark/
WORKDIR /root/scripts

# Set entrypoint script
ENTRYPOINT ["python3", "-m", "entrypoints.entrypoint_main"]
