Calling add_step_closure function does not have any effect. It's lazy mode only functionality. (warning logged once)
Calling mark_step function does not have any effect. It's lazy mode only functionality. (warning logged once)
Calling iter_mark_step function does not have any effect. It's lazy mode only functionality. (warning logged once)
INFO 02-06 04:07:20 [plugins/__init__.py:43] Available plugins for group vllm.platform_plugins:
INFO 02-06 04:07:20 [plugins/__init__.py:45] - hpu -> vllm_gaudi:register
INFO 02-06 04:07:20 [plugins/__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
DEBUG 02-06 04:07:20 [platforms/__init__.py:36] Checking if TPU platform is available.
DEBUG 02-06 04:07:20 [platforms/__init__.py:55] TPU platform is not available because: No module named 'libtpu'
DEBUG 02-06 04:07:20 [platforms/__init__.py:61] Checking if CUDA platform is available.
DEBUG 02-06 04:07:20 [platforms/__init__.py:88] Exception happens when checking CUDA platform: NVML Shared Library Not Found
DEBUG 02-06 04:07:20 [platforms/__init__.py:105] CUDA platform is not available because: NVML Shared Library Not Found
DEBUG 02-06 04:07:20 [platforms/__init__.py:112] Checking if ROCm platform is available.
DEBUG 02-06 04:07:20 [platforms/__init__.py:126] ROCm platform is not available because: No module named 'amdsmi'
DEBUG 02-06 04:07:20 [platforms/__init__.py:133] Checking if XPU platform is available.
DEBUG 02-06 04:07:20 [platforms/__init__.py:155] XPU platform is not available because: No module named 'intel_extension_for_pytorch'
DEBUG 02-06 04:07:20 [platforms/__init__.py:162] Checking if CPU platform is available.
INFO 02-06 04:07:20 [platforms/__init__.py:219] Platform plugin hpu is activated
INFO 02-06 04:07:21 [triton_utils/importing.py:44] Triton is installed but 0 active driver(s) found (expected 1). Disabling Triton to prevent runtime errors.
INFO 02-06 04:07:21 [triton_utils/importing.py:68] Triton not installed or not compatible; certain GPU-related functions will not be available.
DEBUG 02-06 04:07:22 [entrypoints/utils.py:187] Setting VLLM_WORKER_MULTIPROC_METHOD to 'spawn'
DEBUG 02-06 04:07:22 [plugins/__init__.py:43] Available plugins for group vllm.general_plugins:
DEBUG 02-06 04:07:22 [plugins/__init__.py:45] - 01.hpu_custom_ops -> vllm_gaudi:register_ops
DEBUG 02-06 04:07:22 [plugins/__init__.py:45] - 02.hpu_custom_models -> vllm_gaudi:register_models
DEBUG 02-06 04:07:22 [plugins/__init__.py:45] - lora_filesystem_resolver -> vllm.plugins.lora_resolvers.filesystem_resolver:register_filesystem_resolver
DEBUG 02-06 04:07:22 [plugins/__init__.py:45] - lora_hf_hub_resolver -> vllm.plugins.lora_resolvers.hf_hub_resolver:register_hf_hub_resolver
DEBUG 02-06 04:07:22 [plugins/__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
DEBUG 02-06 04:07:22 [utils/flashinfer.py:55] FlashInfer unavailable since package was not found
WARNING 02-06 04:07:22 [platforms/interface.py:222] Failed to import from vllm._C: ModuleNotFoundError("No module named 'vllm._C'")
INFO 02-06 04:07:22 [distributed/.../v1/nixl_connector.py:101] Setting UCX_RCACHE_MAX_UNRELEASED to '1024' to avoid a rare memory leak in UCX when using NIXL.
WARNING 02-06 04:07:22 [distributed/.../v1/nixl_connector.py:116] NIXL is not available
WARNING 02-06 04:07:22 [distributed/.../v1/nixl_connector.py:128] NIXL agent config is not available
WARNING 02-06 04:07:22 [platform.py:163] Pin memory is not supported on HPU.
WARNING 02-06 04:07:22 [model_executor/models/registry.py:823] Model architecture Gemma3ForConditionalGeneration is already registered, and will be overwritten by the new model class vllm_gaudi.models.gemma3_mm:HpuGemma3ForConditionalGeneration.
WARNING 02-06 04:07:22 [model_executor/models/registry.py:823] Model architecture Qwen2_5_VLForConditionalGeneration is already registered, and will be overwritten by the new model class vllm_gaudi.models.qwen2_5_vl:HpuQwen2_5_VLForConditionalGeneration.
WARNING 02-06 04:07:22 [model_executor/models/registry.py:823] Model architecture Qwen3VLForConditionalGeneration is already registered, and will be overwritten by the new model class vllm_gaudi.models.qwen3_vl:HpuQwen3_VLForConditionalGeneration.
DEBUG 02-06 04:07:22 [compilation/decorators.py:202] Inferred dynamic dimensions for forward method of <class 'vllm.model_executor.models.qwen3_moe.Qwen3MoeModel'>: ['input_ids', 'positions', 'intermediate_tensors', 'inputs_embeds']
WARNING 02-06 04:07:22 [model_executor/models/registry.py:823] Model architecture Qwen3VLMoeForConditionalGeneration is already registered, and will be overwritten by the new model class vllm_gaudi.models.qwen3_vl_moe:HpuQwen3_VLMoeForConditionalGeneration.
WARNING 02-06 04:07:22 [utils/argparse_utils.py:342] Found duplicate keys --trust-remote-code
[0;36m(APIServer pid=612145)[0;0m INFO 02-06 04:07:22 [entrypoints/utils.py:346] 
[0;36m(APIServer pid=612145)[0;0m INFO 02-06 04:07:22 [entrypoints/utils.py:346]        â–ˆ     â–ˆ     â–ˆâ–„   â–„â–ˆ
[0;36m(APIServer pid=612145)[0;0m INFO 02-06 04:07:22 [entrypoints/utils.py:346]  â–„â–„ â–„â–ˆ â–ˆ     â–ˆ     â–ˆ â–€â–„â–€ â–ˆ  version 0.15.0rc2.dev85+g17b17c068.d20260205
[0;36m(APIServer pid=612145)[0;0m INFO 02-06 04:07:22 [entrypoints/utils.py:346]   â–ˆâ–„â–ˆâ–€ â–ˆ     â–ˆ     â–ˆ     â–ˆ  model   /root/.cache/huggingface/hub/models--Qwen--Qwen3-VL-32B-Instruct-FP8/snapshots/4bf2c2f39c37c0fede78bede4056e1f18cdf8109/
[0;36m(APIServer pid=612145)[0;0m INFO 02-06 04:07:22 [entrypoints/utils.py:346]    â–€â–€  â–€â–€â–€â–€â–€ â–€â–€â–€â–€â–€ â–€     â–€
[0;36m(APIServer pid=612145)[0;0m INFO 02-06 04:07:22 [entrypoints/utils.py:346] 
[0;36m(APIServer pid=612145)[0;0m INFO 02-06 04:07:22 [entrypoints/utils.py:282] non-default args: {'host': 'localhost', 'port': 12348, 'model': '/root/.cache/huggingface/hub/models--Qwen--Qwen3-VL-32B-Instruct-FP8/snapshots/4bf2c2f39c37c0fede78bede4056e1f18cdf8109/', 'trust_remote_code': True, 'max_model_len': 32768, 'served_model_name': ['Qwen/Qwen3-VL-32B-Instruct-FP8'], 'gpu_memory_utilization': 0.75, 'limit_mm_per_prompt': {'image': {'count': 20, 'width': 1280, 'height': 704}}, 'mm_processor_kwargs': {'size': {'shortest_edge': 65536, 'longest_edge': 2097152}}, 'max_num_batched_tokens': 32768}
[0;36m(APIServer pid=612145)[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
[0;36m(APIServer pid=612145)[0;0m loading configuration file /root/.cache/huggingface/hub/models--Qwen--Qwen3-VL-32B-Instruct-FP8/snapshots/4bf2c2f39c37c0fede78bede4056e1f18cdf8109/config.json
[0;36m(APIServer pid=612145)[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
[0;36m(APIServer pid=612145)[0;0m loading configuration file /root/.cache/huggingface/hub/models--Qwen--Qwen3-VL-32B-Instruct-FP8/snapshots/4bf2c2f39c37c0fede78bede4056e1f18cdf8109/config.json
[0;36m(APIServer pid=612145)[0;0m loading configuration file /root/.cache/huggingface/hub/models--Qwen--Qwen3-VL-32B-Instruct-FP8/snapshots/4bf2c2f39c37c0fede78bede4056e1f18cdf8109/config.json
[0;36m(APIServer pid=612145)[0;0m Model config Qwen3VLConfig {
[0;36m(APIServer pid=612145)[0;0m   "architectures": [
[0;36m(APIServer pid=612145)[0;0m     "Qwen3VLForConditionalGeneration"
[0;36m(APIServer pid=612145)[0;0m   ],
[0;36m(APIServer pid=612145)[0;0m   "image_token_id": 151655,
[0;36m(APIServer pid=612145)[0;0m   "model_type": "qwen3_vl",
[0;36m(APIServer pid=612145)[0;0m   "quantization_config": {
[0;36m(APIServer pid=612145)[0;0m     "activation_scheme": "dynamic",
[0;36m(APIServer pid=612145)[0;0m     "fmt": "e4m3",
[0;36m(APIServer pid=612145)[0;0m     "ignored_layers": [
[0;36m(APIServer pid=612145)[0;0m       "lm_head",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.merger.linear_fc1",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.merger.linear_fc2",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.merger.norm",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.patch_embed.proj",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.pos_embed",
[0;36m(APIServer pid=612145)[0;0m       "visual.merger.linear_fc1",
[0;36m(APIServer pid=612145)[0;0m       "visual.merger.linear_fc2",
[0;36m(APIServer pid=612145)[0;0m       "visual.merger.norm",
[0;36m(APIServer pid=612145)[0;0m       "visual.patch_embed.proj",
[0;36m(APIServer pid=612145)[0;0m       "visual.pos_embed",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.blocks.0.attn.proj",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.blocks.0.attn.qkv",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.blocks.0.mlp.linear_fc1",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.blocks.0.mlp.linear_fc2",
[0;36m(APIServer pid=612145)[0;0m       "visual.blocks.0.attn.proj",
[0;36m(APIServer pid=612145)[0;0m       "visual.blocks.0.attn.qkv_proj",
[0;36m(APIServer pid=612145)[0;0m       "visual.blocks.0.mlp.linear_fc1",
[0;36m(APIServer pid=612145)[0;0m       "visual.blocks.0.mlp.linear_fc2",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.blocks.1.attn.proj",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.blocks.1.attn.qkv",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.blocks.1.mlp.linear_fc1",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.blocks.1.mlp.linear_fc2",
[0;36m(APIServer pid=612145)[0;0m       "visual.blocks.1.attn.proj",
[0;36m(APIServer pid=612145)[0;0m       "visual.blocks.1.attn.qkv_proj",
[0;36m(APIServer pid=612145)[0;0m       "visual.blocks.1.mlp.linear_fc1",
[0;36m(APIServer pid=612145)[0;0m       "visual.blocks.1.mlp.linear_fc2",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.blocks.2.attn.proj",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.blocks.2.attn.qkv",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.blocks.2.mlp.linear_fc1",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.blocks.2.mlp.linear_fc2",
[0;36m(APIServer pid=612145)[0;0m       "visual.blocks.2.attn.proj",
[0;36m(APIServer pid=612145)[0;0m       "visual.blocks.2.attn.qkv_proj",
[0;36m(APIServer pid=612145)[0;0m       "visual.blocks.2.mlp.linear_fc1",
[0;36m(APIServer pid=612145)[0;0m       "visual.blocks.2.mlp.linear_fc2",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.blocks.3.attn.proj",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.blocks.3.attn.qkv",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.blocks.3.mlp.linear_fc1",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.blocks.3.mlp.linear_fc2",
[0;36m(APIServer pid=612145)[0;0m       "visual.blocks.3.attn.proj",
[0;36m(APIServer pid=612145)[0;0m       "visual.blocks.3.attn.qkv_proj",
[0;36m(APIServer pid=612145)[0;0m       "visual.blocks.3.mlp.linear_fc1",
[0;36m(APIServer pid=612145)[0;0m       "visual.blocks.3.mlp.linear_fc2",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.blocks.4.attn.proj",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.blocks.4.attn.qkv",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.blocks.4.mlp.linear_fc1",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.blocks.4.mlp.linear_fc2",
[0;36m(APIServer pid=612145)[0;0m       "visual.blocks.4.attn.proj",
[0;36m(APIServer pid=612145)[0;0m       "visual.blocks.4.attn.qkv_proj",
[0;36m(APIServer pid=612145)[0;0m       "visual.blocks.4.mlp.linear_fc1",
[0;36m(APIServer pid=612145)[0;0m       "visual.blocks.4.mlp.linear_fc2",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.blocks.5.attn.proj",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.blocks.5.attn.qkv",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.blocks.5.mlp.linear_fc1",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.blocks.5.mlp.linear_fc2",
[0;36m(APIServer pid=612145)[0;0m       "visual.blocks.5.attn.proj",
[0;36m(APIServer pid=612145)[0;0m       "visual.blocks.5.attn.qkv_proj",
[0;36m(APIServer pid=612145)[0;0m       "visual.blocks.5.mlp.linear_fc1",
[0;36m(APIServer pid=612145)[0;0m       "visual.blocks.5.mlp.linear_fc2",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.blocks.6.attn.proj",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.blocks.6.attn.qkv",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.blocks.6.mlp.linear_fc1",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.blocks.6.mlp.linear_fc2",
[0;36m(APIServer pid=612145)[0;0m       "visual.blocks.6.attn.proj",
[0;36m(APIServer pid=612145)[0;0m       "visual.blocks.6.attn.qkv_proj",
[0;36m(APIServer pid=612145)[0;0m       "visual.blocks.6.mlp.linear_fc1",
[0;36m(APIServer pid=612145)[0;0m       "visual.blocks.6.mlp.linear_fc2",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.blocks.7.attn.proj",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.blocks.7.attn.qkv",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.blocks.7.mlp.linear_fc1",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.blocks.7.mlp.linear_fc2",
[0;36m(APIServer pid=612145)[0;0m       "visual.blocks.7.attn.proj",
[0;36m(APIServer pid=612145)[0;0m       "visual.blocks.7.attn.qkv_proj",
[0;36m(APIServer pid=612145)[0;0m       "visual.blocks.7.mlp.linear_fc1",
[0;36m(APIServer pid=612145)[0;0m       "visual.blocks.7.mlp.linear_fc2",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.blocks.8.attn.proj",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.blocks.8.attn.qkv",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.blocks.8.mlp.linear_fc1",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.blocks.8.mlp.linear_fc2",
[0;36m(APIServer pid=612145)[0;0m       "visual.blocks.8.attn.proj",
[0;36m(APIServer pid=612145)[0;0m       "visual.blocks.8.attn.qkv_proj",
[0;36m(APIServer pid=612145)[0;0m       "visual.blocks.8.mlp.linear_fc1",
[0;36m(APIServer pid=612145)[0;0m       "visual.blocks.8.mlp.linear_fc2",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.blocks.9.attn.proj",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.blocks.9.attn.qkv",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.blocks.9.mlp.linear_fc1",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.blocks.9.mlp.linear_fc2",
[0;36m(APIServer pid=612145)[0;0m       "visual.blocks.9.attn.proj",
[0;36m(APIServer pid=612145)[0;0m       "visual.blocks.9.attn.qkv_proj",
[0;36m(APIServer pid=612145)[0;0m       "visual.blocks.9.mlp.linear_fc1",
[0;36m(APIServer pid=612145)[0;0m       "visual.blocks.9.mlp.linear_fc2",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.blocks.10.attn.proj",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.blocks.10.attn.qkv",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.blocks.10.mlp.linear_fc1",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.blocks.10.mlp.linear_fc2",
[0;36m(APIServer pid=612145)[0;0m       "visual.blocks.10.attn.proj",
[0;36m(APIServer pid=612145)[0;0m       "visual.blocks.10.attn.qkv_proj",
[0;36m(APIServer pid=612145)[0;0m       "visual.blocks.10.mlp.linear_fc1",
[0;36m(APIServer pid=612145)[0;0m       "visual.blocks.10.mlp.linear_fc2",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.blocks.11.attn.proj",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.blocks.11.attn.qkv",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.blocks.11.mlp.linear_fc1",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.blocks.11.mlp.linear_fc2",
[0;36m(APIServer pid=612145)[0;0m       "visual.blocks.11.attn.proj",
[0;36m(APIServer pid=612145)[0;0m       "visual.blocks.11.attn.qkv_proj",
[0;36m(APIServer pid=612145)[0;0m       "visual.blocks.11.mlp.linear_fc1",
[0;36m(APIServer pid=612145)[0;0m       "visual.blocks.11.mlp.linear_fc2",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.blocks.12.attn.proj",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.blocks.12.attn.qkv",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.blocks.12.mlp.linear_fc1",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.blocks.12.mlp.linear_fc2",
[0;36m(APIServer pid=612145)[0;0m       "visual.blocks.12.attn.proj",
[0;36m(APIServer pid=612145)[0;0m       "visual.blocks.12.attn.qkv_proj",
[0;36m(APIServer pid=612145)[0;0m       "visual.blocks.12.mlp.linear_fc1",
[0;36m(APIServer pid=612145)[0;0m       "visual.blocks.12.mlp.linear_fc2",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.blocks.13.attn.proj",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.blocks.13.attn.qkv",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.blocks.13.mlp.linear_fc1",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.blocks.13.mlp.linear_fc2",
[0;36m(APIServer pid=612145)[0;0m       "visual.blocks.13.attn.proj",
[0;36m(APIServer pid=612145)[0;0m       "visual.blocks.13.attn.qkv_proj",
[0;36m(APIServer pid=612145)[0;0m       "visual.blocks.13.mlp.linear_fc1",
[0;36m(APIServer pid=612145)[0;0m       "visual.blocks.13.mlp.linear_fc2",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.blocks.14.attn.proj",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.blocks.14.attn.qkv",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.blocks.14.mlp.linear_fc1",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.blocks.14.mlp.linear_fc2",
[0;36m(APIServer pid=612145)[0;0m       "visual.blocks.14.attn.proj",
[0;36m(APIServer pid=612145)[0;0m       "visual.blocks.14.attn.qkv_proj",
[0;36m(APIServer pid=612145)[0;0m       "visual.blocks.14.mlp.linear_fc1",
[0;36m(APIServer pid=612145)[0;0m       "visual.blocks.14.mlp.linear_fc2",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.blocks.15.attn.proj",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.blocks.15.attn.qkv",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.blocks.15.mlp.linear_fc1",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.blocks.15.mlp.linear_fc2",
[0;36m(APIServer pid=612145)[0;0m       "visual.blocks.15.attn.proj",
[0;36m(APIServer pid=612145)[0;0m       "visual.blocks.15.attn.qkv_proj",
[0;36m(APIServer pid=612145)[0;0m       "visual.blocks.15.mlp.linear_fc1",
[0;36m(APIServer pid=612145)[0;0m       "visual.blocks.15.mlp.linear_fc2",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.blocks.16.attn.proj",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.blocks.16.attn.qkv",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.blocks.16.mlp.linear_fc1",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.blocks.16.mlp.linear_fc2",
[0;36m(APIServer pid=612145)[0;0m       "visual.blocks.16.attn.proj",
[0;36m(APIServer pid=612145)[0;0m       "visual.blocks.16.attn.qkv_proj",
[0;36m(APIServer pid=612145)[0;0m       "visual.blocks.16.mlp.linear_fc1",
[0;36m(APIServer pid=612145)[0;0m       "visual.blocks.16.mlp.linear_fc2",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.blocks.17.attn.proj",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.blocks.17.attn.qkv",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.blocks.17.mlp.linear_fc1",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.blocks.17.mlp.linear_fc2",
[0;36m(APIServer pid=612145)[0;0m       "visual.blocks.17.attn.proj",
[0;36m(APIServer pid=612145)[0;0m       "visual.blocks.17.attn.qkv_proj",
[0;36m(APIServer pid=612145)[0;0m       "visual.blocks.17.mlp.linear_fc1",
[0;36m(APIServer pid=612145)[0;0m       "visual.blocks.17.mlp.linear_fc2",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.blocks.18.attn.proj",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.blocks.18.attn.qkv",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.blocks.18.mlp.linear_fc1",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.blocks.18.mlp.linear_fc2",
[0;36m(APIServer pid=612145)[0;0m       "visual.blocks.18.attn.proj",
[0;36m(APIServer pid=612145)[0;0m       "visual.blocks.18.attn.qkv_proj",
[0;36m(APIServer pid=612145)[0;0m       "visual.blocks.18.mlp.linear_fc1",
[0;36m(APIServer pid=612145)[0;0m       "visual.blocks.18.mlp.linear_fc2",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.blocks.19.attn.proj",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.blocks.19.attn.qkv",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.blocks.19.mlp.linear_fc1",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.blocks.19.mlp.linear_fc2",
[0;36m(APIServer pid=612145)[0;0m       "visual.blocks.19.attn.proj",
[0;36m(APIServer pid=612145)[0;0m       "visual.blocks.19.attn.qkv_proj",
[0;36m(APIServer pid=612145)[0;0m       "visual.blocks.19.mlp.linear_fc1",
[0;36m(APIServer pid=612145)[0;0m       "visual.blocks.19.mlp.linear_fc2",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.blocks.20.attn.proj",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.blocks.20.attn.qkv",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.blocks.20.mlp.linear_fc1",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.blocks.20.mlp.linear_fc2",
[0;36m(APIServer pid=612145)[0;0m       "visual.blocks.20.attn.proj",
[0;36m(APIServer pid=612145)[0;0m       "visual.blocks.20.attn.qkv_proj",
[0;36m(APIServer pid=612145)[0;0m       "visual.blocks.20.mlp.linear_fc1",
[0;36m(APIServer pid=612145)[0;0m       "visual.blocks.20.mlp.linear_fc2",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.blocks.21.attn.proj",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.blocks.21.attn.qkv",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.blocks.21.mlp.linear_fc1",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.blocks.21.mlp.linear_fc2",
[0;36m(APIServer pid=612145)[0;0m       "visual.blocks.21.attn.proj",
[0;36m(APIServer pid=612145)[0;0m       "visual.blocks.21.attn.qkv_proj",
[0;36m(APIServer pid=612145)[0;0m       "visual.blocks.21.mlp.linear_fc1",
[0;36m(APIServer pid=612145)[0;0m       "visual.blocks.21.mlp.linear_fc2",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.blocks.22.attn.proj",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.blocks.22.attn.qkv",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.blocks.22.mlp.linear_fc1",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.blocks.22.mlp.linear_fc2",
[0;36m(APIServer pid=612145)[0;0m       "visual.blocks.22.attn.proj",
[0;36m(APIServer pid=612145)[0;0m       "visual.blocks.22.attn.qkv_proj",
[0;36m(APIServer pid=612145)[0;0m       "visual.blocks.22.mlp.linear_fc1",
[0;36m(APIServer pid=612145)[0;0m       "visual.blocks.22.mlp.linear_fc2",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.blocks.23.attn.proj",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.blocks.23.attn.qkv",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.blocks.23.mlp.linear_fc1",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.blocks.23.mlp.linear_fc2",
[0;36m(APIServer pid=612145)[0;0m       "visual.blocks.23.attn.proj",
[0;36m(APIServer pid=612145)[0;0m       "visual.blocks.23.attn.qkv_proj",
[0;36m(APIServer pid=612145)[0;0m       "visual.blocks.23.mlp.linear_fc1",
[0;36m(APIServer pid=612145)[0;0m       "visual.blocks.23.mlp.linear_fc2",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.blocks.24.attn.proj",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.blocks.24.attn.qkv",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.blocks.24.mlp.linear_fc1",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.blocks.24.mlp.linear_fc2",
[0;36m(APIServer pid=612145)[0;0m       "visual.blocks.24.attn.proj",
[0;36m(APIServer pid=612145)[0;0m       "visual.blocks.24.attn.qkv_proj",
[0;36m(APIServer pid=612145)[0;0m       "visual.blocks.24.mlp.linear_fc1",
[0;36m(APIServer pid=612145)[0;0m       "visual.blocks.24.mlp.linear_fc2",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.blocks.25.attn.proj",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.blocks.25.attn.qkv",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.blocks.25.mlp.linear_fc1",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.blocks.25.mlp.linear_fc2",
[0;36m(APIServer pid=612145)[0;0m       "visual.blocks.25.attn.proj",
[0;36m(APIServer pid=612145)[0;0m       "visual.blocks.25.attn.qkv_proj",
[0;36m(APIServer pid=612145)[0;0m       "visual.blocks.25.mlp.linear_fc1",
[0;36m(APIServer pid=612145)[0;0m       "visual.blocks.25.mlp.linear_fc2",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.blocks.26.attn.proj",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.blocks.26.attn.qkv",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.blocks.26.mlp.linear_fc1",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.blocks.26.mlp.linear_fc2",
[0;36m(APIServer pid=612145)[0;0m       "visual.blocks.26.attn.proj",
[0;36m(APIServer pid=612145)[0;0m       "visual.blocks.26.attn.qkv_proj",
[0;36m(APIServer pid=612145)[0;0m       "visual.blocks.26.mlp.linear_fc1",
[0;36m(APIServer pid=612145)[0;0m       "visual.blocks.26.mlp.linear_fc2",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.deepstack_merger_list.0.linear_fc1",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.deepstack_merger_list.0.linear_fc2",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.deepstack_merger_list.0.norm",
[0;36m(APIServer pid=612145)[0;0m       "visual.deepstack_merger_list.0.linear_fc1",
[0;36m(APIServer pid=612145)[0;0m       "visual.deepstack_merger_list.0.linear_fc2",
[0;36m(APIServer pid=612145)[0;0m       "visual.deepstack_merger_list.0.norm",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.deepstack_merger_list.1.linear_fc1",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.deepstack_merger_list.1.linear_fc2",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.deepstack_merger_list.1.norm",
[0;36m(APIServer pid=612145)[0;0m       "visual.deepstack_merger_list.1.linear_fc1",
[0;36m(APIServer pid=612145)[0;0m       "visual.deepstack_merger_list.1.linear_fc2",
[0;36m(APIServer pid=612145)[0;0m       "visual.deepstack_merger_list.1.norm",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.deepstack_merger_list.2.linear_fc1",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.deepstack_merger_list.2.linear_fc2",
[0;36m(APIServer pid=612145)[0;0m       "model.visual.deepstack_merger_list.2.norm",
[0;36m(APIServer pid=612145)[0;0m       "visual.deepstack_merger_list.2.linear_fc1",
[0;36m(APIServer pid=612145)[0;0m       "visual.deepstack_merger_list.2.linear_fc2",
[0;36m(APIServer pid=612145)[0;0m       "visual.deepstack_merger_list.2.norm"
[0;36m(APIServer pid=612145)[0;0m     ],
[0;36m(APIServer pid=612145)[0;0m     "quant_method": "fp8",
[0;36m(APIServer pid=612145)[0;0m     "weight_block_size": [
[0;36m(APIServer pid=612145)[0;0m       128,
[0;36m(APIServer pid=612145)[0;0m       128
[0;36m(APIServer pid=612145)[0;0m     ]
[0;36m(APIServer pid=612145)[0;0m   },
[0;36m(APIServer pid=612145)[0;0m   "text_config": {
[0;36m(APIServer pid=612145)[0;0m     "attention_bias": false,
[0;36m(APIServer pid=612145)[0;0m     "attention_dropout": 0.0,
[0;36m(APIServer pid=612145)[0;0m     "bos_token_id": 151643,
[0;36m(APIServer pid=612145)[0;0m     "dtype": "bfloat16",
[0;36m(APIServer pid=612145)[0;0m     "eos_token_id": 151645,
[0;36m(APIServer pid=612145)[0;0m     "head_dim": 128,
[0;36m(APIServer pid=612145)[0;0m     "hidden_act": "silu",
[0;36m(APIServer pid=612145)[0;0m     "hidden_size": 5120,
[0;36m(APIServer pid=612145)[0;0m     "initializer_range": 0.02,
[0;36m(APIServer pid=612145)[0;0m     "intermediate_size": 25600,
[0;36m(APIServer pid=612145)[0;0m     "max_position_embeddings": 262144,
[0;36m(APIServer pid=612145)[0;0m     "model_type": "qwen3_vl_text",
[0;36m(APIServer pid=612145)[0;0m     "num_attention_heads": 64,
[0;36m(APIServer pid=612145)[0;0m     "num_hidden_layers": 64,
[0;36m(APIServer pid=612145)[0;0m     "num_key_value_heads": 8,
[0;36m(APIServer pid=612145)[0;0m     "rms_norm_eps": 1e-06,
[0;36m(APIServer pid=612145)[0;0m     "rope_scaling": {
[0;36m(APIServer pid=612145)[0;0m       "mrope_interleaved": true,
[0;36m(APIServer pid=612145)[0;0m       "mrope_section": [
[0;36m(APIServer pid=612145)[0;0m         24,
[0;36m(APIServer pid=612145)[0;0m         20,
[0;36m(APIServer pid=612145)[0;0m         20
[0;36m(APIServer pid=612145)[0;0m       ],
[0;36m(APIServer pid=612145)[0;0m       "rope_type": "default"
[0;36m(APIServer pid=612145)[0;0m     },
[0;36m(APIServer pid=612145)[0;0m     "rope_theta": 5000000,
[0;36m(APIServer pid=612145)[0;0m     "use_cache": true,
[0;36m(APIServer pid=612145)[0;0m     "vocab_size": 151936
[0;36m(APIServer pid=612145)[0;0m   },
[0;36m(APIServer pid=612145)[0;0m   "tie_word_embeddings": false,
[0;36m(APIServer pid=612145)[0;0m   "transformers_version": "4.57.6",
[0;36m(APIServer pid=612145)[0;0m   "video_token_id": 151656,
[0;36m(APIServer pid=612145)[0;0m   "vision_config": {
[0;36m(APIServer pid=612145)[0;0m     "deepstack_visual_indexes": [
[0;36m(APIServer pid=612145)[0;0m       8,
[0;36m(APIServer pid=612145)[0;0m       16,
[0;36m(APIServer pid=612145)[0;0m       24
[0;36m(APIServer pid=612145)[0;0m     ],
[0;36m(APIServer pid=612145)[0;0m     "depth": 27,
[0;36m(APIServer pid=612145)[0;0m     "hidden_act": "gelu_pytorch_tanh",
[0;36m(APIServer pid=612145)[0;0m     "hidden_size": 1152,
[0;36m(APIServer pid=612145)[0;0m     "in_channels": 3,
[0;36m(APIServer pid=612145)[0;0m     "initializer_range": 0.02,
[0;36m(APIServer pid=612145)[0;0m     "intermediate_size": 4304,
[0;36m(APIServer pid=612145)[0;0m     "model_type": "qwen3_vl",
[0;36m(APIServer pid=612145)[0;0m     "num_heads": 16,
[0;36m(APIServer pid=612145)[0;0m     "num_position_embeddings": 2304,
[0;36m(APIServer pid=612145)[0;0m     "out_hidden_size": 5120,
[0;36m(APIServer pid=612145)[0;0m     "patch_size": 16,
[0;36m(APIServer pid=612145)[0;0m     "spatial_merge_size": 2,
[0;36m(APIServer pid=612145)[0;0m     "temporal_patch_size": 2
[0;36m(APIServer pid=612145)[0;0m   },
[0;36m(APIServer pid=612145)[0;0m   "vision_end_token_id": 151653,
[0;36m(APIServer pid=612145)[0;0m   "vision_start_token_id": 151652
[0;36m(APIServer pid=612145)[0;0m }
[0;36m(APIServer pid=612145)[0;0m 
[0;36m(APIServer pid=612145)[0;0m DEBUG 02-06 04:07:22 [model_executor/models/registry.py:735] Loaded model info for class vllm_gaudi.models.qwen3_vl.HpuQwen3_VLForConditionalGeneration from cache
[0;36m(APIServer pid=612145)[0;0m DEBUG 02-06 04:07:22 [logging_utils/log_time.py:29] Registry inspect model class: Elapsed time 0.0006217 secs
[0;36m(APIServer pid=612145)[0;0m INFO 02-06 04:07:22 [config/model.py:541] Resolved architecture: Qwen3VLForConditionalGeneration
[0;36m(APIServer pid=612145)[0;0m INFO 02-06 04:07:22 [config/model.py:1558] Using max model len 32768
[0;36m(APIServer pid=612145)[0;0m DEBUG 02-06 04:07:23 [_ipex_ops.py:15] Import error msg: No module named 'intel_extension_for_pytorch'
[0;36m(APIServer pid=612145)[0;0m DEBUG 02-06 04:07:23 [config/model.py:1622] Generative models support chunked prefill.
[0;36m(APIServer pid=612145)[0;0m DEBUG 02-06 04:07:23 [config/model.py:1680] Generative models support prefix caching.
[0;36m(APIServer pid=612145)[0;0m DEBUG 02-06 04:07:23 [engine/arg_utils.py:1900] Enabling chunked prefill by default
[0;36m(APIServer pid=612145)[0;0m DEBUG 02-06 04:07:23 [engine/arg_utils.py:1930] Enabling prefix caching by default
[0;36m(APIServer pid=612145)[0;0m WARNING 02-06 04:07:23 [platform.py:95] This is a workaround! Please check the NOTE in the get_device_total_memory definition.
[0;36m(APIServer pid=612145)[0;0m DEBUG 02-06 04:07:23 [engine/arg_utils.py:2018] Defaulting max_num_seqs to 256 for OPENAI_API_SERVER usage context.
[0;36m(APIServer pid=612145)[0;0m DEBUG 02-06 04:07:23 [config/parallel.py:701] Disabled the custom all-reduce kernel because it is not supported on current platform.
[0;36m(APIServer pid=612145)[0;0m INFO 02-06 04:07:23 [config/scheduler.py:226] Chunked prefill is enabled with max_num_batched_tokens=32768.
[0;36m(APIServer pid=612145)[0;0m DEBUG 02-06 04:07:23 [config/parallel.py:701] Disabled the custom all-reduce kernel because it is not supported on current platform.
[0;36m(APIServer pid=612145)[0;0m INFO 02-06 04:07:23 [config/vllm.py:633] Asynchronous scheduling is enabled.
[0;36m(APIServer pid=612145)[0;0m WARNING 02-06 04:07:23 [platform.py:143] Using Contiguous PA, disabling prefix caching
[0;36m(APIServer pid=612145)[0;0m INFO 02-06 04:07:23 [platform.py:147] [HPU] Forcing CompilationMode.NONE compilation mode
[0;36m(APIServer pid=612145)[0;0m =========compilation_config.custom_ops=['all']===========
[0;36m(APIServer pid=612145)[0;0m DEBUG 02-06 04:07:23 [plugins/__init__.py:35] No plugins for group vllm.stat_logger_plugins found.
[0;36m(APIServer pid=612145)[0;0m loading configuration file /root/.cache/huggingface/hub/models--Qwen--Qwen3-VL-32B-Instruct-FP8/snapshots/4bf2c2f39c37c0fede78bede4056e1f18cdf8109/generation_config.json
[0;36m(APIServer pid=612145)[0;0m Generate config GenerationConfig {
[0;36m(APIServer pid=612145)[0;0m   "bos_token_id": 151643,
[0;36m(APIServer pid=612145)[0;0m   "do_sample": true,
[0;36m(APIServer pid=612145)[0;0m   "eos_token_id": [
[0;36m(APIServer pid=612145)[0;0m     151645,
[0;36m(APIServer pid=612145)[0;0m     151643
[0;36m(APIServer pid=612145)[0;0m   ],
[0;36m(APIServer pid=612145)[0;0m   "pad_token_id": 151643,
[0;36m(APIServer pid=612145)[0;0m   "temperature": 0.7,
[0;36m(APIServer pid=612145)[0;0m   "top_k": 20,
[0;36m(APIServer pid=612145)[0;0m   "top_p": 0.8
[0;36m(APIServer pid=612145)[0;0m }
[0;36m(APIServer pid=612145)[0;0m 
[0;36m(APIServer pid=612145)[0;0m DEBUG 02-06 04:07:23 [tokenizers/registry.py:64] Loading CachedHfTokenizer for tokenizer_mode='hf'
[0;36m(APIServer pid=612145)[0;0m loading file vocab.json
[0;36m(APIServer pid=612145)[0;0m loading file merges.txt
[0;36m(APIServer pid=612145)[0;0m loading file tokenizer.json
[0;36m(APIServer pid=612145)[0;0m loading file added_tokens.json
[0;36m(APIServer pid=612145)[0;0m loading file special_tokens_map.json
[0;36m(APIServer pid=612145)[0;0m loading file tokenizer_config.json
[0;36m(APIServer pid=612145)[0;0m loading file chat_template.jinja
[0;36m(APIServer pid=612145)[0;0m Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[0;36m(APIServer pid=612145)[0;0m DEBUG 02-06 04:07:23 [renderers/registry.py:51] Loading HfRenderer for renderer_mode='hf'
[0;36m(APIServer pid=612145)[0;0m loading file vocab.json
[0;36m(APIServer pid=612145)[0;0m loading file merges.txt
[0;36m(APIServer pid=612145)[0;0m loading file tokenizer.json
[0;36m(APIServer pid=612145)[0;0m loading file added_tokens.json
[0;36m(APIServer pid=612145)[0;0m loading file special_tokens_map.json
[0;36m(APIServer pid=612145)[0;0m loading file tokenizer_config.json
[0;36m(APIServer pid=612145)[0;0m loading file chat_template.jinja
[0;36m(APIServer pid=612145)[0;0m Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[0;36m(APIServer pid=612145)[0;0m DEBUG 02-06 04:07:23 [plugins/io_processors/__init__.py:33] No IOProcessor plugins requested by the model
Calling add_step_closure function does not have any effect. It's lazy mode only functionality. (warning logged once)
Calling mark_step function does not have any effect. It's lazy mode only functionality. (warning logged once)
Calling iter_mark_step function does not have any effect. It's lazy mode only functionality. (warning logged once)
INFO 02-06 04:07:26 [plugins/__init__.py:43] Available plugins for group vllm.platform_plugins:
INFO 02-06 04:07:26 [plugins/__init__.py:45] - hpu -> vllm_gaudi:register
INFO 02-06 04:07:26 [plugins/__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
DEBUG 02-06 04:07:26 [platforms/__init__.py:36] Checking if TPU platform is available.
DEBUG 02-06 04:07:26 [platforms/__init__.py:55] TPU platform is not available because: No module named 'libtpu'
DEBUG 02-06 04:07:26 [platforms/__init__.py:61] Checking if CUDA platform is available.
DEBUG 02-06 04:07:26 [platforms/__init__.py:88] Exception happens when checking CUDA platform: NVML Shared Library Not Found
DEBUG 02-06 04:07:26 [platforms/__init__.py:105] CUDA platform is not available because: NVML Shared Library Not Found
DEBUG 02-06 04:07:26 [platforms/__init__.py:112] Checking if ROCm platform is available.
DEBUG 02-06 04:07:26 [platforms/__init__.py:126] ROCm platform is not available because: No module named 'amdsmi'
DEBUG 02-06 04:07:26 [platforms/__init__.py:133] Checking if XPU platform is available.
DEBUG 02-06 04:07:26 [platforms/__init__.py:155] XPU platform is not available because: No module named 'intel_extension_for_pytorch'
DEBUG 02-06 04:07:26 [platforms/__init__.py:162] Checking if CPU platform is available.
INFO 02-06 04:07:26 [platforms/__init__.py:219] Platform plugin hpu is activated
INFO 02-06 04:07:27 [triton_utils/importing.py:44] Triton is installed but 0 active driver(s) found (expected 1). Disabling Triton to prevent runtime errors.
INFO 02-06 04:07:27 [triton_utils/importing.py:68] Triton not installed or not compatible; certain GPU-related functions will not be available.
DEBUG 02-06 04:07:28 [utils/flashinfer.py:55] FlashInfer unavailable since package was not found
WARNING 02-06 04:07:28 [platforms/interface.py:222] Failed to import from vllm._C: ModuleNotFoundError("No module named 'vllm._C'")
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:28 [v1/engine/core.py:861] Waiting for init message from front-end.
[0;36m(APIServer pid=612145)[0;0m DEBUG 02-06 04:07:28 [v1/engine/utils.py:1093] HELLO from local core engine process 0.
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:28 [v1/engine/core.py:872] Received init message: EngineHandshakeMetadata(addresses=EngineZmqAddresses(inputs=['ipc:///tmp/f9b869ec-9b75-4c79-a48f-64553b4ee62e'], outputs=['ipc:///tmp/3a8e8fc4-63c7-413f-8422-dc5ef5d786ff'], coordinator_input=None, coordinator_output=None, frontend_stats_publish_address=None), parallel_config={})
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:28 [v1/engine/core.py:676] Has DP Coordinator: False, stats publish address: None
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:28 [plugins/__init__.py:43] Available plugins for group vllm.general_plugins:
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:28 [plugins/__init__.py:45] - 01.hpu_custom_ops -> vllm_gaudi:register_ops
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:28 [plugins/__init__.py:45] - 02.hpu_custom_models -> vllm_gaudi:register_models
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:28 [plugins/__init__.py:45] - lora_filesystem_resolver -> vllm.plugins.lora_resolvers.filesystem_resolver:register_filesystem_resolver
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:28 [plugins/__init__.py:45] - lora_hf_hub_resolver -> vllm.plugins.lora_resolvers.hf_hub_resolver:register_hf_hub_resolver
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:28 [plugins/__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
[0;36m(EngineCore_DP0 pid=612475)[0;0m WARNING 02-06 04:07:28 [distributed/.../v1/nixl_connector.py:116] NIXL is not available
[0;36m(EngineCore_DP0 pid=612475)[0;0m WARNING 02-06 04:07:28 [distributed/.../v1/nixl_connector.py:128] NIXL agent config is not available
[0;36m(EngineCore_DP0 pid=612475)[0;0m WARNING 02-06 04:07:29 [platform.py:163] Pin memory is not supported on HPU.
[0;36m(EngineCore_DP0 pid=612475)[0;0m WARNING 02-06 04:07:29 [model_executor/models/registry.py:823] Model architecture Gemma3ForConditionalGeneration is already registered, and will be overwritten by the new model class vllm_gaudi.models.gemma3_mm:HpuGemma3ForConditionalGeneration.
[0;36m(EngineCore_DP0 pid=612475)[0;0m WARNING 02-06 04:07:29 [model_executor/models/registry.py:823] Model architecture Qwen2_5_VLForConditionalGeneration is already registered, and will be overwritten by the new model class vllm_gaudi.models.qwen2_5_vl:HpuQwen2_5_VLForConditionalGeneration.
[0;36m(EngineCore_DP0 pid=612475)[0;0m WARNING 02-06 04:07:29 [model_executor/models/registry.py:823] Model architecture Qwen3VLForConditionalGeneration is already registered, and will be overwritten by the new model class vllm_gaudi.models.qwen3_vl:HpuQwen3_VLForConditionalGeneration.
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:29 [compilation/decorators.py:202] Inferred dynamic dimensions for forward method of <class 'vllm.model_executor.models.qwen3_moe.Qwen3MoeModel'>: ['input_ids', 'positions', 'intermediate_tensors', 'inputs_embeds']
[0;36m(EngineCore_DP0 pid=612475)[0;0m WARNING 02-06 04:07:29 [model_executor/models/registry.py:823] Model architecture Qwen3VLMoeForConditionalGeneration is already registered, and will be overwritten by the new model class vllm_gaudi.models.qwen3_vl_moe:HpuQwen3_VLMoeForConditionalGeneration.
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:29 [v1/engine/core.py:96] Initializing a V1 LLM engine (v0.15.0rc2.dev85+g17b17c068.d20260205) with config: model='/root/.cache/huggingface/hub/models--Qwen--Qwen3-VL-32B-Instruct-FP8/snapshots/4bf2c2f39c37c0fede78bede4056e1f18cdf8109/', speculative_config=None, tokenizer='/root/.cache/huggingface/hub/models--Qwen--Qwen3-VL-32B-Instruct-FP8/snapshots/4bf2c2f39c37c0fede78bede4056e1f18cdf8109/', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=32768, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=fp8, enforce_eager=False, enable_return_routed_experts=False, kv_cache_dtype=auto, device_config=hpu, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01, cudagraph_metrics=False, enable_layerwise_nvtx_tracing=False, enable_mfu_metrics=False, enable_mm_processor_stats=False, enable_logging_iteration_details=False), seed=0, served_model_name=Qwen/Qwen3-VL-32B-Instruct-FP8, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.NONE: 0>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'hpu_backend', 'custom_ops': ['all', '+quant_fp8'], 'splitting_ops': [], 'compile_mm_encoder': False, 'compile_sizes': None, 'compile_ranges_split_points': [32768], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.NONE: 0>, 'cudagraph_num_of_warmups': 0, 'cudagraph_capture_sizes': [], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': True, 'fuse_act_quant': True, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False, 'fuse_act_padding': False}, 'max_cudagraph_capture_size': None, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>, 'evaluate_guards': False, 'assume_32_bit_indexing': False}, 'local_cache_dir': None, 'static_all_moe_layers': []}
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:29 [compilation/decorators.py:202] Inferred dynamic dimensions for forward method of <class 'vllm.model_executor.models.deepseek_v2.DeepseekV2Model'>: ['input_ids', 'positions', 'intermediate_tensors', 'inputs_embeds']
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:29 [compilation/decorators.py:202] Inferred dynamic dimensions for forward method of <class 'vllm.model_executor.models.llama.LlamaModel'>: ['input_ids', 'positions', 'intermediate_tensors', 'inputs_embeds']
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:29 [tokenizers/registry.py:64] Loading CachedHfTokenizer for tokenizer_mode='hf'
[0;36m(EngineCore_DP0 pid=612475)[0;0m loading file vocab.json
[0;36m(EngineCore_DP0 pid=612475)[0;0m loading file merges.txt
[0;36m(EngineCore_DP0 pid=612475)[0;0m loading file tokenizer.json
[0;36m(EngineCore_DP0 pid=612475)[0;0m loading file added_tokens.json
[0;36m(EngineCore_DP0 pid=612475)[0;0m loading file special_tokens_map.json
[0;36m(EngineCore_DP0 pid=612475)[0;0m loading file tokenizer_config.json
[0;36m(EngineCore_DP0 pid=612475)[0;0m loading file chat_template.jinja
[0;36m(EngineCore_DP0 pid=612475)[0;0m Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:29 [distributed/parallel_state.py:1192] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://172.26.46.50:34357 backend=hccl
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:29 [distributed/parallel_state.py:1234] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://172.26.46.50:34357 backend=hccl
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:29 [distributed/parallel_state.py:1278] Detected 1 nodes in the distributed environment
============================= HPU PT BRIDGE CONFIGURATION ON RANK = 0 ============= 
 PT_HPU_LAZY_MODE = 0
 PT_HPU_RECIPE_CACHE_CONFIG = ,false,1024,false
 PT_HPU_MAX_COMPOUND_OP_SIZE = 9223372036854775807
 PT_HPU_LAZY_ACC_PAR_MODE = 1
 PT_HPU_ENABLE_REFINE_DYNAMIC_SHAPES = 0
 PT_HPU_EAGER_PIPELINE_ENABLE = 1
 PT_HPU_EAGER_COLLECTIVE_PIPELINE_ENABLE = 1
 PT_HPU_ENABLE_LAZY_COLLECTIVES = 1
---------------------------: System Configuration :---------------------------
Num CPU Cores : 224
CPU RAM       : 1007 GB
------------------------------------------------------------------------------
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:30 [distributed/parallel_state.py:1445] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank N/A
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:30 [runtime.py:28] Environment:
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:30 [runtime.py:32]     hw: gaudi3
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:30 [runtime.py:32]     build: 1.23.0.695
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:30 [runtime.py:32]     engine_version: v1
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:30 [runtime.py:32]     bridge_mode: eager
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:30 [runtime.py:32]     model_type: qwen3_vl
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:30 [runtime.py:32]     prefix_caching: False
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:30 [runtime.py:32]     vllm_gaudi_commit: slokesha/Update_qwen_from_v0.14.1+9cde00c
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:30 [runtime.py:28] Features:
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:30 [runtime.py:32]     fp32_alibi_biases: True
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:30 [runtime.py:32]     fp32_softmax: False
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:30 [runtime.py:32]     fused_block_softmax_adjustment: False
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:30 [runtime.py:32]     fused_block_softmax: False
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:30 [runtime.py:32]     prompt_attn_impl: fsdpa_impl
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:30 [runtime.py:32]     skip_warmup: False
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:30 [runtime.py:32]     merged_prefill: False
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:30 [runtime.py:32]     use_contiguous_pa: True
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:30 [runtime.py:32]     use_bucketing: True
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:30 [runtime.py:32]     bucketing_strategy: linear_bucketing
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:30 [runtime.py:32]     defrag: True
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:30 [runtime.py:32]     regional_compilation: True
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:30 [runtime.py:32]     dynamic_shapes_compilation: True
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:30 [runtime.py:32]     fullgraph_compilation: False
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:30 [runtime.py:32]     unified_attn: False
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:30 [runtime.py:32]     unified_attn_dense_shared_bias: True
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:30 [runtime.py:32]     unified_attn_chunked_shared_attn: True
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:30 [runtime.py:32]     unified_attn_online_merge: True
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:30 [runtime.py:32]     unified_attn_shared_attn_chunk_size: 64
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:30 [runtime.py:32]     unified_attn_split_graphs: True
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:30 [runtime.py:32]     unified_attn_softmax_fa2: False
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:30 [runtime.py:32]     scale_adjustment: True
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:30 [runtime.py:32]     flatten_input: False
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:30 [runtime.py:32]     unified_attn_shared_cache_ratio: 1
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:30 [runtime.py:32]     high_level_profiler_enabled: False
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:30 [runtime.py:32]     track_graph_compilation: False
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:30 [runtime.py:32]     use_output_tensor_in_matmulqk: False
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:30 [runtime.py:32]     per_token_kv_scaling_support: False
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:30 [runtime.py:32]     moe_chunk: 
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:30 [runtime.py:32]     moe_token_boundary: 
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:30 [runtime.py:32]     use_dispatch_fn: False
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:30 [runtime.py:32]     use_hpu_aligned_scale: False
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:30 [runtime.py:28] User flags:
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:30 [runtime.py:32]     VLLM_EXPONENTIAL_BUCKETING: False
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:30 [runtime.py:32]     VLLM_PROMPT_BS_BUCKET_MIN: 1
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:30 [runtime.py:32]     VLLM_PROMPT_BS_BUCKET_STEP: 1
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:30 [runtime.py:32]     VLLM_PROMPT_BS_BUCKET_MAX: 1
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:30 [runtime.py:32]     VLLM_PROMPT_SEQ_BUCKET_MIN: 5120
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:30 [runtime.py:32]     VLLM_PROMPT_SEQ_BUCKET_STEP: 1024
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:30 [runtime.py:32]     VLLM_PROMPT_SEQ_BUCKET_MAX: 20480
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:30 [runtime.py:32]     VLLM_PROMPT_CTX_BUCKET_MIN: 0
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:30 [runtime.py:32]     VLLM_PROMPT_CTX_BUCKET_STEP: 12
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:30 [runtime.py:32]     VLLM_PROMPT_CTX_BUCKET_MAX: 24
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:30 [runtime.py:32]     VLLM_DECODE_BS_BUCKET_MIN: 1
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:30 [runtime.py:32]     VLLM_DECODE_BS_BUCKET_STEP: 4
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:30 [runtime.py:32]     VLLM_DECODE_BS_BUCKET_MAX: 64
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:30 [runtime.py:32]     VLLM_DECODE_BLOCK_BUCKET_MIN: 256
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:30 [runtime.py:32]     VLLM_DECODE_BLOCK_BUCKET_STEP: 128
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:30 [runtime.py:32]     VLLM_DECODE_BLOCK_BUCKET_MAX: 1152
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:30 [runtime.py:32]     EXPERIMENTAL_WEIGHT_SHARING: 0
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:30 [runtime.py:32]     PT_HPU_WEIGHT_SHARING: 0
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:30 [runtime.py:32]     RUNTIME_SCALE_PATCHING: 1
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761] model config: ModelConfig(model='/root/.cache/huggingface/hub/models--Qwen--Qwen3-VL-32B-Instruct-FP8/snapshots/4bf2c2f39c37c0fede78bede4056e1f18cdf8109/', model_weights='', runner='auto', convert='auto', tokenizer='/root/.cache/huggingface/hub/models--Qwen--Qwen3-VL-32B-Instruct-FP8/snapshots/4bf2c2f39c37c0fede78bede4056e1f18cdf8109/', tokenizer_mode='auto', trust_remote_code=True, dtype=torch.bfloat16, seed=0, hf_config=Qwen3VLConfig {
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]   "architectures": [
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]     "Qwen3VLForConditionalGeneration"
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]   ],
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]   "image_token_id": 151655,
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]   "model_type": "qwen3_vl",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]   "quantization_config": {
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]     "activation_scheme": "dynamic",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]     "fmt": "e4m3",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]     "ignored_layers": [
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "lm_head",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.merger.linear_fc1",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.merger.linear_fc2",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.merger.norm",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.patch_embed.proj",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.pos_embed",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.merger.linear_fc1",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.merger.linear_fc2",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.merger.norm",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.patch_embed.proj",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.pos_embed",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.blocks.0.attn.proj",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.blocks.0.attn.qkv",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.blocks.0.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.blocks.0.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.blocks.0.attn.proj",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.blocks.0.attn.qkv_proj",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.blocks.0.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.blocks.0.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.blocks.1.attn.proj",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.blocks.1.attn.qkv",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.blocks.1.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.blocks.1.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.blocks.1.attn.proj",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.blocks.1.attn.qkv_proj",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.blocks.1.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.blocks.1.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.blocks.2.attn.proj",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.blocks.2.attn.qkv",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.blocks.2.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.blocks.2.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.blocks.2.attn.proj",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.blocks.2.attn.qkv_proj",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.blocks.2.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.blocks.2.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.blocks.3.attn.proj",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.blocks.3.attn.qkv",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.blocks.3.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.blocks.3.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.blocks.3.attn.proj",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.blocks.3.attn.qkv_proj",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.blocks.3.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.blocks.3.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.blocks.4.attn.proj",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.blocks.4.attn.qkv",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.blocks.4.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.blocks.4.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.blocks.4.attn.proj",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.blocks.4.attn.qkv_proj",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.blocks.4.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.blocks.4.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.blocks.5.attn.proj",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.blocks.5.attn.qkv",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.blocks.5.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.blocks.5.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.blocks.5.attn.proj",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.blocks.5.attn.qkv_proj",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.blocks.5.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.blocks.5.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.blocks.6.attn.proj",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.blocks.6.attn.qkv",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.blocks.6.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.blocks.6.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.blocks.6.attn.proj",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.blocks.6.attn.qkv_proj",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.blocks.6.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.blocks.6.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.blocks.7.attn.proj",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.blocks.7.attn.qkv",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.blocks.7.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.blocks.7.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.blocks.7.attn.proj",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.blocks.7.attn.qkv_proj",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.blocks.7.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.blocks.7.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.blocks.8.attn.proj",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.blocks.8.attn.qkv",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.blocks.8.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.blocks.8.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.blocks.8.attn.proj",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.blocks.8.attn.qkv_proj",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.blocks.8.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.blocks.8.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.blocks.9.attn.proj",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.blocks.9.attn.qkv",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.blocks.9.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.blocks.9.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.blocks.9.attn.proj",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.blocks.9.attn.qkv_proj",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.blocks.9.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.blocks.9.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.blocks.10.attn.proj",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.blocks.10.attn.qkv",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.blocks.10.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.blocks.10.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.blocks.10.attn.proj",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.blocks.10.attn.qkv_proj",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.blocks.10.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.blocks.10.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.blocks.11.attn.proj",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.blocks.11.attn.qkv",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.blocks.11.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.blocks.11.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.blocks.11.attn.proj",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.blocks.11.attn.qkv_proj",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.blocks.11.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.blocks.11.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.blocks.12.attn.proj",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.blocks.12.attn.qkv",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.blocks.12.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.blocks.12.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.blocks.12.attn.proj",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.blocks.12.attn.qkv_proj",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.blocks.12.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.blocks.12.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.blocks.13.attn.proj",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.blocks.13.attn.qkv",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.blocks.13.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.blocks.13.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.blocks.13.attn.proj",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.blocks.13.attn.qkv_proj",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.blocks.13.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.blocks.13.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.blocks.14.attn.proj",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.blocks.14.attn.qkv",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.blocks.14.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.blocks.14.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.blocks.14.attn.proj",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.blocks.14.attn.qkv_proj",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.blocks.14.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.blocks.14.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.blocks.15.attn.proj",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.blocks.15.attn.qkv",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.blocks.15.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.blocks.15.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.blocks.15.attn.proj",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.blocks.15.attn.qkv_proj",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.blocks.15.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.blocks.15.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.blocks.16.attn.proj",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.blocks.16.attn.qkv",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.blocks.16.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.blocks.16.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.blocks.16.attn.proj",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.blocks.16.attn.qkv_proj",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.blocks.16.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.blocks.16.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.blocks.17.attn.proj",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.blocks.17.attn.qkv",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.blocks.17.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.blocks.17.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.blocks.17.attn.proj",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.blocks.17.attn.qkv_proj",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.blocks.17.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.blocks.17.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.blocks.18.attn.proj",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.blocks.18.attn.qkv",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.blocks.18.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.blocks.18.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.blocks.18.attn.proj",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.blocks.18.attn.qkv_proj",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.blocks.18.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.blocks.18.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.blocks.19.attn.proj",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.blocks.19.attn.qkv",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.blocks.19.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.blocks.19.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.blocks.19.attn.proj",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.blocks.19.attn.qkv_proj",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.blocks.19.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.blocks.19.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.blocks.20.attn.proj",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.blocks.20.attn.qkv",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.blocks.20.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.blocks.20.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.blocks.20.attn.proj",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.blocks.20.attn.qkv_proj",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.blocks.20.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.blocks.20.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.blocks.21.attn.proj",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.blocks.21.attn.qkv",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.blocks.21.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.blocks.21.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.blocks.21.attn.proj",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.blocks.21.attn.qkv_proj",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.blocks.21.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.blocks.21.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.blocks.22.attn.proj",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.blocks.22.attn.qkv",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.blocks.22.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.blocks.22.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.blocks.22.attn.proj",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.blocks.22.attn.qkv_proj",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.blocks.22.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.blocks.22.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.blocks.23.attn.proj",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.blocks.23.attn.qkv",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.blocks.23.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.blocks.23.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.blocks.23.attn.proj",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.blocks.23.attn.qkv_proj",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.blocks.23.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.blocks.23.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.blocks.24.attn.proj",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.blocks.24.attn.qkv",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.blocks.24.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.blocks.24.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.blocks.24.attn.proj",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.blocks.24.attn.qkv_proj",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.blocks.24.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.blocks.24.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.blocks.25.attn.proj",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.blocks.25.attn.qkv",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.blocks.25.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.blocks.25.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.blocks.25.attn.proj",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.blocks.25.attn.qkv_proj",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.blocks.25.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.blocks.25.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.blocks.26.attn.proj",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.blocks.26.attn.qkv",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.blocks.26.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.blocks.26.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.blocks.26.attn.proj",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.blocks.26.attn.qkv_proj",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.blocks.26.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.blocks.26.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.deepstack_merger_list.0.linear_fc1",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.deepstack_merger_list.0.linear_fc2",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.deepstack_merger_list.0.norm",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.deepstack_merger_list.0.linear_fc1",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.deepstack_merger_list.0.linear_fc2",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.deepstack_merger_list.0.norm",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.deepstack_merger_list.1.linear_fc1",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.deepstack_merger_list.1.linear_fc2",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.deepstack_merger_list.1.norm",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.deepstack_merger_list.1.linear_fc1",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.deepstack_merger_list.1.linear_fc2",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.deepstack_merger_list.1.norm",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.deepstack_merger_list.2.linear_fc1",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.deepstack_merger_list.2.linear_fc2",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "model.visual.deepstack_merger_list.2.norm",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.deepstack_merger_list.2.linear_fc1",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.deepstack_merger_list.2.linear_fc2",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "visual.deepstack_merger_list.2.norm"
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]     ],
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]     "quant_method": "fp8",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]     "weight_block_size": [
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       128,
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       128
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]     ]
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]   },
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]   "text_config": {
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]     "attention_bias": false,
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]     "attention_dropout": 0.0,
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]     "bos_token_id": 151643,
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]     "dtype": "bfloat16",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]     "eos_token_id": 151645,
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]     "head_dim": 128,
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]     "hidden_act": "silu",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]     "hidden_size": 5120,
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]     "initializer_range": 0.02,
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]     "intermediate_size": 25600,
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]     "max_position_embeddings": 262144,
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]     "model_type": "qwen3_vl_text",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]     "num_attention_heads": 64,
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]     "num_hidden_layers": 64,
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]     "num_key_value_heads": 8,
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]     "rms_norm_eps": 1e-06,
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]     "rope_parameters": {
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "mrope_interleaved": true,
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "mrope_section": [
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]         24,
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]         20,
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]         20
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       ],
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "rope_theta": 5000000,
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "rope_type": "default"
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]     },
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]     "rope_scaling": {
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "mrope_interleaved": true,
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "mrope_section": [
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]         24,
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]         20,
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]         20
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       ],
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "rope_theta": 5000000,
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       "rope_type": "default"
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]     },
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]     "rope_theta": 5000000,
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]     "use_cache": true,
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]     "vocab_size": 151936
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]   },
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]   "tie_word_embeddings": false,
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]   "transformers_version": "4.57.6",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]   "video_token_id": 151656,
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]   "vision_config": {
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]     "deepstack_visual_indexes": [
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       8,
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       16,
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       24
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]     ],
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]     "depth": 27,
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]     "hidden_act": "gelu_pytorch_tanh",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]     "hidden_size": 1152,
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]     "in_channels": 3,
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]     "initializer_range": 0.02,
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]     "intermediate_size": 4304,
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]     "model_type": "qwen3_vl",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]     "num_heads": 16,
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]     "num_position_embeddings": 2304,
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]     "out_hidden_size": 5120,
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]     "patch_size": 16,
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]     "spatial_merge_size": 2,
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]     "temporal_patch_size": 2
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]   },
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]   "vision_end_token_id": 151653,
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]   "vision_start_token_id": 151652
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761] }
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761] , hf_text_config=Qwen3VLTextConfig {
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]   "attention_bias": false,
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]   "attention_dropout": 0.0,
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]   "bos_token_id": 151643,
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]   "dtype": "bfloat16",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]   "eos_token_id": 151645,
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]   "head_dim": 128,
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]   "hidden_act": "silu",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]   "hidden_size": 5120,
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]   "initializer_range": 0.02,
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]   "intermediate_size": 25600,
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]   "max_position_embeddings": 262144,
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]   "model_type": "qwen3_vl_text",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]   "num_attention_heads": 64,
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]   "num_hidden_layers": 64,
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]   "num_key_value_heads": 8,
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]   "rms_norm_eps": 1e-06,
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]   "rope_parameters": {
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]     "mrope_interleaved": true,
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]     "mrope_section": [
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       24,
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       20,
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       20
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]     ],
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]     "rope_theta": 5000000,
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]     "rope_type": "default"
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]   },
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]   "rope_scaling": {
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]     "mrope_interleaved": true,
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]     "mrope_section": [
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       24,
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       20,
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]       20
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]     ],
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]     "rope_theta": 5000000,
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]     "rope_type": "default"
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]   },
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]   "rope_theta": 5000000,
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]   "tie_word_embeddings": false,
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]   "transformers_version": "4.57.6",
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]   "use_cache": true,
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761]   "vocab_size": 151936
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761] }
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [hpu_model_runner.py:761] , hf_config_path=None, allowed_local_media_path='', allowed_media_domains=None, revision=None, code_revision=None, tokenizer_revision=None, max_model_len=32768, spec_target_max_model_len=None, quantization='fp8', allow_deprecated_quantization=False, enforce_eager=False, enable_return_routed_experts=False, max_logprobs=20, logprobs_mode='raw_logprobs', disable_sliding_window=False, disable_cascade_attn=False, skip_tokenizer_init=False, enable_prompt_embeds=False, served_model_name='Qwen/Qwen3-VL-32B-Instruct-FP8', config_format='auto', hf_token=None, hf_overrides={}, logits_processor_pattern=None, generation_config='auto', override_generation_config={}, enable_sleep_mode=False, model_impl='auto', override_attention_dtype=None, logits_processors=None, io_processor_plugin=None, pooler_config=None, multimodal_config=MultiModalConfig(limit_per_prompt={'image': ImageDummyOptions(count=20, width=1280, height=704)}, enable_mm_embeds=False, media_io_kwargs={}, mm_processor_kwargs={'size': {'shortest_edge': 65536, 'longest_edge': 2097152}}, mm_processor_cache_gb=4.0, mm_processor_cache_type='lru', mm_shm_cache_max_object_size_mb=128, mm_encoder_only=False, mm_encoder_tp_mode='weights', mm_encoder_attn_backend=None, interleave_mm_strings=False, skip_mm_profiling=False, video_pruning_rate=None))
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:30 [platform.py:65] Using HPUAttentionV1 backend.
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [v1/sample/logits_processor/__init__.py:63] No logitsprocs plugins installed (group vllm.logits_processors).
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:30 [hpu_model_runner.py:880] Bucketing is ON.
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:30 [hpu_model_runner.py:3994] Starting to load model /root/.cache/huggingface/hub/models--Qwen--Qwen3-VL-32B-Instruct-FP8/snapshots/4bf2c2f39c37c0fede78bede4056e1f18cdf8109/...
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: Conv3dLayer using <class 'vllm_gaudi.ops.hpu_conv.HPUConv3dLayer'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RotaryEmbedding using <class 'vllm_gaudi.ops.hpu_rotary_embedding.HPURotaryEmbedding'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:30 [platforms/interface.py:267] Using default backend AttentionBackendEnum.TORCH_SDPA for vit attention
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:30 [model_executor/.../attention/mm_encoder_attention.py:77] Using AttentionBackendEnum.TORCH_SDPA for MMEncoderAttention.
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [utils/deep_gemm.py:86] DeepGEMM E8M0 disabled: DeepGEMM not supported on this system.
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: MRotaryEmbedding using <class 'vllm_gaudi.ops.hpu_rotary_embedding.HPUMRotaryEmbedding'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:30 [platform.py:65] Using HPUAttentionV1 backend.
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: Conv3dLayer using <class 'vllm_gaudi.ops.hpu_conv.HPUConv3dLayer'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/custom_op.py:113] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [config/compilation.py:1039] enabled custom ops: Counter({'RMSNorm': 257, 'quant_fp8': 256, 'apply_rotary_emb': 137, 'MMEncoderAttention': 108, 'silu_and_mul': 64, 'Conv3dLayer': 2, 'RotaryEmbedding': 1, 'vocab_parallel_embedding': 1, 'MRotaryEmbedding': 1, 'parallel_lm_head': 1, 'logits_processor': 1})
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [config/compilation.py:1040] disabled custom ops: Counter()
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:30 [model_executor/model_loader/base_loader.py:56] Loading weights on hpu ...
[0;36m(EngineCore_DP0 pid=612475)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/7 [00:00<?, ?it/s]
[0;36m(EngineCore_DP0 pid=612475)[0;0m Loading safetensors checkpoint shards:  14% Completed | 1/7 [00:00<00:03,  1.62it/s]
[0;36m(EngineCore_DP0 pid=612475)[0;0m Loading safetensors checkpoint shards:  29% Completed | 2/7 [00:01<00:03,  1.25it/s]
[0;36m(EngineCore_DP0 pid=612475)[0;0m Loading safetensors checkpoint shards:  43% Completed | 3/7 [00:02<00:03,  1.14it/s]
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:07:33 [model_executor/models/utils.py:222] Loaded weight lm_head.weight with shape torch.Size([151936, 5120])
[0;36m(EngineCore_DP0 pid=612475)[0;0m Loading safetensors checkpoint shards:  57% Completed | 4/7 [00:03<00:02,  1.06it/s]
[0;36m(EngineCore_DP0 pid=612475)[0;0m Loading safetensors checkpoint shards:  71% Completed | 5/7 [00:04<00:01,  1.05it/s]
[0;36m(EngineCore_DP0 pid=612475)[0;0m Loading safetensors checkpoint shards:  86% Completed | 6/7 [00:05<00:00,  1.04it/s]
[0;36m(EngineCore_DP0 pid=612475)[0;0m Loading safetensors checkpoint shards: 100% Completed | 7/7 [00:06<00:00,  1.03it/s]
[0;36m(EngineCore_DP0 pid=612475)[0;0m Loading safetensors checkpoint shards: 100% Completed | 7/7 [00:06<00:00,  1.08it/s]
[0;36m(EngineCore_DP0 pid=612475)[0;0m 
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:37 [model_executor/model_loader/default_loader.py:291] Loading weights took 6.54 seconds
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:38 [hpu_model_runner.py:4000] Loading model weights took 34.7600 GB
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:38 [hpu_model_runner.py:4043] Wrapping in HPUGraph took 0.0000 GB
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:38 [hpu_model_runner.py:4071] Compilation took 0.0000 GB
[0;36m(APIServer pid=612145)[0;0m DEBUG 02-06 04:07:38 [v1/engine/utils.py:982] Waiting for 1 local, 0 remote core engine proc(s) to start.
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:38 [hpu_worker.py:251] Model profiling run took 0 B of device memory (34.8 GiB/126.5 GiB used) and -176 KiB of host memory (79.2 GiB/1007 GiB used)
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:38 [hpu_worker.py:275] Free device memory: 91.74 GiB, 68.81 GiB usable (gpu_memory_utilization=0.75), 27.52 GiB reserved for HPUGraphs (VLLM_GRAPH_RESERVED_MEM=0.4), 32 MiB reserved for KV cache dummy block 41.25 GiB reserved for usable KV cache
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:39 [v1/core/kv_cache_utils.py:1307] GPU KV cache size: 168,960 tokens
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:39 [v1/core/kv_cache_utils.py:1312] Maximum concurrency for 32,768 tokens per request: 5.16x
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:39 [hpu_worker.py:303] Usable num_blocks: 1320, actual allocated num_blocks: 169088 (_PAD_BLOCK_ID=0, _PAD_SLOT_ID=-1)
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:39 [hpu_worker.py:306] Initializing cache engine took 41.28 GiB of device memory (76.05 GiB/126.5 GiB used) and 752 KiB of host memory (79.2 GiB/1007 GiB used)
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:39 [linear.py:116] VLLM_PROMPT_BS_BUCKET_MIN=1 (default:1)
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:39 [linear.py:116] VLLM_PROMPT_BS_BUCKET_STEP=1 (default:1)
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:39 [linear.py:116] VLLM_PROMPT_BS_BUCKET_MAX=1 (default:1)
[0;36m(EngineCore_DP0 pid=612475)[0;0m WARNING 02-06 04:07:39 [linear.py:113] VLLM_PROMPT_QUERY_BUCKET_MIN not set, using VLLM_PROMPT_SEQ_BUCKET_MIN value (5120) instead. This fallback behavior is deprecated and will be removed in v0.12.0.
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:39 [linear.py:116] VLLM_PROMPT_QUERY_BUCKET_MIN=5120 (default:128)
[0;36m(EngineCore_DP0 pid=612475)[0;0m WARNING 02-06 04:07:39 [linear.py:113] VLLM_PROMPT_QUERY_BUCKET_STEP not set, using VLLM_PROMPT_SEQ_BUCKET_STEP value (1024) instead. This fallback behavior is deprecated and will be removed in v0.12.0.
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:39 [linear.py:116] VLLM_PROMPT_QUERY_BUCKET_STEP=1024 (default:128)
[0;36m(EngineCore_DP0 pid=612475)[0;0m WARNING 02-06 04:07:39 [linear.py:113] VLLM_PROMPT_QUERY_BUCKET_MAX not set, using VLLM_PROMPT_SEQ_BUCKET_MAX value (20480) instead. This fallback behavior is deprecated and will be removed in v0.12.0.
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:39 [linear.py:116] VLLM_PROMPT_QUERY_BUCKET_MAX=20480 (default:32768)
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:39 [linear.py:116] VLLM_PROMPT_CTX_BUCKET_MIN=0 (default:0)
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:39 [linear.py:116] VLLM_PROMPT_CTX_BUCKET_STEP=12 (default:1)
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:39 [linear.py:116] VLLM_PROMPT_CTX_BUCKET_MAX=24 (default:216)
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:39 [linear.py:52] Prompt bucket config (min, step, max_warmup) bs:[1, 1, 1], query:[5120, 1024, 20480], blocks:[0, 12, 24]
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:39 [common.py:222] Generated 48 prompt buckets [bs, query, num_blocks]: [(1, 5120, 0), (1, 5120, 12), (1, 5120, 216), (1, 6144, 0), (1, 6144, 12), (1, 6144, 208), (1, 7168, 0), (1, 7168, 12), (1, 7168, 200), (1, 8192, 0), (1, 8192, 12), (1, 8192, 192), (1, 9216, 0), (1, 9216, 12), (1, 9216, 184), (1, 10240, 0), (1, 10240, 12), (1, 10240, 176), (1, 11264, 0), (1, 11264, 12), (1, 11264, 168), (1, 12288, 0), (1, 12288, 12), (1, 12288, 160), (1, 13312, 0), (1, 13312, 12), (1, 13312, 152), (1, 14336, 0), (1, 14336, 12), (1, 14336, 144), (1, 15360, 0), (1, 15360, 12), (1, 15360, 136), (1, 16384, 0), (1, 16384, 12), (1, 16384, 128), (1, 17408, 0), (1, 17408, 12), (1, 17408, 120), (1, 18432, 0), (1, 18432, 12), (1, 18432, 112), (1, 19456, 0), (1, 19456, 12), (1, 19456, 104), (1, 20480, 0), (1, 20480, 12), (1, 20480, 96)]
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:39 [linear.py:116] VLLM_DECODE_BS_BUCKET_MIN=1 (default:1)
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:39 [linear.py:116] VLLM_DECODE_BS_BUCKET_STEP=4 (default:32)
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:39 [linear.py:116] VLLM_DECODE_BS_BUCKET_MAX=64 (default:256)
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:39 [linear.py:116] VLLM_DECODE_BLOCK_BUCKET_MIN=256 (default:1)
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:39 [linear.py:116] VLLM_DECODE_BLOCK_BUCKET_STEP=128 (default:128)
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:39 [linear.py:116] VLLM_DECODE_BLOCK_BUCKET_MAX=1152 (default:1320)
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:39 [linear.py:81] Decode bucket config (min, step, max_warmup) bs:[1, 4, 64], blocks:[256, 128, 1152]
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:39 [common.py:222] Generated 162 decode buckets [bs, query, num_blocks]: [(1, 1, 256), (1, 1, 384), (1, 1, 512), (1, 1, 640), (1, 1, 768), (1, 1, 896), (1, 1, 1024), (1, 1, 1152), (1, 1, 1320), (2, 1, 256), (2, 1, 384), (2, 1, 512), (2, 1, 640), (2, 1, 768), (2, 1, 896), (2, 1, 1024), (2, 1, 1152), (2, 1, 1320), (4, 1, 256), (4, 1, 384), (4, 1, 512), (4, 1, 640), (4, 1, 768), (4, 1, 896), (4, 1, 1024), (4, 1, 1152), (4, 1, 1320), (8, 1, 256), (8, 1, 384), (8, 1, 512), (8, 1, 640), (8, 1, 768), (8, 1, 896), (8, 1, 1024), (8, 1, 1152), (8, 1, 1320), (12, 1, 256), (12, 1, 384), (12, 1, 512), (12, 1, 640), (12, 1, 768), (12, 1, 896), (12, 1, 1024), (12, 1, 1152), (12, 1, 1320), (16, 1, 256), (16, 1, 384), (16, 1, 512), (16, 1, 640), (16, 1, 768), (16, 1, 896), (16, 1, 1024), (16, 1, 1152), (16, 1, 1320), (20, 1, 256), (20, 1, 384), (20, 1, 512), (20, 1, 640), (20, 1, 768), (20, 1, 896), (20, 1, 1024), (20, 1, 1152), (20, 1, 1320), (24, 1, 256), (24, 1, 384), (24, 1, 512), (24, 1, 640), (24, 1, 768), (24, 1, 896), (24, 1, 1024), (24, 1, 1152), (24, 1, 1320), (28, 1, 256), (28, 1, 384), (28, 1, 512), (28, 1, 640), (28, 1, 768), (28, 1, 896), (28, 1, 1024), (28, 1, 1152), (28, 1, 1320), (32, 1, 256), (32, 1, 384), (32, 1, 512), (32, 1, 640), (32, 1, 768), (32, 1, 896), (32, 1, 1024), (32, 1, 1152), (32, 1, 1320), (36, 1, 256), (36, 1, 384), (36, 1, 512), (36, 1, 640), (36, 1, 768), (36, 1, 896), (36, 1, 1024), (36, 1, 1152), (36, 1, 1320), (40, 1, 256), (40, 1, 384), (40, 1, 512), (40, 1, 640), (40, 1, 768), (40, 1, 896), (40, 1, 1024), (40, 1, 1152), (40, 1, 1320), (44, 1, 256), (44, 1, 384), (44, 1, 512), (44, 1, 640), (44, 1, 768), (44, 1, 896), (44, 1, 1024), (44, 1, 1152), (44, 1, 1320), (48, 1, 256), (48, 1, 384), (48, 1, 512), (48, 1, 640), (48, 1, 768), (48, 1, 896), (48, 1, 1024), (48, 1, 1152), (48, 1, 1320), (52, 1, 256), (52, 1, 384), (52, 1, 512), (52, 1, 640), (52, 1, 768), (52, 1, 896), (52, 1, 1024), (52, 1, 1152), (52, 1, 1320), (56, 1, 256), (56, 1, 384), (56, 1, 512), (56, 1, 640), (56, 1, 768), (56, 1, 896), (56, 1, 1024), (56, 1, 1152), (56, 1, 1320), (60, 1, 256), (60, 1, 384), (60, 1, 512), (60, 1, 640), (60, 1, 768), (60, 1, 896), (60, 1, 1024), (60, 1, 1152), (60, 1, 1320), (64, 1, 256), (64, 1, 384), (64, 1, 512), (64, 1, 640), (64, 1, 768), (64, 1, 896), (64, 1, 1024), (64, 1, 1152), (64, 1, 1320)]
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:39 [hpu_model_runner.py:5023] Multimodal bucket : [196, 256, 441, 480, 576, 900, 1156]
[0;36m(EngineCore_DP0 pid=612475)[0;0m loading configuration file /root/.cache/huggingface/hub/models--Qwen--Qwen3-VL-32B-Instruct-FP8/snapshots/4bf2c2f39c37c0fede78bede4056e1f18cdf8109/preprocessor_config.json
[0;36m(EngineCore_DP0 pid=612475)[0;0m Image processor Qwen2VLImageProcessorFast {
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "crop_size": null,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "data_format": "channels_first",
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "default_to_square": true,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "device": null,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "disable_grouping": null,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "do_center_crop": null,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "do_convert_rgb": true,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "do_normalize": true,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "do_pad": null,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "do_rescale": true,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "do_resize": true,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "image_mean": [
[0;36m(EngineCore_DP0 pid=612475)[0;0m     0.5,
[0;36m(EngineCore_DP0 pid=612475)[0;0m     0.5,
[0;36m(EngineCore_DP0 pid=612475)[0;0m     0.5
[0;36m(EngineCore_DP0 pid=612475)[0;0m   ],
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "image_processor_type": "Qwen2VLImageProcessorFast",
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "image_std": [
[0;36m(EngineCore_DP0 pid=612475)[0;0m     0.5,
[0;36m(EngineCore_DP0 pid=612475)[0;0m     0.5,
[0;36m(EngineCore_DP0 pid=612475)[0;0m     0.5
[0;36m(EngineCore_DP0 pid=612475)[0;0m   ],
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "input_data_format": null,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "max_pixels": null,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "merge_size": 2,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "min_pixels": null,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "pad_size": null,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "patch_size": 16,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "processor_class": "Qwen3VLProcessor",
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "resample": 3,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "rescale_factor": 0.00392156862745098,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "return_tensors": null,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "size": {
[0;36m(EngineCore_DP0 pid=612475)[0;0m     "longest_edge": 16777216,
[0;36m(EngineCore_DP0 pid=612475)[0;0m     "shortest_edge": 65536
[0;36m(EngineCore_DP0 pid=612475)[0;0m   },
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "temporal_patch_size": 2
[0;36m(EngineCore_DP0 pid=612475)[0;0m }
[0;36m(EngineCore_DP0 pid=612475)[0;0m 
[0;36m(EngineCore_DP0 pid=612475)[0;0m loading file vocab.json
[0;36m(EngineCore_DP0 pid=612475)[0;0m loading file merges.txt
[0;36m(EngineCore_DP0 pid=612475)[0;0m loading file tokenizer.json
[0;36m(EngineCore_DP0 pid=612475)[0;0m loading file added_tokens.json
[0;36m(EngineCore_DP0 pid=612475)[0;0m loading file special_tokens_map.json
[0;36m(EngineCore_DP0 pid=612475)[0;0m loading file tokenizer_config.json
[0;36m(EngineCore_DP0 pid=612475)[0;0m loading file chat_template.jinja
[0;36m(EngineCore_DP0 pid=612475)[0;0m Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[0;36m(EngineCore_DP0 pid=612475)[0;0m loading configuration file /root/.cache/huggingface/hub/models--Qwen--Qwen3-VL-32B-Instruct-FP8/snapshots/4bf2c2f39c37c0fede78bede4056e1f18cdf8109/video_preprocessor_config.json
[0;36m(EngineCore_DP0 pid=612475)[0;0m Video processor Qwen3VLVideoProcessor {
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "crop_size": null,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "data_format": "channels_first",
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "default_to_square": true,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "device": null,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "do_center_crop": null,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "do_convert_rgb": true,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "do_normalize": true,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "do_rescale": true,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "do_resize": true,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "do_sample_frames": true,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "fps": 2,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "image_mean": [
[0;36m(EngineCore_DP0 pid=612475)[0;0m     0.5,
[0;36m(EngineCore_DP0 pid=612475)[0;0m     0.5,
[0;36m(EngineCore_DP0 pid=612475)[0;0m     0.5
[0;36m(EngineCore_DP0 pid=612475)[0;0m   ],
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "image_std": [
[0;36m(EngineCore_DP0 pid=612475)[0;0m     0.5,
[0;36m(EngineCore_DP0 pid=612475)[0;0m     0.5,
[0;36m(EngineCore_DP0 pid=612475)[0;0m     0.5
[0;36m(EngineCore_DP0 pid=612475)[0;0m   ],
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "input_data_format": null,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "max_frames": 768,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "merge_size": 2,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "min_frames": 4,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "num_frames": null,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "pad_size": null,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "patch_size": 16,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "processor_class": "Qwen3VLProcessor",
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "resample": 3,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "rescale_factor": 0.00392156862745098,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "return_metadata": false,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "size": {
[0;36m(EngineCore_DP0 pid=612475)[0;0m     "longest_edge": 25165824,
[0;36m(EngineCore_DP0 pid=612475)[0;0m     "shortest_edge": 4096
[0;36m(EngineCore_DP0 pid=612475)[0;0m   },
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "temporal_patch_size": 2,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "video_metadata": null,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "video_processor_type": "Qwen3VLVideoProcessor"
[0;36m(EngineCore_DP0 pid=612475)[0;0m }
[0;36m(EngineCore_DP0 pid=612475)[0;0m 
[0;36m(EngineCore_DP0 pid=612475)[0;0m loading configuration file None
[0;36m(EngineCore_DP0 pid=612475)[0;0m Processor Qwen3VLProcessor:
[0;36m(EngineCore_DP0 pid=612475)[0;0m - image_processor: Qwen2VLImageProcessorFast {
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "crop_size": null,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "data_format": "channels_first",
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "default_to_square": true,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "device": null,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "disable_grouping": null,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "do_center_crop": null,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "do_convert_rgb": true,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "do_normalize": true,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "do_pad": null,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "do_rescale": true,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "do_resize": true,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "image_mean": [
[0;36m(EngineCore_DP0 pid=612475)[0;0m     0.5,
[0;36m(EngineCore_DP0 pid=612475)[0;0m     0.5,
[0;36m(EngineCore_DP0 pid=612475)[0;0m     0.5
[0;36m(EngineCore_DP0 pid=612475)[0;0m   ],
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "image_processor_type": "Qwen2VLImageProcessorFast",
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "image_std": [
[0;36m(EngineCore_DP0 pid=612475)[0;0m     0.5,
[0;36m(EngineCore_DP0 pid=612475)[0;0m     0.5,
[0;36m(EngineCore_DP0 pid=612475)[0;0m     0.5
[0;36m(EngineCore_DP0 pid=612475)[0;0m   ],
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "input_data_format": null,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "max_pixels": null,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "merge_size": 2,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "min_pixels": null,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "pad_size": null,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "patch_size": 16,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "processor_class": "Qwen3VLProcessor",
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "resample": 3,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "rescale_factor": 0.00392156862745098,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "return_tensors": null,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "size": {
[0;36m(EngineCore_DP0 pid=612475)[0;0m     "longest_edge": 16777216,
[0;36m(EngineCore_DP0 pid=612475)[0;0m     "shortest_edge": 65536
[0;36m(EngineCore_DP0 pid=612475)[0;0m   },
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "temporal_patch_size": 2
[0;36m(EngineCore_DP0 pid=612475)[0;0m }
[0;36m(EngineCore_DP0 pid=612475)[0;0m 
[0;36m(EngineCore_DP0 pid=612475)[0;0m - tokenizer: Qwen2TokenizerFast(name_or_path='/root/.cache/huggingface/hub/models--Qwen--Qwen3-VL-32B-Instruct-FP8/snapshots/4bf2c2f39c37c0fede78bede4056e1f18cdf8109/', vocab_size=151643, model_max_length=262144, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
[0;36m(EngineCore_DP0 pid=612475)[0;0m 	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
[0;36m(EngineCore_DP0 pid=612475)[0;0m 	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
[0;36m(EngineCore_DP0 pid=612475)[0;0m 	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
[0;36m(EngineCore_DP0 pid=612475)[0;0m 	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
[0;36m(EngineCore_DP0 pid=612475)[0;0m 	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
[0;36m(EngineCore_DP0 pid=612475)[0;0m 	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
[0;36m(EngineCore_DP0 pid=612475)[0;0m 	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
[0;36m(EngineCore_DP0 pid=612475)[0;0m 	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
[0;36m(EngineCore_DP0 pid=612475)[0;0m 	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
[0;36m(EngineCore_DP0 pid=612475)[0;0m 	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
[0;36m(EngineCore_DP0 pid=612475)[0;0m 	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
[0;36m(EngineCore_DP0 pid=612475)[0;0m 	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
[0;36m(EngineCore_DP0 pid=612475)[0;0m 	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
[0;36m(EngineCore_DP0 pid=612475)[0;0m 	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
[0;36m(EngineCore_DP0 pid=612475)[0;0m 	151657: AddedToken("<tool_call>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
[0;36m(EngineCore_DP0 pid=612475)[0;0m 	151658: AddedToken("</tool_call>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
[0;36m(EngineCore_DP0 pid=612475)[0;0m 	151659: AddedToken("<|fim_prefix|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
[0;36m(EngineCore_DP0 pid=612475)[0;0m 	151660: AddedToken("<|fim_middle|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
[0;36m(EngineCore_DP0 pid=612475)[0;0m 	151661: AddedToken("<|fim_suffix|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
[0;36m(EngineCore_DP0 pid=612475)[0;0m 	151662: AddedToken("<|fim_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
[0;36m(EngineCore_DP0 pid=612475)[0;0m 	151663: AddedToken("<|repo_name|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
[0;36m(EngineCore_DP0 pid=612475)[0;0m 	151664: AddedToken("<|file_sep|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
[0;36m(EngineCore_DP0 pid=612475)[0;0m 	151665: AddedToken("<tool_response>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
[0;36m(EngineCore_DP0 pid=612475)[0;0m 	151666: AddedToken("</tool_response>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
[0;36m(EngineCore_DP0 pid=612475)[0;0m 	151667: AddedToken("<think>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
[0;36m(EngineCore_DP0 pid=612475)[0;0m 	151668: AddedToken("</think>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
[0;36m(EngineCore_DP0 pid=612475)[0;0m }
[0;36m(EngineCore_DP0 pid=612475)[0;0m )
[0;36m(EngineCore_DP0 pid=612475)[0;0m - video_processor: Qwen3VLVideoProcessor {
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "crop_size": null,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "data_format": "channels_first",
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "default_to_square": true,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "device": null,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "do_center_crop": null,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "do_convert_rgb": true,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "do_normalize": true,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "do_rescale": true,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "do_resize": true,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "do_sample_frames": true,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "fps": 2,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "image_mean": [
[0;36m(EngineCore_DP0 pid=612475)[0;0m     0.5,
[0;36m(EngineCore_DP0 pid=612475)[0;0m     0.5,
[0;36m(EngineCore_DP0 pid=612475)[0;0m     0.5
[0;36m(EngineCore_DP0 pid=612475)[0;0m   ],
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "image_std": [
[0;36m(EngineCore_DP0 pid=612475)[0;0m     0.5,
[0;36m(EngineCore_DP0 pid=612475)[0;0m     0.5,
[0;36m(EngineCore_DP0 pid=612475)[0;0m     0.5
[0;36m(EngineCore_DP0 pid=612475)[0;0m   ],
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "input_data_format": null,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "max_frames": 768,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "merge_size": 2,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "min_frames": 4,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "num_frames": null,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "pad_size": null,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "patch_size": 16,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "processor_class": "Qwen3VLProcessor",
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "resample": 3,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "rescale_factor": 0.00392156862745098,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "return_metadata": false,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "size": {
[0;36m(EngineCore_DP0 pid=612475)[0;0m     "longest_edge": 25165824,
[0;36m(EngineCore_DP0 pid=612475)[0;0m     "shortest_edge": 4096
[0;36m(EngineCore_DP0 pid=612475)[0;0m   },
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "temporal_patch_size": 2,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "video_metadata": null,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "video_processor_type": "Qwen3VLVideoProcessor"
[0;36m(EngineCore_DP0 pid=612475)[0;0m }
[0;36m(EngineCore_DP0 pid=612475)[0;0m 
[0;36m(EngineCore_DP0 pid=612475)[0;0m 
[0;36m(EngineCore_DP0 pid=612475)[0;0m {
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "processor_class": "Qwen3VLProcessor"
[0;36m(EngineCore_DP0 pid=612475)[0;0m }
[0;36m(EngineCore_DP0 pid=612475)[0;0m 
[0;36m(EngineCore_DP0 pid=612475)[0;0m loading configuration file /root/.cache/huggingface/hub/models--Qwen--Qwen3-VL-32B-Instruct-FP8/snapshots/4bf2c2f39c37c0fede78bede4056e1f18cdf8109/preprocessor_config.json
[0;36m(EngineCore_DP0 pid=612475)[0;0m Image processor Qwen2VLImageProcessorFast {
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "crop_size": null,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "data_format": "channels_first",
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "default_to_square": true,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "device": null,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "disable_grouping": null,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "do_center_crop": null,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "do_convert_rgb": true,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "do_normalize": true,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "do_pad": null,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "do_rescale": true,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "do_resize": true,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "image_mean": [
[0;36m(EngineCore_DP0 pid=612475)[0;0m     0.5,
[0;36m(EngineCore_DP0 pid=612475)[0;0m     0.5,
[0;36m(EngineCore_DP0 pid=612475)[0;0m     0.5
[0;36m(EngineCore_DP0 pid=612475)[0;0m   ],
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "image_processor_type": "Qwen2VLImageProcessorFast",
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "image_std": [
[0;36m(EngineCore_DP0 pid=612475)[0;0m     0.5,
[0;36m(EngineCore_DP0 pid=612475)[0;0m     0.5,
[0;36m(EngineCore_DP0 pid=612475)[0;0m     0.5
[0;36m(EngineCore_DP0 pid=612475)[0;0m   ],
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "input_data_format": null,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "max_pixels": null,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "merge_size": 2,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "min_pixels": null,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "pad_size": null,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "patch_size": 16,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "processor_class": "Qwen3VLProcessor",
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "resample": 3,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "rescale_factor": 0.00392156862745098,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "return_tensors": null,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "size": {
[0;36m(EngineCore_DP0 pid=612475)[0;0m     "longest_edge": 2097152,
[0;36m(EngineCore_DP0 pid=612475)[0;0m     "shortest_edge": 65536
[0;36m(EngineCore_DP0 pid=612475)[0;0m   },
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "temporal_patch_size": 2
[0;36m(EngineCore_DP0 pid=612475)[0;0m }
[0;36m(EngineCore_DP0 pid=612475)[0;0m 
[0;36m(EngineCore_DP0 pid=612475)[0;0m loading file vocab.json
[0;36m(EngineCore_DP0 pid=612475)[0;0m loading file merges.txt
[0;36m(EngineCore_DP0 pid=612475)[0;0m loading file tokenizer.json
[0;36m(EngineCore_DP0 pid=612475)[0;0m loading file added_tokens.json
[0;36m(EngineCore_DP0 pid=612475)[0;0m loading file special_tokens_map.json
[0;36m(EngineCore_DP0 pid=612475)[0;0m loading file tokenizer_config.json
[0;36m(EngineCore_DP0 pid=612475)[0;0m loading file chat_template.jinja
[0;36m(EngineCore_DP0 pid=612475)[0;0m Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[0;36m(EngineCore_DP0 pid=612475)[0;0m loading configuration file /root/.cache/huggingface/hub/models--Qwen--Qwen3-VL-32B-Instruct-FP8/snapshots/4bf2c2f39c37c0fede78bede4056e1f18cdf8109/video_preprocessor_config.json
[0;36m(EngineCore_DP0 pid=612475)[0;0m Video processor Qwen3VLVideoProcessor {
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "crop_size": null,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "data_format": "channels_first",
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "default_to_square": true,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "device": null,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "do_center_crop": null,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "do_convert_rgb": true,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "do_normalize": true,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "do_rescale": true,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "do_resize": true,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "do_sample_frames": true,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "fps": 2,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "image_mean": [
[0;36m(EngineCore_DP0 pid=612475)[0;0m     0.5,
[0;36m(EngineCore_DP0 pid=612475)[0;0m     0.5,
[0;36m(EngineCore_DP0 pid=612475)[0;0m     0.5
[0;36m(EngineCore_DP0 pid=612475)[0;0m   ],
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "image_std": [
[0;36m(EngineCore_DP0 pid=612475)[0;0m     0.5,
[0;36m(EngineCore_DP0 pid=612475)[0;0m     0.5,
[0;36m(EngineCore_DP0 pid=612475)[0;0m     0.5
[0;36m(EngineCore_DP0 pid=612475)[0;0m   ],
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "input_data_format": null,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "max_frames": 768,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "merge_size": 2,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "min_frames": 4,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "num_frames": null,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "pad_size": null,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "patch_size": 16,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "processor_class": "Qwen3VLProcessor",
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "resample": 3,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "rescale_factor": 0.00392156862745098,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "return_metadata": false,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "size": {
[0;36m(EngineCore_DP0 pid=612475)[0;0m     "longest_edge": 2097152,
[0;36m(EngineCore_DP0 pid=612475)[0;0m     "shortest_edge": 65536
[0;36m(EngineCore_DP0 pid=612475)[0;0m   },
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "temporal_patch_size": 2,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "video_metadata": null,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "video_processor_type": "Qwen3VLVideoProcessor"
[0;36m(EngineCore_DP0 pid=612475)[0;0m }
[0;36m(EngineCore_DP0 pid=612475)[0;0m 
[0;36m(EngineCore_DP0 pid=612475)[0;0m loading configuration file None
[0;36m(EngineCore_DP0 pid=612475)[0;0m Processor Qwen3VLProcessor:
[0;36m(EngineCore_DP0 pid=612475)[0;0m - image_processor: Qwen2VLImageProcessorFast {
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "crop_size": null,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "data_format": "channels_first",
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "default_to_square": true,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "device": null,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "disable_grouping": null,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "do_center_crop": null,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "do_convert_rgb": true,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "do_normalize": true,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "do_pad": null,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "do_rescale": true,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "do_resize": true,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "image_mean": [
[0;36m(EngineCore_DP0 pid=612475)[0;0m     0.5,
[0;36m(EngineCore_DP0 pid=612475)[0;0m     0.5,
[0;36m(EngineCore_DP0 pid=612475)[0;0m     0.5
[0;36m(EngineCore_DP0 pid=612475)[0;0m   ],
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "image_processor_type": "Qwen2VLImageProcessorFast",
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "image_std": [
[0;36m(EngineCore_DP0 pid=612475)[0;0m     0.5,
[0;36m(EngineCore_DP0 pid=612475)[0;0m     0.5,
[0;36m(EngineCore_DP0 pid=612475)[0;0m     0.5
[0;36m(EngineCore_DP0 pid=612475)[0;0m   ],
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "input_data_format": null,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "max_pixels": null,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "merge_size": 2,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "min_pixels": null,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "pad_size": null,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "patch_size": 16,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "processor_class": "Qwen3VLProcessor",
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "resample": 3,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "rescale_factor": 0.00392156862745098,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "return_tensors": null,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "size": {
[0;36m(EngineCore_DP0 pid=612475)[0;0m     "longest_edge": 2097152,
[0;36m(EngineCore_DP0 pid=612475)[0;0m     "shortest_edge": 65536
[0;36m(EngineCore_DP0 pid=612475)[0;0m   },
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "temporal_patch_size": 2
[0;36m(EngineCore_DP0 pid=612475)[0;0m }
[0;36m(EngineCore_DP0 pid=612475)[0;0m 
[0;36m(EngineCore_DP0 pid=612475)[0;0m - tokenizer: CachedQwen2TokenizerFast(name_or_path='/root/.cache/huggingface/hub/models--Qwen--Qwen3-VL-32B-Instruct-FP8/snapshots/4bf2c2f39c37c0fede78bede4056e1f18cdf8109/', vocab_size=151643, model_max_length=262144, is_fast=True, padding_side='right', truncation_side='left', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
[0;36m(EngineCore_DP0 pid=612475)[0;0m 	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
[0;36m(EngineCore_DP0 pid=612475)[0;0m 	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
[0;36m(EngineCore_DP0 pid=612475)[0;0m 	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
[0;36m(EngineCore_DP0 pid=612475)[0;0m 	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
[0;36m(EngineCore_DP0 pid=612475)[0;0m 	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
[0;36m(EngineCore_DP0 pid=612475)[0;0m 	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
[0;36m(EngineCore_DP0 pid=612475)[0;0m 	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
[0;36m(EngineCore_DP0 pid=612475)[0;0m 	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
[0;36m(EngineCore_DP0 pid=612475)[0;0m 	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
[0;36m(EngineCore_DP0 pid=612475)[0;0m 	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
[0;36m(EngineCore_DP0 pid=612475)[0;0m 	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
[0;36m(EngineCore_DP0 pid=612475)[0;0m 	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
[0;36m(EngineCore_DP0 pid=612475)[0;0m 	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
[0;36m(EngineCore_DP0 pid=612475)[0;0m 	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
[0;36m(EngineCore_DP0 pid=612475)[0;0m 	151657: AddedToken("<tool_call>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
[0;36m(EngineCore_DP0 pid=612475)[0;0m 	151658: AddedToken("</tool_call>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
[0;36m(EngineCore_DP0 pid=612475)[0;0m 	151659: AddedToken("<|fim_prefix|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
[0;36m(EngineCore_DP0 pid=612475)[0;0m 	151660: AddedToken("<|fim_middle|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
[0;36m(EngineCore_DP0 pid=612475)[0;0m 	151661: AddedToken("<|fim_suffix|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
[0;36m(EngineCore_DP0 pid=612475)[0;0m 	151662: AddedToken("<|fim_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
[0;36m(EngineCore_DP0 pid=612475)[0;0m 	151663: AddedToken("<|repo_name|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
[0;36m(EngineCore_DP0 pid=612475)[0;0m 	151664: AddedToken("<|file_sep|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
[0;36m(EngineCore_DP0 pid=612475)[0;0m 	151665: AddedToken("<tool_response>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
[0;36m(EngineCore_DP0 pid=612475)[0;0m 	151666: AddedToken("</tool_response>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
[0;36m(EngineCore_DP0 pid=612475)[0;0m 	151667: AddedToken("<think>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
[0;36m(EngineCore_DP0 pid=612475)[0;0m 	151668: AddedToken("</think>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
[0;36m(EngineCore_DP0 pid=612475)[0;0m }
[0;36m(EngineCore_DP0 pid=612475)[0;0m )
[0;36m(EngineCore_DP0 pid=612475)[0;0m - video_processor: Qwen3VLVideoProcessor {
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "crop_size": null,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "data_format": "channels_first",
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "default_to_square": true,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "device": null,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "do_center_crop": null,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "do_convert_rgb": true,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "do_normalize": true,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "do_rescale": true,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "do_resize": true,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "do_sample_frames": true,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "fps": 2,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "image_mean": [
[0;36m(EngineCore_DP0 pid=612475)[0;0m     0.5,
[0;36m(EngineCore_DP0 pid=612475)[0;0m     0.5,
[0;36m(EngineCore_DP0 pid=612475)[0;0m     0.5
[0;36m(EngineCore_DP0 pid=612475)[0;0m   ],
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "image_std": [
[0;36m(EngineCore_DP0 pid=612475)[0;0m     0.5,
[0;36m(EngineCore_DP0 pid=612475)[0;0m     0.5,
[0;36m(EngineCore_DP0 pid=612475)[0;0m     0.5
[0;36m(EngineCore_DP0 pid=612475)[0;0m   ],
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "input_data_format": null,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "max_frames": 768,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "merge_size": 2,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "min_frames": 4,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "num_frames": null,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "pad_size": null,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "patch_size": 16,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "processor_class": "Qwen3VLProcessor",
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "resample": 3,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "rescale_factor": 0.00392156862745098,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "return_metadata": false,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "size": {
[0;36m(EngineCore_DP0 pid=612475)[0;0m     "longest_edge": 2097152,
[0;36m(EngineCore_DP0 pid=612475)[0;0m     "shortest_edge": 65536
[0;36m(EngineCore_DP0 pid=612475)[0;0m   },
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "temporal_patch_size": 2,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "video_metadata": null,
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "video_processor_type": "Qwen3VLVideoProcessor"
[0;36m(EngineCore_DP0 pid=612475)[0;0m }
[0;36m(EngineCore_DP0 pid=612475)[0;0m 
[0;36m(EngineCore_DP0 pid=612475)[0;0m 
[0;36m(EngineCore_DP0 pid=612475)[0;0m {
[0;36m(EngineCore_DP0 pid=612475)[0;0m   "processor_class": "Qwen3VLProcessor"
[0;36m(EngineCore_DP0 pid=612475)[0;0m }
[0;36m(EngineCore_DP0 pid=612475)[0;0m 
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:46 [hpu_model_runner.py:4194] [Warmup][Graph/Multimodal(image)][1/36] batch_size:1 seq_len:0 resolution:1280X704 free_mem:47.73 GiB
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:47 [hpu_model_runner.py:4194] [Warmup][Graph/Multimodal(image)][2/36] batch_size:1 seq_len:0 resolution:224X224 free_mem:47.73 GiB
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:48 [hpu_model_runner.py:4194] [Warmup][Graph/Multimodal(image)][3/36] batch_size:1 seq_len:0 resolution:288X224 free_mem:47.73 GiB
[0;36m(APIServer pid=612145)[0;0m DEBUG 02-06 04:07:48 [v1/engine/utils.py:982] Waiting for 1 local, 0 remote core engine proc(s) to start.
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:49 [hpu_model_runner.py:4194] [Warmup][Graph/Multimodal(image)][4/36] batch_size:1 seq_len:0 resolution:160X224 free_mem:47.73 GiB
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:50 [hpu_model_runner.py:4194] [Warmup][Graph/Multimodal(image)][5/36] batch_size:1 seq_len:0 resolution:384X224 free_mem:47.73 GiB
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:50 [hpu_model_runner.py:4194] [Warmup][Graph/Multimodal(image)][6/36] batch_size:1 seq_len:0 resolution:128X224 free_mem:47.73 GiB
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:51 [hpu_model_runner.py:4194] [Warmup][Graph/Multimodal(image)][7/36] batch_size:1 seq_len:0 resolution:256X256 free_mem:47.73 GiB
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:52 [hpu_model_runner.py:4194] [Warmup][Graph/Multimodal(image)][8/36] batch_size:1 seq_len:0 resolution:352X256 free_mem:47.73 GiB
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:53 [hpu_model_runner.py:4194] [Warmup][Graph/Multimodal(image)][9/36] batch_size:1 seq_len:0 resolution:192X256 free_mem:47.73 GiB
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:53 [hpu_model_runner.py:4194] [Warmup][Graph/Multimodal(image)][10/36] batch_size:1 seq_len:0 resolution:448X256 free_mem:47.73 GiB
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:54 [hpu_model_runner.py:4194] [Warmup][Graph/Multimodal(image)][11/36] batch_size:1 seq_len:0 resolution:160X256 free_mem:47.73 GiB
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:55 [hpu_model_runner.py:4194] [Warmup][Graph/Multimodal(image)][12/36] batch_size:1 seq_len:0 resolution:352X336 free_mem:47.73 GiB
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:56 [hpu_model_runner.py:4194] [Warmup][Graph/Multimodal(image)][13/36] batch_size:1 seq_len:0 resolution:448X336 free_mem:47.73 GiB
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:57 [hpu_model_runner.py:4194] [Warmup][Graph/Multimodal(image)][14/36] batch_size:1 seq_len:0 resolution:256X336 free_mem:47.73 GiB
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:58 [hpu_model_runner.py:4194] [Warmup][Graph/Multimodal(image)][15/36] batch_size:1 seq_len:0 resolution:608X336 free_mem:47.73 GiB
[0;36m(APIServer pid=612145)[0;0m DEBUG 02-06 04:07:58 [v1/engine/utils.py:982] Waiting for 1 local, 0 remote core engine proc(s) to start.
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:58 [hpu_model_runner.py:4194] [Warmup][Graph/Multimodal(image)][16/36] batch_size:1 seq_len:0 resolution:192X336 free_mem:47.73 GiB
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:07:59 [hpu_model_runner.py:4194] [Warmup][Graph/Multimodal(image)][17/36] batch_size:1 seq_len:0 resolution:352X336 free_mem:47.73 GiB
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:08:00 [hpu_model_runner.py:4194] [Warmup][Graph/Multimodal(image)][18/36] batch_size:1 seq_len:0 resolution:448X336 free_mem:47.73 GiB
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:08:01 [hpu_model_runner.py:4194] [Warmup][Graph/Multimodal(image)][19/36] batch_size:1 seq_len:0 resolution:256X336 free_mem:47.73 GiB
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:08:02 [hpu_model_runner.py:4194] [Warmup][Graph/Multimodal(image)][20/36] batch_size:1 seq_len:0 resolution:608X336 free_mem:47.73 GiB
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:08:02 [hpu_model_runner.py:4194] [Warmup][Graph/Multimodal(image)][21/36] batch_size:1 seq_len:0 resolution:192X336 free_mem:47.73 GiB
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:08:03 [hpu_model_runner.py:4194] [Warmup][Graph/Multimodal(image)][22/36] batch_size:1 seq_len:0 resolution:384X384 free_mem:47.73 GiB
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:08:04 [hpu_model_runner.py:4194] [Warmup][Graph/Multimodal(image)][23/36] batch_size:1 seq_len:0 resolution:512X384 free_mem:47.73 GiB
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:08:05 [hpu_model_runner.py:4194] [Warmup][Graph/Multimodal(image)][24/36] batch_size:1 seq_len:0 resolution:288X384 free_mem:47.73 GiB
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:08:05 [hpu_model_runner.py:4194] [Warmup][Graph/Multimodal(image)][25/36] batch_size:1 seq_len:0 resolution:672X384 free_mem:47.73 GiB
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:08:06 [hpu_model_runner.py:4194] [Warmup][Graph/Multimodal(image)][26/36] batch_size:1 seq_len:0 resolution:224X384 free_mem:47.73 GiB
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:08:07 [hpu_model_runner.py:4194] [Warmup][Graph/Multimodal(image)][27/36] batch_size:1 seq_len:0 resolution:480X480 free_mem:47.73 GiB
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:08:08 [hpu_model_runner.py:4194] [Warmup][Graph/Multimodal(image)][28/36] batch_size:1 seq_len:0 resolution:640X480 free_mem:47.73 GiB
[0;36m(APIServer pid=612145)[0;0m DEBUG 02-06 04:08:08 [v1/engine/utils.py:982] Waiting for 1 local, 0 remote core engine proc(s) to start.
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:08:09 [hpu_model_runner.py:4194] [Warmup][Graph/Multimodal(image)][29/36] batch_size:1 seq_len:0 resolution:352X480 free_mem:47.73 GiB
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:08:10 [hpu_model_runner.py:4194] [Warmup][Graph/Multimodal(image)][30/36] batch_size:1 seq_len:0 resolution:864X480 free_mem:47.73 GiB
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:08:10 [hpu_model_runner.py:4194] [Warmup][Graph/Multimodal(image)][31/36] batch_size:1 seq_len:0 resolution:256X480 free_mem:47.73 GiB
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:08:11 [hpu_model_runner.py:4194] [Warmup][Graph/Multimodal(image)][32/36] batch_size:1 seq_len:0 resolution:544X544 free_mem:47.73 GiB
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:08:12 [hpu_model_runner.py:4194] [Warmup][Graph/Multimodal(image)][33/36] batch_size:1 seq_len:0 resolution:736X544 free_mem:47.73 GiB
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:08:13 [hpu_model_runner.py:4194] [Warmup][Graph/Multimodal(image)][34/36] batch_size:1 seq_len:0 resolution:416X544 free_mem:47.73 GiB
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:08:14 [hpu_model_runner.py:4194] [Warmup][Graph/Multimodal(image)][35/36] batch_size:1 seq_len:0 resolution:960X544 free_mem:47.73 GiB
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:08:14 [hpu_model_runner.py:4194] [Warmup][Graph/Multimodal(image)][36/36] batch_size:1 seq_len:0 resolution:320X544 free_mem:47.73 GiB
[0;36m(EngineCore_DP0 pid=612475)[0;0m DEBUG 02-06 04:08:14 [hpu_model_runner.py:5087] Using PT_COMPILE_ONLY_MODE.
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:08:14 [hpu_model_runner.py:4320] Warming up sampler with batch sizes: [0, 1, 2, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64] and following configs:
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:08:14 [hpu_model_runner.py:4322] temp=0.0, top_p=1.0, top_k=0, batch_changed=True
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:08:14 [hpu_model_runner.py:4322] temp=1.0, top_p=1.0, top_k=0, batch_changed=True
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:08:14 [hpu_model_runner.py:4322] temp=0.7, top_p=0.9, top_k=50, batch_changed=True
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:08:14 [hpu_model_runner.py:4322] temp=0.3, top_p=0.95, top_k=20, batch_changed=True
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:08:14 [hpu_model_runner.py:4322] temp=1.2, top_p=0.8, top_k=100, batch_changed=True
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:08:14 [hpu_model_runner.py:4322] temp=0.8, top_p=0.85, top_k=0, batch_changed=True
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:08:14 [hpu_model_runner.py:4322] temp=0.0, top_p=1.0, top_k=0, batch_changed=False
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:08:14 [hpu_model_runner.py:4322] temp=1.0, top_p=1.0, top_k=0, batch_changed=False
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:08:14 [hpu_model_runner.py:4322] temp=0.7, top_p=0.9, top_k=50, batch_changed=False
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:08:14 [hpu_model_runner.py:4322] temp=0.3, top_p=0.95, top_k=20, batch_changed=False
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:08:14 [hpu_model_runner.py:4322] temp=1.2, top_p=0.8, top_k=100, batch_changed=False
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:08:14 [hpu_model_runner.py:4322] temp=0.8, top_p=0.85, top_k=0, batch_changed=False
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:08:14 [hpu_model_runner.py:4323] Starting sampler warmup...
[0;36m(APIServer pid=612145)[0;0m DEBUG 02-06 04:08:18 [v1/engine/utils.py:982] Waiting for 1 local, 0 remote core engine proc(s) to start.
[0;36m(APIServer pid=612145)[0;0m DEBUG 02-06 04:08:28 [v1/engine/utils.py:982] Waiting for 1 local, 0 remote core engine proc(s) to start.
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:08:36 [hpu_model_runner.py:4387] Sampler warmup completed successfully
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:08:36 [hpu_model_runner.py:4404] Warming up defragmenter with thresholds: [8, 16, 32, 64, 128, 256, 512]
[0;36m(APIServer pid=612145)[0;0m DEBUG 02-06 04:08:38 [v1/engine/utils.py:982] Waiting for 1 local, 0 remote core engine proc(s) to start.
[0;36m(EngineCore_DP0 pid=612475)[0;0m INFO 02-06 04:08:40 [hpu_model_runner.py:4428] Defragmenter warmup completed successfully
[0;36m(EngineCore_DP0 pid=612475)[0;0m Prompt warmup processing:   0%|          | 0/48 [00:00<?, ?item/s]/usr/local/lib/python3.12/dist-packages/torch/_dynamo/variables/functions.py:1692: UserWarning: Dynamo detected a call to a `functools.lru_cache`-wrapped function. Dynamo ignores the cache wrapper and directly traces the wrapped function. Silent incorrectness is only a *potential* risk, not something we have observed. Enable TORCH_LOGS="+dynamo" for a DEBUG stack trace.
[0;36m(EngineCore_DP0 pid=612475)[0;0m   torch._dynamo.utils.warn_once(msg)
[0;36m(EngineCore_DP0 pid=612475)[0;0m Prompt warmup processing:   0%|          | 0/48 [00:03<?, ?item/s]
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946]   File "/root/migration/vllm/vllm/v1/engine/core.py", line 937, in run_engine_core
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946]     engine_core = EngineCoreProc(*args, engine_index=dp_rank, **kwargs)
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946]   File "/root/migration/vllm/vllm/v1/engine/core.py", line 691, in __init__
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946]     super().__init__(
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946]   File "/root/migration/vllm/vllm/v1/engine/core.py", line 112, in __init__
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946]   File "/root/migration/vllm/vllm/v1/engine/core.py", line 269, in _initialize_kv_caches
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946]     self.model_executor.initialize_from_config(kv_cache_configs)
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946]   File "/root/migration/vllm/vllm/v1/executor/abstract.py", line 115, in initialize_from_config
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946]     self.collective_rpc("initialize_from_config", args=(kv_cache_configs,))
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946]   File "/root/migration/vllm/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946]     result = run_method(self.driver_worker, method, args, kwargs)
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946]   File "/root/migration/vllm/vllm/v1/serial_utils.py", line 461, in run_method
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946]            ^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946]   File "/root/migration/vllm/vllm/v1/worker/worker_base.py", line 320, in initialize_from_config
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946]     self.worker.initialize_from_config(kv_cache_config)  # type: ignore
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946]   File "/root/migration/vllm-gaudi/vllm_gaudi/v1/worker/hpu_worker.py", line 307, in initialize_from_config
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946]     self.compile_or_warm_up_model()
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946]   File "/root/migration/vllm-gaudi/vllm_gaudi/v1/worker/hpu_worker.py", line 312, in compile_or_warm_up_model
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946]     self.model_runner.warmup_model()
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946]            ^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946]   File "/root/migration/vllm-gaudi/vllm_gaudi/v1/worker/hpu_model_runner.py", line 5110, in warmup_model
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946]     self.warmup_graphs(
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946]   File "/root/migration/vllm-gaudi/vllm_gaudi/v1/worker/hpu_model_runner.py", line 4460, in warmup_graphs
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946]     self._prepare_dummy_scenario(prompt_cfg, decode_cfg)
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946]   File "/root/migration/vllm-gaudi/vllm_gaudi/v1/worker/hpu_model_runner.py", line 4766, in _prepare_dummy_scenario
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946]     self._execute_dummy_scenario(requests, scheduled_tokens)
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946]   File "/root/migration/vllm-gaudi/vllm_gaudi/v1/worker/hpu_model_runner.py", line 4794, in _execute_dummy_scenario
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946]     self.sample_tokens(None)
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946]            ^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946]   File "/root/migration/vllm-gaudi/vllm_gaudi/v1/worker/hpu_model_runner.py", line 3666, in sample_tokens
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946]     self._execute_model_generic(
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946]   File "/root/migration/vllm-gaudi/vllm_gaudi/v1/worker/hpu_model_runner.py", line 2931, in _execute_model_generic
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946]     hidden_states = self.model.forward(input_ids=token_ids,
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946]   File "/root/migration/vllm-gaudi/vllm_gaudi/v1/worker/hpu_model_runner.py", line 563, in forward
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946]     hidden_states = self.model(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1778, in _wrapped_call_impl
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946]     return self._call_impl(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1789, in _call_impl
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946]     return forward_call(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946]   File "/root/migration/vllm/vllm/model_executor/models/qwen3_vl.py", line 2045, in forward
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946]     hidden_states = self.language_model.model(
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946]   File "/root/migration/vllm/vllm/compilation/decorators.py", line 389, in __call__
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946]     return self.forward(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946]   File "/root/migration/vllm/vllm/model_executor/models/qwen3_vl.py", line 1148, in forward
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946]     hidden_states, residual = layer(
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946]                               ^^^^^^
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946]   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 414, in __call__
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946]     return super().__call__(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1778, in _wrapped_call_impl
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946]     return self._call_impl(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1789, in _call_impl
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946]     return forward_call(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946]   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 832, in compile_wrapper
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946]     return fn(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946]            ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1778, in _wrapped_call_impl
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946]     return self._call_impl(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1884, in _call_impl
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946]     return inner()
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946]            ^^^^^^^
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1832, in inner
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946]     result = forward_call(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946]   File "/root/migration/vllm/vllm/model_executor/models/qwen3.py", line 220, in forward
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946]     hidden_states = self.self_attn(
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946]                     ^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1778, in _wrapped_call_impl
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946]     return self._call_impl(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1789, in _call_impl
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946]     return forward_call(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946]   File "/root/migration/vllm/vllm/model_executor/models/qwen3.py", line 152, in forward
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946]     attn_output = self.attn(q, k, v)
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946]                   ^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1778, in _wrapped_call_impl
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946]     return self._call_impl(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1789, in _call_impl
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946]     return forward_call(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946]   File "/root/migration/vllm/vllm/model_executor/layers/attention/attention.py", line 462, in forward
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946]     return unified_attention(query, key, value, self.layer_name)
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946]   File "/root/migration/vllm/vllm/model_executor/layers/attention/kv_transfer_utils.py", line 39, in wrapper
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946]            ^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946]   File "/root/migration/vllm/vllm/model_executor/layers/attention/attention.py", line 612, in unified_attention
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946]     attn_metadata, self, kv_cache = get_attention_context(layer_idx)
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946]                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946]   File "/root/migration/vllm/vllm/model_executor/layers/attention/attention.py", line 590, in get_attention_context
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946]     attn_layer = forward_context.no_compile_layers[layer_name]
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946]                  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=612475)[0;0m ERROR 02-06 04:08:44 [v1/engine/core.py:946] KeyError: 0
[0;36m(EngineCore_DP0 pid=612475)[0;0m Process EngineCore_DP0:
[0;36m(EngineCore_DP0 pid=612475)[0;0m Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=612475)[0;0m   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[0;36m(EngineCore_DP0 pid=612475)[0;0m     self.run()
[0;36m(EngineCore_DP0 pid=612475)[0;0m   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
[0;36m(EngineCore_DP0 pid=612475)[0;0m     self._target(*self._args, **self._kwargs)
[0;36m(EngineCore_DP0 pid=612475)[0;0m   File "/root/migration/vllm/vllm/v1/engine/core.py", line 950, in run_engine_core
[0;36m(EngineCore_DP0 pid=612475)[0;0m     raise e
[0;36m(EngineCore_DP0 pid=612475)[0;0m   File "/root/migration/vllm/vllm/v1/engine/core.py", line 937, in run_engine_core
[0;36m(EngineCore_DP0 pid=612475)[0;0m     engine_core = EngineCoreProc(*args, engine_index=dp_rank, **kwargs)
[0;36m(EngineCore_DP0 pid=612475)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=612475)[0;0m   File "/root/migration/vllm/vllm/v1/engine/core.py", line 691, in __init__
[0;36m(EngineCore_DP0 pid=612475)[0;0m     super().__init__(
[0;36m(EngineCore_DP0 pid=612475)[0;0m   File "/root/migration/vllm/vllm/v1/engine/core.py", line 112, in __init__
[0;36m(EngineCore_DP0 pid=612475)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[0;36m(EngineCore_DP0 pid=612475)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=612475)[0;0m   File "/root/migration/vllm/vllm/v1/engine/core.py", line 269, in _initialize_kv_caches
[0;36m(EngineCore_DP0 pid=612475)[0;0m     self.model_executor.initialize_from_config(kv_cache_configs)
[0;36m(EngineCore_DP0 pid=612475)[0;0m   File "/root/migration/vllm/vllm/v1/executor/abstract.py", line 115, in initialize_from_config
[0;36m(EngineCore_DP0 pid=612475)[0;0m     self.collective_rpc("initialize_from_config", args=(kv_cache_configs,))
[0;36m(EngineCore_DP0 pid=612475)[0;0m   File "/root/migration/vllm/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[0;36m(EngineCore_DP0 pid=612475)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[0;36m(EngineCore_DP0 pid=612475)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=612475)[0;0m   File "/root/migration/vllm/vllm/v1/serial_utils.py", line 461, in run_method
[0;36m(EngineCore_DP0 pid=612475)[0;0m     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=612475)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=612475)[0;0m   File "/root/migration/vllm/vllm/v1/worker/worker_base.py", line 320, in initialize_from_config
[0;36m(EngineCore_DP0 pid=612475)[0;0m     self.worker.initialize_from_config(kv_cache_config)  # type: ignore
[0;36m(EngineCore_DP0 pid=612475)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=612475)[0;0m   File "/root/migration/vllm-gaudi/vllm_gaudi/v1/worker/hpu_worker.py", line 307, in initialize_from_config
[0;36m(EngineCore_DP0 pid=612475)[0;0m     self.compile_or_warm_up_model()
[0;36m(EngineCore_DP0 pid=612475)[0;0m   File "/root/migration/vllm-gaudi/vllm_gaudi/v1/worker/hpu_worker.py", line 312, in compile_or_warm_up_model
[0;36m(EngineCore_DP0 pid=612475)[0;0m     self.model_runner.warmup_model()
[0;36m(EngineCore_DP0 pid=612475)[0;0m   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[0;36m(EngineCore_DP0 pid=612475)[0;0m     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=612475)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=612475)[0;0m   File "/root/migration/vllm-gaudi/vllm_gaudi/v1/worker/hpu_model_runner.py", line 5110, in warmup_model
[0;36m(EngineCore_DP0 pid=612475)[0;0m     self.warmup_graphs(
[0;36m(EngineCore_DP0 pid=612475)[0;0m   File "/root/migration/vllm-gaudi/vllm_gaudi/v1/worker/hpu_model_runner.py", line 4460, in warmup_graphs
[0;36m(EngineCore_DP0 pid=612475)[0;0m     self._prepare_dummy_scenario(prompt_cfg, decode_cfg)
[0;36m(EngineCore_DP0 pid=612475)[0;0m   File "/root/migration/vllm-gaudi/vllm_gaudi/v1/worker/hpu_model_runner.py", line 4766, in _prepare_dummy_scenario
[0;36m(EngineCore_DP0 pid=612475)[0;0m     self._execute_dummy_scenario(requests, scheduled_tokens)
[0;36m(EngineCore_DP0 pid=612475)[0;0m   File "/root/migration/vllm-gaudi/vllm_gaudi/v1/worker/hpu_model_runner.py", line 4794, in _execute_dummy_scenario
[0;36m(EngineCore_DP0 pid=612475)[0;0m     self.sample_tokens(None)
[0;36m(EngineCore_DP0 pid=612475)[0;0m   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[0;36m(EngineCore_DP0 pid=612475)[0;0m     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=612475)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=612475)[0;0m   File "/root/migration/vllm-gaudi/vllm_gaudi/v1/worker/hpu_model_runner.py", line 3666, in sample_tokens
[0;36m(EngineCore_DP0 pid=612475)[0;0m     self._execute_model_generic(
[0;36m(EngineCore_DP0 pid=612475)[0;0m   File "/root/migration/vllm-gaudi/vllm_gaudi/v1/worker/hpu_model_runner.py", line 2931, in _execute_model_generic
[0;36m(EngineCore_DP0 pid=612475)[0;0m     hidden_states = self.model.forward(input_ids=token_ids,
[0;36m(EngineCore_DP0 pid=612475)[0;0m                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=612475)[0;0m   File "/root/migration/vllm-gaudi/vllm_gaudi/v1/worker/hpu_model_runner.py", line 563, in forward
[0;36m(EngineCore_DP0 pid=612475)[0;0m     hidden_states = self.model(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=612475)[0;0m                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=612475)[0;0m   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1778, in _wrapped_call_impl
[0;36m(EngineCore_DP0 pid=612475)[0;0m     return self._call_impl(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=612475)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=612475)[0;0m   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1789, in _call_impl
[0;36m(EngineCore_DP0 pid=612475)[0;0m     return forward_call(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=612475)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=612475)[0;0m   File "/root/migration/vllm/vllm/model_executor/models/qwen3_vl.py", line 2045, in forward
[0;36m(EngineCore_DP0 pid=612475)[0;0m     hidden_states = self.language_model.model(
[0;36m(EngineCore_DP0 pid=612475)[0;0m                     ^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=612475)[0;0m   File "/root/migration/vllm/vllm/compilation/decorators.py", line 389, in __call__
[0;36m(EngineCore_DP0 pid=612475)[0;0m     return self.forward(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=612475)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=612475)[0;0m   File "/root/migration/vllm/vllm/model_executor/models/qwen3_vl.py", line 1148, in forward
[0;36m(EngineCore_DP0 pid=612475)[0;0m     hidden_states, residual = layer(
[0;36m(EngineCore_DP0 pid=612475)[0;0m                               ^^^^^^
[0;36m(EngineCore_DP0 pid=612475)[0;0m   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 414, in __call__
[0;36m(EngineCore_DP0 pid=612475)[0;0m     return super().__call__(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=612475)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=612475)[0;0m   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1778, in _wrapped_call_impl
[0;36m(EngineCore_DP0 pid=612475)[0;0m     return self._call_impl(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=612475)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=612475)[0;0m   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1789, in _call_impl
[0;36m(EngineCore_DP0 pid=612475)[0;0m     return forward_call(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=612475)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=612475)[0;0m   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 832, in compile_wrapper
[0;36m(EngineCore_DP0 pid=612475)[0;0m     return fn(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=612475)[0;0m            ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=612475)[0;0m   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1778, in _wrapped_call_impl
[0;36m(EngineCore_DP0 pid=612475)[0;0m     return self._call_impl(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=612475)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=612475)[0;0m   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1884, in _call_impl
[0;36m(EngineCore_DP0 pid=612475)[0;0m     return inner()
[0;36m(EngineCore_DP0 pid=612475)[0;0m            ^^^^^^^
[0;36m(EngineCore_DP0 pid=612475)[0;0m   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1832, in inner
[0;36m(EngineCore_DP0 pid=612475)[0;0m     result = forward_call(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=612475)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=612475)[0;0m   File "/root/migration/vllm/vllm/model_executor/models/qwen3.py", line 220, in forward
[0;36m(EngineCore_DP0 pid=612475)[0;0m     hidden_states = self.self_attn(
[0;36m(EngineCore_DP0 pid=612475)[0;0m                     ^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=612475)[0;0m   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1778, in _wrapped_call_impl
[0;36m(EngineCore_DP0 pid=612475)[0;0m     return self._call_impl(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=612475)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=612475)[0;0m   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1789, in _call_impl
[0;36m(EngineCore_DP0 pid=612475)[0;0m     return forward_call(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=612475)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=612475)[0;0m   File "/root/migration/vllm/vllm/model_executor/models/qwen3.py", line 152, in forward
[0;36m(EngineCore_DP0 pid=612475)[0;0m     attn_output = self.attn(q, k, v)
[0;36m(EngineCore_DP0 pid=612475)[0;0m                   ^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=612475)[0;0m   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1778, in _wrapped_call_impl
[0;36m(EngineCore_DP0 pid=612475)[0;0m     return self._call_impl(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=612475)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=612475)[0;0m   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1789, in _call_impl
[0;36m(EngineCore_DP0 pid=612475)[0;0m     return forward_call(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=612475)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=612475)[0;0m   File "/root/migration/vllm/vllm/model_executor/layers/attention/attention.py", line 462, in forward
[0;36m(EngineCore_DP0 pid=612475)[0;0m     return unified_attention(query, key, value, self.layer_name)
[0;36m(EngineCore_DP0 pid=612475)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=612475)[0;0m   File "/root/migration/vllm/vllm/model_executor/layers/attention/kv_transfer_utils.py", line 39, in wrapper
[0;36m(EngineCore_DP0 pid=612475)[0;0m     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=612475)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=612475)[0;0m   File "/root/migration/vllm/vllm/model_executor/layers/attention/attention.py", line 612, in unified_attention
[0;36m(EngineCore_DP0 pid=612475)[0;0m     attn_metadata, self, kv_cache = get_attention_context(layer_idx)
[0;36m(EngineCore_DP0 pid=612475)[0;0m                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=612475)[0;0m   File "/root/migration/vllm/vllm/model_executor/layers/attention/attention.py", line 590, in get_attention_context
[0;36m(EngineCore_DP0 pid=612475)[0;0m     attn_layer = forward_context.no_compile_layers[layer_name]
[0;36m(EngineCore_DP0 pid=612475)[0;0m                  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=612475)[0;0m KeyError: 0
[0;36m(APIServer pid=612145)[0;0m Traceback (most recent call last):
[0;36m(APIServer pid=612145)[0;0m   File "<frozen runpy>", line 198, in _run_module_as_main
[0;36m(APIServer pid=612145)[0;0m   File "<frozen runpy>", line 88, in _run_code
[0;36m(APIServer pid=612145)[0;0m   File "/root/migration/vllm/vllm/entrypoints/openai/api_server.py", line 493, in <module>
[0;36m(APIServer pid=612145)[0;0m     uvloop.run(run_server(args))
[0;36m(APIServer pid=612145)[0;0m   File "/usr/local/lib/python3.12/dist-packages/uvloop/__init__.py", line 96, in run
[0;36m(APIServer pid=612145)[0;0m     return __asyncio.run(
[0;36m(APIServer pid=612145)[0;0m            ^^^^^^^^^^^^^^
[0;36m(APIServer pid=612145)[0;0m   File "/usr/lib/python3.12/asyncio/runners.py", line 194, in run
[0;36m(APIServer pid=612145)[0;0m     return runner.run(main)
[0;36m(APIServer pid=612145)[0;0m            ^^^^^^^^^^^^^^^^
[0;36m(APIServer pid=612145)[0;0m   File "/usr/lib/python3.12/asyncio/runners.py", line 118, in run
[0;36m(APIServer pid=612145)[0;0m     return self._loop.run_until_complete(task)
[0;36m(APIServer pid=612145)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(APIServer pid=612145)[0;0m   File "uvloop/loop.pyx", line 1518, in uvloop.loop.Loop.run_until_complete
[0;36m(APIServer pid=612145)[0;0m   File "/usr/local/lib/python3.12/dist-packages/uvloop/__init__.py", line 48, in wrapper
[0;36m(APIServer pid=612145)[0;0m     return await main
[0;36m(APIServer pid=612145)[0;0m            ^^^^^^^^^^
[0;36m(APIServer pid=612145)[0;0m   File "/root/migration/vllm/vllm/entrypoints/openai/api_server.py", line 419, in run_server
[0;36m(APIServer pid=612145)[0;0m     await run_server_worker(listen_address, sock, args, **uvicorn_kwargs)
[0;36m(APIServer pid=612145)[0;0m   File "/root/migration/vllm/vllm/entrypoints/openai/api_server.py", line 438, in run_server_worker
[0;36m(APIServer pid=612145)[0;0m     async with build_async_engine_client(
[0;36m(APIServer pid=612145)[0;0m   File "/usr/lib/python3.12/contextlib.py", line 210, in __aenter__
[0;36m(APIServer pid=612145)[0;0m     return await anext(self.gen)
[0;36m(APIServer pid=612145)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[0;36m(APIServer pid=612145)[0;0m   File "/root/migration/vllm/vllm/entrypoints/openai/api_server.py", line 92, in build_async_engine_client
[0;36m(APIServer pid=612145)[0;0m     async with build_async_engine_client_from_engine_args(
[0;36m(APIServer pid=612145)[0;0m   File "/usr/lib/python3.12/contextlib.py", line 210, in __aenter__
[0;36m(APIServer pid=612145)[0;0m     return await anext(self.gen)
[0;36m(APIServer pid=612145)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[0;36m(APIServer pid=612145)[0;0m   File "/root/migration/vllm/vllm/entrypoints/openai/api_server.py", line 133, in build_async_engine_client_from_engine_args
[0;36m(APIServer pid=612145)[0;0m     async_llm = AsyncLLM.from_vllm_config(
[0;36m(APIServer pid=612145)[0;0m                 ^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(APIServer pid=612145)[0;0m   File "/root/migration/vllm/vllm/v1/engine/async_llm.py", line 228, in from_vllm_config
[0;36m(APIServer pid=612145)[0;0m     return cls(
[0;36m(APIServer pid=612145)[0;0m            ^^^^
[0;36m(APIServer pid=612145)[0;0m   File "/root/migration/vllm/vllm/v1/engine/async_llm.py", line 155, in __init__
[0;36m(APIServer pid=612145)[0;0m     self.engine_core = EngineCoreClient.make_async_mp_client(
[0;36m(APIServer pid=612145)[0;0m                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(APIServer pid=612145)[0;0m   File "/root/migration/vllm/vllm/v1/engine/core_client.py", line 122, in make_async_mp_client
[0;36m(APIServer pid=612145)[0;0m     return AsyncMPClient(*client_args)
[0;36m(APIServer pid=612145)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(APIServer pid=612145)[0;0m   File "/root/migration/vllm/vllm/v1/engine/core_client.py", line 819, in __init__
[0;36m(APIServer pid=612145)[0;0m     super().__init__(
[0;36m(APIServer pid=612145)[0;0m   File "/root/migration/vllm/vllm/v1/engine/core_client.py", line 479, in __init__
[0;36m(APIServer pid=612145)[0;0m     with launch_core_engines(vllm_config, executor_class, log_stats) as (
[0;36m(APIServer pid=612145)[0;0m   File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
[0;36m(APIServer pid=612145)[0;0m     next(self.gen)
[0;36m(APIServer pid=612145)[0;0m   File "/root/migration/vllm/vllm/v1/engine/utils.py", line 933, in launch_core_engines
[0;36m(APIServer pid=612145)[0;0m     wait_for_engine_startup(
[0;36m(APIServer pid=612145)[0;0m   File "/root/migration/vllm/vllm/v1/engine/utils.py", line 992, in wait_for_engine_startup
[0;36m(APIServer pid=612145)[0;0m     raise RuntimeError(
[0;36m(APIServer pid=612145)[0;0m RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}
