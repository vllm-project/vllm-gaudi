Calling add_step_closure function does not have any effect. It's lazy mode only functionality. (warning logged once)
Calling mark_step function does not have any effect. It's lazy mode only functionality. (warning logged once)
Calling iter_mark_step function does not have any effect. It's lazy mode only functionality. (warning logged once)
INFO 01-27 22:06:26 [plugins/__init__.py:43] Available plugins for group vllm.platform_plugins:
INFO 01-27 22:06:26 [plugins/__init__.py:45] - hpu -> vllm_gaudi:register
INFO 01-27 22:06:26 [plugins/__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
DEBUG 01-27 22:06:26 [platforms/__init__.py:36] Checking if TPU platform is available.
DEBUG 01-27 22:06:26 [platforms/__init__.py:55] TPU platform is not available because: No module named 'libtpu'
DEBUG 01-27 22:06:26 [platforms/__init__.py:61] Checking if CUDA platform is available.
DEBUG 01-27 22:06:26 [platforms/__init__.py:88] Exception happens when checking CUDA platform: NVML Shared Library Not Found
DEBUG 01-27 22:06:26 [platforms/__init__.py:105] CUDA platform is not available because: NVML Shared Library Not Found
DEBUG 01-27 22:06:26 [platforms/__init__.py:112] Checking if ROCm platform is available.
DEBUG 01-27 22:06:26 [platforms/__init__.py:126] ROCm platform is not available because: No module named 'amdsmi'
DEBUG 01-27 22:06:26 [platforms/__init__.py:133] Checking if XPU platform is available.
DEBUG 01-27 22:06:26 [platforms/__init__.py:153] XPU platform is not available because: No module named 'intel_extension_for_pytorch'
DEBUG 01-27 22:06:26 [platforms/__init__.py:160] Checking if CPU platform is available.
INFO 01-27 22:06:26 [platforms/__init__.py:217] Platform plugin hpu is activated
INFO 01-27 22:06:28 [triton_utils/importing.py:44] Triton is installed but 0 active driver(s) found (expected 1). Disabling Triton to prevent runtime errors.
INFO 01-27 22:06:28 [triton_utils/importing.py:68] Triton not installed or not compatible; certain GPU-related functions will not be available.
DEBUG 01-27 22:06:29 [entrypoints/utils.py:183] Setting VLLM_WORKER_MULTIPROC_METHOD to 'spawn'
DEBUG 01-27 22:06:29 [plugins/__init__.py:43] Available plugins for group vllm.general_plugins:
DEBUG 01-27 22:06:29 [plugins/__init__.py:45] - 01.hpu_custom_ops -> vllm_gaudi:register_ops
DEBUG 01-27 22:06:29 [plugins/__init__.py:45] - 02.hpu_custom_models -> vllm_gaudi:register_models
DEBUG 01-27 22:06:29 [plugins/__init__.py:45] - lora_filesystem_resolver -> vllm.plugins.lora_resolvers.filesystem_resolver:register_filesystem_resolver
DEBUG 01-27 22:06:29 [plugins/__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
WARNING 01-27 22:06:29 [platforms/interface.py:222] Failed to import from vllm._C: ModuleNotFoundError("No module named 'vllm._C'")
WARNING 01-27 22:06:29 [distributed/.../v1/nixl_connector.py:99] NIXL is not available
WARNING 01-27 22:06:29 [distributed/.../v1/nixl_connector.py:111] NIXL agent config is not available
DEBUG 01-27 22:06:29 [utils/flashinfer.py:55] FlashInfer unavailable since package was not found
WARNING 01-27 22:06:30 [platform.py:163] Pin memory is not supported on HPU.
WARNING 01-27 22:06:30 [model_executor/models/registry.py:801] Model architecture Gemma3ForConditionalGeneration is already registered, and will be overwritten by the new model class vllm_gaudi.models.gemma3_mm:HpuGemma3ForConditionalGeneration.
WARNING 01-27 22:06:30 [model_executor/models/registry.py:801] Model architecture Qwen2_5_VLForConditionalGeneration is already registered, and will be overwritten by the new model class vllm_gaudi.models.qwen2_5_vl:HpuQwen2_5_VLForConditionalGeneration.
WARNING 01-27 22:06:30 [model_executor/models/registry.py:801] Model architecture Qwen3VLForConditionalGeneration is already registered, and will be overwritten by the new model class vllm_gaudi.models.qwen3_vl:HpuQwen3_VLForConditionalGeneration.
DEBUG 01-27 22:06:30 [compilation/decorators.py:202] Inferred dynamic dimensions for forward method of <class 'vllm.model_executor.models.qwen3_moe.Qwen3MoeModel'>: ['input_ids', 'positions', 'intermediate_tensors', 'inputs_embeds']
WARNING 01-27 22:06:30 [model_executor/models/registry.py:801] Model architecture Qwen3VLMoeForConditionalGeneration is already registered, and will be overwritten by the new model class vllm_gaudi.models.qwen3_vl_moe:HpuQwen3_VLMoeForConditionalGeneration.
[0;36m(APIServer pid=380742)[0;0m INFO 01-27 22:06:30 [entrypoints/openai/api_server.py:1272] vLLM API server version 0.14.1
[0;36m(APIServer pid=380742)[0;0m INFO 01-27 22:06:30 [entrypoints/utils.py:263] non-default args: {'host': 'localhost', 'port': 12346, 'model': '/root/.cache/huggingface/hub/models--Qwen--Qwen3-VL-32B-Instruct-FP8/snapshots/4bf2c2f39c37c0fede78bede4056e1f18cdf8109/', 'trust_remote_code': True, 'max_model_len': 32768, 'gpu_memory_utilization': 0.75, 'limit_mm_per_prompt': {'image': 100}, 'mm_processor_kwargs': {'size': {'shortest_edge': 65536, 'longest_edge': 1048576}}, 'max_num_batched_tokens': 32768, 'async_scheduling': True}
[0;36m(APIServer pid=380742)[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
[0;36m(APIServer pid=380742)[0;0m loading configuration file /root/.cache/huggingface/hub/models--Qwen--Qwen3-VL-32B-Instruct-FP8/snapshots/4bf2c2f39c37c0fede78bede4056e1f18cdf8109/config.json
[0;36m(APIServer pid=380742)[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
[0;36m(APIServer pid=380742)[0;0m loading configuration file /root/.cache/huggingface/hub/models--Qwen--Qwen3-VL-32B-Instruct-FP8/snapshots/4bf2c2f39c37c0fede78bede4056e1f18cdf8109/config.json
[0;36m(APIServer pid=380742)[0;0m loading configuration file /root/.cache/huggingface/hub/models--Qwen--Qwen3-VL-32B-Instruct-FP8/snapshots/4bf2c2f39c37c0fede78bede4056e1f18cdf8109/config.json
[0;36m(APIServer pid=380742)[0;0m Model config Qwen3VLConfig {
[0;36m(APIServer pid=380742)[0;0m   "architectures": [
[0;36m(APIServer pid=380742)[0;0m     "Qwen3VLForConditionalGeneration"
[0;36m(APIServer pid=380742)[0;0m   ],
[0;36m(APIServer pid=380742)[0;0m   "image_token_id": 151655,
[0;36m(APIServer pid=380742)[0;0m   "model_type": "qwen3_vl",
[0;36m(APIServer pid=380742)[0;0m   "quantization_config": {
[0;36m(APIServer pid=380742)[0;0m     "activation_scheme": "dynamic",
[0;36m(APIServer pid=380742)[0;0m     "fmt": "e4m3",
[0;36m(APIServer pid=380742)[0;0m     "ignored_layers": [
[0;36m(APIServer pid=380742)[0;0m       "lm_head",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.merger.linear_fc1",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.merger.linear_fc2",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.merger.norm",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.patch_embed.proj",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.pos_embed",
[0;36m(APIServer pid=380742)[0;0m       "visual.merger.linear_fc1",
[0;36m(APIServer pid=380742)[0;0m       "visual.merger.linear_fc2",
[0;36m(APIServer pid=380742)[0;0m       "visual.merger.norm",
[0;36m(APIServer pid=380742)[0;0m       "visual.patch_embed.proj",
[0;36m(APIServer pid=380742)[0;0m       "visual.pos_embed",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.blocks.0.attn.proj",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.blocks.0.attn.qkv",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.blocks.0.mlp.linear_fc1",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.blocks.0.mlp.linear_fc2",
[0;36m(APIServer pid=380742)[0;0m       "visual.blocks.0.attn.proj",
[0;36m(APIServer pid=380742)[0;0m       "visual.blocks.0.attn.qkv_proj",
[0;36m(APIServer pid=380742)[0;0m       "visual.blocks.0.mlp.linear_fc1",
[0;36m(APIServer pid=380742)[0;0m       "visual.blocks.0.mlp.linear_fc2",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.blocks.1.attn.proj",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.blocks.1.attn.qkv",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.blocks.1.mlp.linear_fc1",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.blocks.1.mlp.linear_fc2",
[0;36m(APIServer pid=380742)[0;0m       "visual.blocks.1.attn.proj",
[0;36m(APIServer pid=380742)[0;0m       "visual.blocks.1.attn.qkv_proj",
[0;36m(APIServer pid=380742)[0;0m       "visual.blocks.1.mlp.linear_fc1",
[0;36m(APIServer pid=380742)[0;0m       "visual.blocks.1.mlp.linear_fc2",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.blocks.2.attn.proj",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.blocks.2.attn.qkv",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.blocks.2.mlp.linear_fc1",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.blocks.2.mlp.linear_fc2",
[0;36m(APIServer pid=380742)[0;0m       "visual.blocks.2.attn.proj",
[0;36m(APIServer pid=380742)[0;0m       "visual.blocks.2.attn.qkv_proj",
[0;36m(APIServer pid=380742)[0;0m       "visual.blocks.2.mlp.linear_fc1",
[0;36m(APIServer pid=380742)[0;0m       "visual.blocks.2.mlp.linear_fc2",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.blocks.3.attn.proj",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.blocks.3.attn.qkv",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.blocks.3.mlp.linear_fc1",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.blocks.3.mlp.linear_fc2",
[0;36m(APIServer pid=380742)[0;0m       "visual.blocks.3.attn.proj",
[0;36m(APIServer pid=380742)[0;0m       "visual.blocks.3.attn.qkv_proj",
[0;36m(APIServer pid=380742)[0;0m       "visual.blocks.3.mlp.linear_fc1",
[0;36m(APIServer pid=380742)[0;0m       "visual.blocks.3.mlp.linear_fc2",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.blocks.4.attn.proj",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.blocks.4.attn.qkv",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.blocks.4.mlp.linear_fc1",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.blocks.4.mlp.linear_fc2",
[0;36m(APIServer pid=380742)[0;0m       "visual.blocks.4.attn.proj",
[0;36m(APIServer pid=380742)[0;0m       "visual.blocks.4.attn.qkv_proj",
[0;36m(APIServer pid=380742)[0;0m       "visual.blocks.4.mlp.linear_fc1",
[0;36m(APIServer pid=380742)[0;0m       "visual.blocks.4.mlp.linear_fc2",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.blocks.5.attn.proj",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.blocks.5.attn.qkv",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.blocks.5.mlp.linear_fc1",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.blocks.5.mlp.linear_fc2",
[0;36m(APIServer pid=380742)[0;0m       "visual.blocks.5.attn.proj",
[0;36m(APIServer pid=380742)[0;0m       "visual.blocks.5.attn.qkv_proj",
[0;36m(APIServer pid=380742)[0;0m       "visual.blocks.5.mlp.linear_fc1",
[0;36m(APIServer pid=380742)[0;0m       "visual.blocks.5.mlp.linear_fc2",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.blocks.6.attn.proj",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.blocks.6.attn.qkv",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.blocks.6.mlp.linear_fc1",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.blocks.6.mlp.linear_fc2",
[0;36m(APIServer pid=380742)[0;0m       "visual.blocks.6.attn.proj",
[0;36m(APIServer pid=380742)[0;0m       "visual.blocks.6.attn.qkv_proj",
[0;36m(APIServer pid=380742)[0;0m       "visual.blocks.6.mlp.linear_fc1",
[0;36m(APIServer pid=380742)[0;0m       "visual.blocks.6.mlp.linear_fc2",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.blocks.7.attn.proj",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.blocks.7.attn.qkv",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.blocks.7.mlp.linear_fc1",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.blocks.7.mlp.linear_fc2",
[0;36m(APIServer pid=380742)[0;0m       "visual.blocks.7.attn.proj",
[0;36m(APIServer pid=380742)[0;0m       "visual.blocks.7.attn.qkv_proj",
[0;36m(APIServer pid=380742)[0;0m       "visual.blocks.7.mlp.linear_fc1",
[0;36m(APIServer pid=380742)[0;0m       "visual.blocks.7.mlp.linear_fc2",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.blocks.8.attn.proj",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.blocks.8.attn.qkv",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.blocks.8.mlp.linear_fc1",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.blocks.8.mlp.linear_fc2",
[0;36m(APIServer pid=380742)[0;0m       "visual.blocks.8.attn.proj",
[0;36m(APIServer pid=380742)[0;0m       "visual.blocks.8.attn.qkv_proj",
[0;36m(APIServer pid=380742)[0;0m       "visual.blocks.8.mlp.linear_fc1",
[0;36m(APIServer pid=380742)[0;0m       "visual.blocks.8.mlp.linear_fc2",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.blocks.9.attn.proj",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.blocks.9.attn.qkv",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.blocks.9.mlp.linear_fc1",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.blocks.9.mlp.linear_fc2",
[0;36m(APIServer pid=380742)[0;0m       "visual.blocks.9.attn.proj",
[0;36m(APIServer pid=380742)[0;0m       "visual.blocks.9.attn.qkv_proj",
[0;36m(APIServer pid=380742)[0;0m       "visual.blocks.9.mlp.linear_fc1",
[0;36m(APIServer pid=380742)[0;0m       "visual.blocks.9.mlp.linear_fc2",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.blocks.10.attn.proj",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.blocks.10.attn.qkv",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.blocks.10.mlp.linear_fc1",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.blocks.10.mlp.linear_fc2",
[0;36m(APIServer pid=380742)[0;0m       "visual.blocks.10.attn.proj",
[0;36m(APIServer pid=380742)[0;0m       "visual.blocks.10.attn.qkv_proj",
[0;36m(APIServer pid=380742)[0;0m       "visual.blocks.10.mlp.linear_fc1",
[0;36m(APIServer pid=380742)[0;0m       "visual.blocks.10.mlp.linear_fc2",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.blocks.11.attn.proj",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.blocks.11.attn.qkv",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.blocks.11.mlp.linear_fc1",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.blocks.11.mlp.linear_fc2",
[0;36m(APIServer pid=380742)[0;0m       "visual.blocks.11.attn.proj",
[0;36m(APIServer pid=380742)[0;0m       "visual.blocks.11.attn.qkv_proj",
[0;36m(APIServer pid=380742)[0;0m       "visual.blocks.11.mlp.linear_fc1",
[0;36m(APIServer pid=380742)[0;0m       "visual.blocks.11.mlp.linear_fc2",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.blocks.12.attn.proj",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.blocks.12.attn.qkv",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.blocks.12.mlp.linear_fc1",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.blocks.12.mlp.linear_fc2",
[0;36m(APIServer pid=380742)[0;0m       "visual.blocks.12.attn.proj",
[0;36m(APIServer pid=380742)[0;0m       "visual.blocks.12.attn.qkv_proj",
[0;36m(APIServer pid=380742)[0;0m       "visual.blocks.12.mlp.linear_fc1",
[0;36m(APIServer pid=380742)[0;0m       "visual.blocks.12.mlp.linear_fc2",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.blocks.13.attn.proj",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.blocks.13.attn.qkv",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.blocks.13.mlp.linear_fc1",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.blocks.13.mlp.linear_fc2",
[0;36m(APIServer pid=380742)[0;0m       "visual.blocks.13.attn.proj",
[0;36m(APIServer pid=380742)[0;0m       "visual.blocks.13.attn.qkv_proj",
[0;36m(APIServer pid=380742)[0;0m       "visual.blocks.13.mlp.linear_fc1",
[0;36m(APIServer pid=380742)[0;0m       "visual.blocks.13.mlp.linear_fc2",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.blocks.14.attn.proj",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.blocks.14.attn.qkv",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.blocks.14.mlp.linear_fc1",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.blocks.14.mlp.linear_fc2",
[0;36m(APIServer pid=380742)[0;0m       "visual.blocks.14.attn.proj",
[0;36m(APIServer pid=380742)[0;0m       "visual.blocks.14.attn.qkv_proj",
[0;36m(APIServer pid=380742)[0;0m       "visual.blocks.14.mlp.linear_fc1",
[0;36m(APIServer pid=380742)[0;0m       "visual.blocks.14.mlp.linear_fc2",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.blocks.15.attn.proj",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.blocks.15.attn.qkv",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.blocks.15.mlp.linear_fc1",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.blocks.15.mlp.linear_fc2",
[0;36m(APIServer pid=380742)[0;0m       "visual.blocks.15.attn.proj",
[0;36m(APIServer pid=380742)[0;0m       "visual.blocks.15.attn.qkv_proj",
[0;36m(APIServer pid=380742)[0;0m       "visual.blocks.15.mlp.linear_fc1",
[0;36m(APIServer pid=380742)[0;0m       "visual.blocks.15.mlp.linear_fc2",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.blocks.16.attn.proj",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.blocks.16.attn.qkv",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.blocks.16.mlp.linear_fc1",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.blocks.16.mlp.linear_fc2",
[0;36m(APIServer pid=380742)[0;0m       "visual.blocks.16.attn.proj",
[0;36m(APIServer pid=380742)[0;0m       "visual.blocks.16.attn.qkv_proj",
[0;36m(APIServer pid=380742)[0;0m       "visual.blocks.16.mlp.linear_fc1",
[0;36m(APIServer pid=380742)[0;0m       "visual.blocks.16.mlp.linear_fc2",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.blocks.17.attn.proj",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.blocks.17.attn.qkv",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.blocks.17.mlp.linear_fc1",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.blocks.17.mlp.linear_fc2",
[0;36m(APIServer pid=380742)[0;0m       "visual.blocks.17.attn.proj",
[0;36m(APIServer pid=380742)[0;0m       "visual.blocks.17.attn.qkv_proj",
[0;36m(APIServer pid=380742)[0;0m       "visual.blocks.17.mlp.linear_fc1",
[0;36m(APIServer pid=380742)[0;0m       "visual.blocks.17.mlp.linear_fc2",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.blocks.18.attn.proj",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.blocks.18.attn.qkv",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.blocks.18.mlp.linear_fc1",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.blocks.18.mlp.linear_fc2",
[0;36m(APIServer pid=380742)[0;0m       "visual.blocks.18.attn.proj",
[0;36m(APIServer pid=380742)[0;0m       "visual.blocks.18.attn.qkv_proj",
[0;36m(APIServer pid=380742)[0;0m       "visual.blocks.18.mlp.linear_fc1",
[0;36m(APIServer pid=380742)[0;0m       "visual.blocks.18.mlp.linear_fc2",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.blocks.19.attn.proj",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.blocks.19.attn.qkv",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.blocks.19.mlp.linear_fc1",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.blocks.19.mlp.linear_fc2",
[0;36m(APIServer pid=380742)[0;0m       "visual.blocks.19.attn.proj",
[0;36m(APIServer pid=380742)[0;0m       "visual.blocks.19.attn.qkv_proj",
[0;36m(APIServer pid=380742)[0;0m       "visual.blocks.19.mlp.linear_fc1",
[0;36m(APIServer pid=380742)[0;0m       "visual.blocks.19.mlp.linear_fc2",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.blocks.20.attn.proj",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.blocks.20.attn.qkv",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.blocks.20.mlp.linear_fc1",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.blocks.20.mlp.linear_fc2",
[0;36m(APIServer pid=380742)[0;0m       "visual.blocks.20.attn.proj",
[0;36m(APIServer pid=380742)[0;0m       "visual.blocks.20.attn.qkv_proj",
[0;36m(APIServer pid=380742)[0;0m       "visual.blocks.20.mlp.linear_fc1",
[0;36m(APIServer pid=380742)[0;0m       "visual.blocks.20.mlp.linear_fc2",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.blocks.21.attn.proj",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.blocks.21.attn.qkv",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.blocks.21.mlp.linear_fc1",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.blocks.21.mlp.linear_fc2",
[0;36m(APIServer pid=380742)[0;0m       "visual.blocks.21.attn.proj",
[0;36m(APIServer pid=380742)[0;0m       "visual.blocks.21.attn.qkv_proj",
[0;36m(APIServer pid=380742)[0;0m       "visual.blocks.21.mlp.linear_fc1",
[0;36m(APIServer pid=380742)[0;0m       "visual.blocks.21.mlp.linear_fc2",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.blocks.22.attn.proj",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.blocks.22.attn.qkv",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.blocks.22.mlp.linear_fc1",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.blocks.22.mlp.linear_fc2",
[0;36m(APIServer pid=380742)[0;0m       "visual.blocks.22.attn.proj",
[0;36m(APIServer pid=380742)[0;0m       "visual.blocks.22.attn.qkv_proj",
[0;36m(APIServer pid=380742)[0;0m       "visual.blocks.22.mlp.linear_fc1",
[0;36m(APIServer pid=380742)[0;0m       "visual.blocks.22.mlp.linear_fc2",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.blocks.23.attn.proj",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.blocks.23.attn.qkv",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.blocks.23.mlp.linear_fc1",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.blocks.23.mlp.linear_fc2",
[0;36m(APIServer pid=380742)[0;0m       "visual.blocks.23.attn.proj",
[0;36m(APIServer pid=380742)[0;0m       "visual.blocks.23.attn.qkv_proj",
[0;36m(APIServer pid=380742)[0;0m       "visual.blocks.23.mlp.linear_fc1",
[0;36m(APIServer pid=380742)[0;0m       "visual.blocks.23.mlp.linear_fc2",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.blocks.24.attn.proj",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.blocks.24.attn.qkv",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.blocks.24.mlp.linear_fc1",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.blocks.24.mlp.linear_fc2",
[0;36m(APIServer pid=380742)[0;0m       "visual.blocks.24.attn.proj",
[0;36m(APIServer pid=380742)[0;0m       "visual.blocks.24.attn.qkv_proj",
[0;36m(APIServer pid=380742)[0;0m       "visual.blocks.24.mlp.linear_fc1",
[0;36m(APIServer pid=380742)[0;0m       "visual.blocks.24.mlp.linear_fc2",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.blocks.25.attn.proj",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.blocks.25.attn.qkv",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.blocks.25.mlp.linear_fc1",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.blocks.25.mlp.linear_fc2",
[0;36m(APIServer pid=380742)[0;0m       "visual.blocks.25.attn.proj",
[0;36m(APIServer pid=380742)[0;0m       "visual.blocks.25.attn.qkv_proj",
[0;36m(APIServer pid=380742)[0;0m       "visual.blocks.25.mlp.linear_fc1",
[0;36m(APIServer pid=380742)[0;0m       "visual.blocks.25.mlp.linear_fc2",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.blocks.26.attn.proj",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.blocks.26.attn.qkv",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.blocks.26.mlp.linear_fc1",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.blocks.26.mlp.linear_fc2",
[0;36m(APIServer pid=380742)[0;0m       "visual.blocks.26.attn.proj",
[0;36m(APIServer pid=380742)[0;0m       "visual.blocks.26.attn.qkv_proj",
[0;36m(APIServer pid=380742)[0;0m       "visual.blocks.26.mlp.linear_fc1",
[0;36m(APIServer pid=380742)[0;0m       "visual.blocks.26.mlp.linear_fc2",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.deepstack_merger_list.0.linear_fc1",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.deepstack_merger_list.0.linear_fc2",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.deepstack_merger_list.0.norm",
[0;36m(APIServer pid=380742)[0;0m       "visual.deepstack_merger_list.0.linear_fc1",
[0;36m(APIServer pid=380742)[0;0m       "visual.deepstack_merger_list.0.linear_fc2",
[0;36m(APIServer pid=380742)[0;0m       "visual.deepstack_merger_list.0.norm",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.deepstack_merger_list.1.linear_fc1",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.deepstack_merger_list.1.linear_fc2",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.deepstack_merger_list.1.norm",
[0;36m(APIServer pid=380742)[0;0m       "visual.deepstack_merger_list.1.linear_fc1",
[0;36m(APIServer pid=380742)[0;0m       "visual.deepstack_merger_list.1.linear_fc2",
[0;36m(APIServer pid=380742)[0;0m       "visual.deepstack_merger_list.1.norm",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.deepstack_merger_list.2.linear_fc1",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.deepstack_merger_list.2.linear_fc2",
[0;36m(APIServer pid=380742)[0;0m       "model.visual.deepstack_merger_list.2.norm",
[0;36m(APIServer pid=380742)[0;0m       "visual.deepstack_merger_list.2.linear_fc1",
[0;36m(APIServer pid=380742)[0;0m       "visual.deepstack_merger_list.2.linear_fc2",
[0;36m(APIServer pid=380742)[0;0m       "visual.deepstack_merger_list.2.norm"
[0;36m(APIServer pid=380742)[0;0m     ],
[0;36m(APIServer pid=380742)[0;0m     "quant_method": "fp8",
[0;36m(APIServer pid=380742)[0;0m     "weight_block_size": [
[0;36m(APIServer pid=380742)[0;0m       128,
[0;36m(APIServer pid=380742)[0;0m       128
[0;36m(APIServer pid=380742)[0;0m     ]
[0;36m(APIServer pid=380742)[0;0m   },
[0;36m(APIServer pid=380742)[0;0m   "text_config": {
[0;36m(APIServer pid=380742)[0;0m     "attention_bias": false,
[0;36m(APIServer pid=380742)[0;0m     "attention_dropout": 0.0,
[0;36m(APIServer pid=380742)[0;0m     "bos_token_id": 151643,
[0;36m(APIServer pid=380742)[0;0m     "dtype": "bfloat16",
[0;36m(APIServer pid=380742)[0;0m     "eos_token_id": 151645,
[0;36m(APIServer pid=380742)[0;0m     "head_dim": 128,
[0;36m(APIServer pid=380742)[0;0m     "hidden_act": "silu",
[0;36m(APIServer pid=380742)[0;0m     "hidden_size": 5120,
[0;36m(APIServer pid=380742)[0;0m     "initializer_range": 0.02,
[0;36m(APIServer pid=380742)[0;0m     "intermediate_size": 25600,
[0;36m(APIServer pid=380742)[0;0m     "max_position_embeddings": 262144,
[0;36m(APIServer pid=380742)[0;0m     "model_type": "qwen3_vl_text",
[0;36m(APIServer pid=380742)[0;0m     "num_attention_heads": 64,
[0;36m(APIServer pid=380742)[0;0m     "num_hidden_layers": 64,
[0;36m(APIServer pid=380742)[0;0m     "num_key_value_heads": 8,
[0;36m(APIServer pid=380742)[0;0m     "rms_norm_eps": 1e-06,
[0;36m(APIServer pid=380742)[0;0m     "rope_scaling": {
[0;36m(APIServer pid=380742)[0;0m       "mrope_interleaved": true,
[0;36m(APIServer pid=380742)[0;0m       "mrope_section": [
[0;36m(APIServer pid=380742)[0;0m         24,
[0;36m(APIServer pid=380742)[0;0m         20,
[0;36m(APIServer pid=380742)[0;0m         20
[0;36m(APIServer pid=380742)[0;0m       ],
[0;36m(APIServer pid=380742)[0;0m       "rope_type": "default"
[0;36m(APIServer pid=380742)[0;0m     },
[0;36m(APIServer pid=380742)[0;0m     "rope_theta": 5000000,
[0;36m(APIServer pid=380742)[0;0m     "use_cache": true,
[0;36m(APIServer pid=380742)[0;0m     "vocab_size": 151936
[0;36m(APIServer pid=380742)[0;0m   },
[0;36m(APIServer pid=380742)[0;0m   "tie_word_embeddings": false,
[0;36m(APIServer pid=380742)[0;0m   "transformers_version": "4.57.6",
[0;36m(APIServer pid=380742)[0;0m   "video_token_id": 151656,
[0;36m(APIServer pid=380742)[0;0m   "vision_config": {
[0;36m(APIServer pid=380742)[0;0m     "deepstack_visual_indexes": [
[0;36m(APIServer pid=380742)[0;0m       8,
[0;36m(APIServer pid=380742)[0;0m       16,
[0;36m(APIServer pid=380742)[0;0m       24
[0;36m(APIServer pid=380742)[0;0m     ],
[0;36m(APIServer pid=380742)[0;0m     "depth": 27,
[0;36m(APIServer pid=380742)[0;0m     "hidden_act": "gelu_pytorch_tanh",
[0;36m(APIServer pid=380742)[0;0m     "hidden_size": 1152,
[0;36m(APIServer pid=380742)[0;0m     "in_channels": 3,
[0;36m(APIServer pid=380742)[0;0m     "initializer_range": 0.02,
[0;36m(APIServer pid=380742)[0;0m     "intermediate_size": 4304,
[0;36m(APIServer pid=380742)[0;0m     "model_type": "qwen3_vl",
[0;36m(APIServer pid=380742)[0;0m     "num_heads": 16,
[0;36m(APIServer pid=380742)[0;0m     "num_position_embeddings": 2304,
[0;36m(APIServer pid=380742)[0;0m     "out_hidden_size": 5120,
[0;36m(APIServer pid=380742)[0;0m     "patch_size": 16,
[0;36m(APIServer pid=380742)[0;0m     "spatial_merge_size": 2,
[0;36m(APIServer pid=380742)[0;0m     "temporal_patch_size": 2
[0;36m(APIServer pid=380742)[0;0m   },
[0;36m(APIServer pid=380742)[0;0m   "vision_end_token_id": 151653,
[0;36m(APIServer pid=380742)[0;0m   "vision_start_token_id": 151652
[0;36m(APIServer pid=380742)[0;0m }
[0;36m(APIServer pid=380742)[0;0m 
[0;36m(APIServer pid=380742)[0;0m DEBUG 01-27 22:06:30 [model_executor/models/registry.py:713] Loaded model info for class vllm_gaudi.models.qwen3_vl.HpuQwen3_VLForConditionalGeneration from cache
[0;36m(APIServer pid=380742)[0;0m DEBUG 01-27 22:06:30 [logging_utils/log_time.py:29] Registry inspect model class: Elapsed time 0.0006202 secs
[0;36m(APIServer pid=380742)[0;0m INFO 01-27 22:06:30 [config/model.py:530] Resolved architecture: Qwen3VLForConditionalGeneration
[0;36m(APIServer pid=380742)[0;0m INFO 01-27 22:06:30 [config/model.py:1545] Using max model len 32768
[0;36m(APIServer pid=380742)[0;0m DEBUG 01-27 22:06:30 [_ipex_ops.py:15] Import error msg: No module named 'intel_extension_for_pytorch'
[0;36m(APIServer pid=380742)[0;0m DEBUG 01-27 22:06:30 [config/model.py:1609] Generative models support chunked prefill.
[0;36m(APIServer pid=380742)[0;0m DEBUG 01-27 22:06:30 [config/model.py:1667] Generative models support prefix caching.
[0;36m(APIServer pid=380742)[0;0m DEBUG 01-27 22:06:30 [engine/arg_utils.py:1909] Enabling chunked prefill by default
[0;36m(APIServer pid=380742)[0;0m DEBUG 01-27 22:06:30 [engine/arg_utils.py:1939] Enabling prefix caching by default
[0;36m(APIServer pid=380742)[0;0m WARNING 01-27 22:06:30 [platform.py:95] This is a workaround! Please check the NOTE in the get_device_total_memory definition.
[0;36m(APIServer pid=380742)[0;0m DEBUG 01-27 22:06:30 [engine/arg_utils.py:2027] Defaulting max_num_seqs to 256 for OPENAI_API_SERVER usage context.
[0;36m(APIServer pid=380742)[0;0m DEBUG 01-27 22:06:30 [config/parallel.py:689] Disabled the custom all-reduce kernel because it is not supported on current platform.
[0;36m(APIServer pid=380742)[0;0m INFO 01-27 22:06:30 [config/scheduler.py:229] Chunked prefill is enabled with max_num_batched_tokens=32768.
[0;36m(APIServer pid=380742)[0;0m DEBUG 01-27 22:06:30 [config/parallel.py:689] Disabled the custom all-reduce kernel because it is not supported on current platform.
[0;36m(APIServer pid=380742)[0;0m INFO 01-27 22:06:30 [config/vllm.py:630] Asynchronous scheduling is enabled.
[0;36m(APIServer pid=380742)[0;0m INFO 01-27 22:06:30 [config/vllm.py:637] Disabling NCCL for DP synchronization when using async scheduling.
[0;36m(APIServer pid=380742)[0;0m INFO 01-27 22:06:30 [platform.py:147] [HPU] Forcing CompilationMode.NONE compilation mode
[0;36m(APIServer pid=380742)[0;0m =========compilation_config.custom_ops=['all']===========
[0;36m(APIServer pid=380742)[0;0m DEBUG 01-27 22:06:30 [plugins/__init__.py:35] No plugins for group vllm.stat_logger_plugins found.
[0;36m(APIServer pid=380742)[0;0m DEBUG 01-27 22:06:30 [tokenizers/registry.py:64] Loading CachedHfTokenizer for tokenizer_mode='hf'
[0;36m(APIServer pid=380742)[0;0m loading file vocab.json
[0;36m(APIServer pid=380742)[0;0m loading file merges.txt
[0;36m(APIServer pid=380742)[0;0m loading file tokenizer.json
[0;36m(APIServer pid=380742)[0;0m loading file added_tokens.json
[0;36m(APIServer pid=380742)[0;0m loading file special_tokens_map.json
[0;36m(APIServer pid=380742)[0;0m loading file tokenizer_config.json
[0;36m(APIServer pid=380742)[0;0m loading file chat_template.jinja
[0;36m(APIServer pid=380742)[0;0m Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[0;36m(APIServer pid=380742)[0;0m loading configuration file /root/.cache/huggingface/hub/models--Qwen--Qwen3-VL-32B-Instruct-FP8/snapshots/4bf2c2f39c37c0fede78bede4056e1f18cdf8109/generation_config.json
[0;36m(APIServer pid=380742)[0;0m Generate config GenerationConfig {
[0;36m(APIServer pid=380742)[0;0m   "bos_token_id": 151643,
[0;36m(APIServer pid=380742)[0;0m   "do_sample": true,
[0;36m(APIServer pid=380742)[0;0m   "eos_token_id": [
[0;36m(APIServer pid=380742)[0;0m     151645,
[0;36m(APIServer pid=380742)[0;0m     151643
[0;36m(APIServer pid=380742)[0;0m   ],
[0;36m(APIServer pid=380742)[0;0m   "pad_token_id": 151643,
[0;36m(APIServer pid=380742)[0;0m   "temperature": 0.7,
[0;36m(APIServer pid=380742)[0;0m   "top_k": 20,
[0;36m(APIServer pid=380742)[0;0m   "top_p": 0.8
[0;36m(APIServer pid=380742)[0;0m }
[0;36m(APIServer pid=380742)[0;0m 
[0;36m(APIServer pid=380742)[0;0m DEBUG 01-27 22:06:30 [plugins/io_processors/__init__.py:33] No IOProcessor plugins requested by the model
Calling add_step_closure function does not have any effect. It's lazy mode only functionality. (warning logged once)
Calling mark_step function does not have any effect. It's lazy mode only functionality. (warning logged once)
Calling iter_mark_step function does not have any effect. It's lazy mode only functionality. (warning logged once)
INFO 01-27 22:06:33 [plugins/__init__.py:43] Available plugins for group vllm.platform_plugins:
INFO 01-27 22:06:33 [plugins/__init__.py:45] - hpu -> vllm_gaudi:register
INFO 01-27 22:06:33 [plugins/__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
DEBUG 01-27 22:06:33 [platforms/__init__.py:36] Checking if TPU platform is available.
DEBUG 01-27 22:06:33 [platforms/__init__.py:55] TPU platform is not available because: No module named 'libtpu'
DEBUG 01-27 22:06:33 [platforms/__init__.py:61] Checking if CUDA platform is available.
DEBUG 01-27 22:06:33 [platforms/__init__.py:88] Exception happens when checking CUDA platform: NVML Shared Library Not Found
DEBUG 01-27 22:06:33 [platforms/__init__.py:105] CUDA platform is not available because: NVML Shared Library Not Found
DEBUG 01-27 22:06:33 [platforms/__init__.py:112] Checking if ROCm platform is available.
DEBUG 01-27 22:06:33 [platforms/__init__.py:126] ROCm platform is not available because: No module named 'amdsmi'
DEBUG 01-27 22:06:33 [platforms/__init__.py:133] Checking if XPU platform is available.
DEBUG 01-27 22:06:33 [platforms/__init__.py:153] XPU platform is not available because: No module named 'intel_extension_for_pytorch'
DEBUG 01-27 22:06:33 [platforms/__init__.py:160] Checking if CPU platform is available.
INFO 01-27 22:06:33 [platforms/__init__.py:217] Platform plugin hpu is activated
INFO 01-27 22:06:34 [triton_utils/importing.py:44] Triton is installed but 0 active driver(s) found (expected 1). Disabling Triton to prevent runtime errors.
INFO 01-27 22:06:34 [triton_utils/importing.py:68] Triton not installed or not compatible; certain GPU-related functions will not be available.
WARNING 01-27 22:06:36 [platforms/interface.py:222] Failed to import from vllm._C: ModuleNotFoundError("No module named 'vllm._C'")
DEBUG 01-27 22:06:36 [utils/flashinfer.py:55] FlashInfer unavailable since package was not found
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:36 [v1/engine/core.py:862] Waiting for init message from front-end.
[0;36m(APIServer pid=380742)[0;0m DEBUG 01-27 22:06:36 [v1/engine/utils.py:1081] HELLO from local core engine process 0.
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:36 [v1/engine/core.py:873] Received init message: EngineHandshakeMetadata(addresses=EngineZmqAddresses(inputs=['ipc:///tmp/0c46754a-7b7d-4956-8508-c8f422df6ba7'], outputs=['ipc:///tmp/ff29ea9f-bffa-4b9a-b0d2-71cd4eab3e4a'], coordinator_input=None, coordinator_output=None, frontend_stats_publish_address=None), parallel_config={})
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:36 [v1/engine/core.py:677] Has DP Coordinator: False, stats publish address: None
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:36 [plugins/__init__.py:43] Available plugins for group vllm.general_plugins:
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:36 [plugins/__init__.py:45] - 01.hpu_custom_ops -> vllm_gaudi:register_ops
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:36 [plugins/__init__.py:45] - 02.hpu_custom_models -> vllm_gaudi:register_models
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:36 [plugins/__init__.py:45] - lora_filesystem_resolver -> vllm.plugins.lora_resolvers.filesystem_resolver:register_filesystem_resolver
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:36 [plugins/__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
[0;36m(EngineCore_DP0 pid=381139)[0;0m WARNING 01-27 22:06:36 [distributed/.../v1/nixl_connector.py:99] NIXL is not available
[0;36m(EngineCore_DP0 pid=381139)[0;0m WARNING 01-27 22:06:36 [distributed/.../v1/nixl_connector.py:111] NIXL agent config is not available
[0;36m(EngineCore_DP0 pid=381139)[0;0m WARNING 01-27 22:06:36 [platform.py:163] Pin memory is not supported on HPU.
[0;36m(EngineCore_DP0 pid=381139)[0;0m WARNING 01-27 22:06:36 [model_executor/models/registry.py:801] Model architecture Gemma3ForConditionalGeneration is already registered, and will be overwritten by the new model class vllm_gaudi.models.gemma3_mm:HpuGemma3ForConditionalGeneration.
[0;36m(EngineCore_DP0 pid=381139)[0;0m WARNING 01-27 22:06:36 [model_executor/models/registry.py:801] Model architecture Qwen2_5_VLForConditionalGeneration is already registered, and will be overwritten by the new model class vllm_gaudi.models.qwen2_5_vl:HpuQwen2_5_VLForConditionalGeneration.
[0;36m(EngineCore_DP0 pid=381139)[0;0m WARNING 01-27 22:06:36 [model_executor/models/registry.py:801] Model architecture Qwen3VLForConditionalGeneration is already registered, and will be overwritten by the new model class vllm_gaudi.models.qwen3_vl:HpuQwen3_VLForConditionalGeneration.
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:36 [compilation/decorators.py:202] Inferred dynamic dimensions for forward method of <class 'vllm.model_executor.models.qwen3_moe.Qwen3MoeModel'>: ['input_ids', 'positions', 'intermediate_tensors', 'inputs_embeds']
[0;36m(EngineCore_DP0 pid=381139)[0;0m WARNING 01-27 22:06:36 [model_executor/models/registry.py:801] Model architecture Qwen3VLMoeForConditionalGeneration is already registered, and will be overwritten by the new model class vllm_gaudi.models.qwen3_vl_moe:HpuQwen3_VLMoeForConditionalGeneration.
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:06:36 [v1/engine/core.py:97] Initializing a V1 LLM engine (v0.14.1) with config: model='/root/.cache/huggingface/hub/models--Qwen--Qwen3-VL-32B-Instruct-FP8/snapshots/4bf2c2f39c37c0fede78bede4056e1f18cdf8109/', speculative_config=None, tokenizer='/root/.cache/huggingface/hub/models--Qwen--Qwen3-VL-32B-Instruct-FP8/snapshots/4bf2c2f39c37c0fede78bede4056e1f18cdf8109/', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=32768, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=fp8, enforce_eager=False, enable_return_routed_experts=False, kv_cache_dtype=auto, device_config=hpu, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01, cudagraph_metrics=False, enable_layerwise_nvtx_tracing=False, enable_mfu_metrics=False, enable_mm_processor_stats=False, enable_logging_iteration_details=False), seed=0, served_model_name=/root/.cache/huggingface/hub/models--Qwen--Qwen3-VL-32B-Instruct-FP8/snapshots/4bf2c2f39c37c0fede78bede4056e1f18cdf8109/, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.NONE: 0>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'hpu_backend', 'custom_ops': ['all', '+quant_fp8'], 'splitting_ops': [], 'compile_mm_encoder': False, 'compile_sizes': None, 'compile_ranges_split_points': [32768], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.NONE: 0>, 'cudagraph_num_of_warmups': 0, 'cudagraph_capture_sizes': [], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': True, 'fuse_act_quant': True, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': None, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>, 'evaluate_guards': False, 'assume_32_bit_indexing': True}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:36 [compilation/decorators.py:202] Inferred dynamic dimensions for forward method of <class 'vllm.model_executor.models.deepseek_v2.DeepseekV2Model'>: ['input_ids', 'positions', 'intermediate_tensors', 'inputs_embeds']
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:36 [compilation/decorators.py:202] Inferred dynamic dimensions for forward method of <class 'vllm.model_executor.models.llama.LlamaModel'>: ['input_ids', 'positions', 'intermediate_tensors', 'inputs_embeds']
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:36 [tokenizers/registry.py:64] Loading CachedHfTokenizer for tokenizer_mode='hf'
[0;36m(EngineCore_DP0 pid=381139)[0;0m loading file vocab.json
[0;36m(EngineCore_DP0 pid=381139)[0;0m loading file merges.txt
[0;36m(EngineCore_DP0 pid=381139)[0;0m loading file tokenizer.json
[0;36m(EngineCore_DP0 pid=381139)[0;0m loading file added_tokens.json
[0;36m(EngineCore_DP0 pid=381139)[0;0m loading file special_tokens_map.json
[0;36m(EngineCore_DP0 pid=381139)[0;0m loading file tokenizer_config.json
[0;36m(EngineCore_DP0 pid=381139)[0;0m loading file chat_template.jinja
[0;36m(EngineCore_DP0 pid=381139)[0;0m Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:37 [distributed/parallel_state.py:1172] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://172.26.46.50:40397 backend=hccl
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:06:37 [distributed/parallel_state.py:1214] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://172.26.46.50:40397 backend=hccl
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:37 [distributed/parallel_state.py:1258] Detected 1 nodes in the distributed environment
============================= HPU PT BRIDGE CONFIGURATION ON RANK = 0 ============= 
 PT_HPU_LAZY_MODE = 0
 PT_HPU_RECIPE_CACHE_CONFIG = ,false,1024,false
 PT_HPU_MAX_COMPOUND_OP_SIZE = 9223372036854775807
 PT_HPU_LAZY_ACC_PAR_MODE = 1
 PT_HPU_ENABLE_REFINE_DYNAMIC_SHAPES = 0
 PT_HPU_EAGER_PIPELINE_ENABLE = 1
 PT_HPU_EAGER_COLLECTIVE_PIPELINE_ENABLE = 1
 PT_HPU_ENABLE_LAZY_COLLECTIVES = 1
---------------------------: System Configuration :---------------------------
Num CPU Cores : 224
CPU RAM       : 1007 GB
------------------------------------------------------------------------------
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:06:37 [distributed/parallel_state.py:1425] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank N/A
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:06:38 [runtime.py:28] Environment:
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:06:38 [runtime.py:32]     hw: gaudi3
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:06:38 [runtime.py:32]     build: 1.23.0.695
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:06:38 [runtime.py:32]     engine_version: v1
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:06:38 [runtime.py:32]     bridge_mode: eager
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:06:38 [runtime.py:32]     model_type: qwen3_vl
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:06:38 [runtime.py:32]     prefix_caching: True
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:06:38 [runtime.py:32]     vllm_gaudi_commit: heads/libinta/libinta/add_mask+981abc5
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:06:38 [runtime.py:28] Features:
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:06:38 [runtime.py:32]     fp32_alibi_biases: True
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:06:38 [runtime.py:32]     fp32_softmax: False
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:06:38 [runtime.py:32]     fused_block_softmax_adjustment: False
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:06:38 [runtime.py:32]     fused_block_softmax: False
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:06:38 [runtime.py:32]     prompt_attn_impl: fsdpa_impl
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:06:38 [runtime.py:32]     skip_warmup: True
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:06:38 [runtime.py:32]     merged_prefill: False
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:06:38 [runtime.py:32]     use_contiguous_pa: False
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:06:38 [runtime.py:32]     use_bucketing: True
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:06:38 [runtime.py:32]     bucketing_strategy: linear_bucketing
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:06:38 [runtime.py:32]     defrag: False
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:06:38 [runtime.py:32]     regional_compilation: True
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:06:38 [runtime.py:32]     dynamic_shapes_compilation: True
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:06:38 [runtime.py:32]     fullgraph_compilation: False
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:06:38 [runtime.py:32]     unified_attn: False
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:06:38 [runtime.py:32]     unified_attn_softmax_fa2: False
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:06:38 [runtime.py:32]     scale_adjustment: True
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:06:38 [runtime.py:32]     flatten_input: False
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:06:38 [runtime.py:32]     unified_attn_shared_cache_ratio: 0.8
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:06:38 [runtime.py:32]     high_level_profiler_enabled: False
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:06:38 [runtime.py:32]     track_graph_compilation: False
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:06:38 [runtime.py:32]     use_output_tensor_in_matmulqk: False
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:06:38 [runtime.py:32]     per_token_kv_scaling_support: False
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:06:38 [runtime.py:32]     moe_chunk: 
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:06:38 [runtime.py:32]     moe_token_boundary: 
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:06:38 [runtime.py:32]     use_dispatch_fn: False
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:06:38 [runtime.py:32]     use_hpu_aligned_scale: False
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:06:38 [runtime.py:28] User flags:
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:06:38 [runtime.py:32]     VLLM_EXPONENTIAL_BUCKETING: False
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:06:38 [runtime.py:32]     VLLM_PROMPT_BS_BUCKET_MIN: 1
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:06:38 [runtime.py:32]     VLLM_PROMPT_BS_BUCKET_STEP: 1
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:06:38 [runtime.py:32]     VLLM_PROMPT_BS_BUCKET_MAX: 1
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:06:38 [runtime.py:32]     VLLM_PROMPT_SEQ_BUCKET_MIN: 5120
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:06:38 [runtime.py:32]     VLLM_PROMPT_SEQ_BUCKET_STEP: 256
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:06:38 [runtime.py:32]     VLLM_PROMPT_SEQ_BUCKET_MAX: 6400
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:06:38 [runtime.py:32]     VLLM_PROMPT_CTX_BUCKET_MIN: 0
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:06:38 [runtime.py:32]     VLLM_PROMPT_CTX_BUCKET_STEP: 12
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:06:38 [runtime.py:32]     VLLM_PROMPT_CTX_BUCKET_MAX: 24
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:06:38 [runtime.py:32]     VLLM_DECODE_BS_BUCKET_MIN: 1
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:06:38 [runtime.py:32]     VLLM_DECODE_BS_BUCKET_STEP: 4
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:06:38 [runtime.py:32]     VLLM_DECODE_BS_BUCKET_MAX: 64
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:06:38 [runtime.py:32]     VLLM_DECODE_BLOCK_BUCKET_MIN: 48
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:06:38 [runtime.py:32]     VLLM_DECODE_BLOCK_BUCKET_STEP: 16
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:06:38 [runtime.py:32]     VLLM_DECODE_BLOCK_BUCKET_MAX: 64
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:06:38 [runtime.py:32]     EXPERIMENTAL_WEIGHT_SHARING: 0
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:06:38 [runtime.py:32]     PT_HPU_WEIGHT_SHARING: 0
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:06:38 [runtime.py:32]     RUNTIME_SCALE_PATCHING: 1
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700] model config: ModelConfig(model='/root/.cache/huggingface/hub/models--Qwen--Qwen3-VL-32B-Instruct-FP8/snapshots/4bf2c2f39c37c0fede78bede4056e1f18cdf8109/', model_weights='', runner='auto', convert='auto', tokenizer='/root/.cache/huggingface/hub/models--Qwen--Qwen3-VL-32B-Instruct-FP8/snapshots/4bf2c2f39c37c0fede78bede4056e1f18cdf8109/', tokenizer_mode='auto', trust_remote_code=True, dtype=torch.bfloat16, seed=0, hf_config=Qwen3VLConfig {
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]   "architectures": [
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]     "Qwen3VLForConditionalGeneration"
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]   ],
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]   "image_token_id": 151655,
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]   "model_type": "qwen3_vl",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]   "quantization_config": {
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]     "activation_scheme": "dynamic",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]     "fmt": "e4m3",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]     "ignored_layers": [
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "lm_head",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.merger.linear_fc1",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.merger.linear_fc2",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.merger.norm",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.patch_embed.proj",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.pos_embed",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.merger.linear_fc1",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.merger.linear_fc2",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.merger.norm",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.patch_embed.proj",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.pos_embed",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.blocks.0.attn.proj",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.blocks.0.attn.qkv",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.blocks.0.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.blocks.0.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.blocks.0.attn.proj",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.blocks.0.attn.qkv_proj",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.blocks.0.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.blocks.0.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.blocks.1.attn.proj",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.blocks.1.attn.qkv",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.blocks.1.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.blocks.1.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.blocks.1.attn.proj",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.blocks.1.attn.qkv_proj",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.blocks.1.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.blocks.1.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.blocks.2.attn.proj",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.blocks.2.attn.qkv",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.blocks.2.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.blocks.2.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.blocks.2.attn.proj",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.blocks.2.attn.qkv_proj",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.blocks.2.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.blocks.2.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.blocks.3.attn.proj",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.blocks.3.attn.qkv",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.blocks.3.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.blocks.3.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.blocks.3.attn.proj",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.blocks.3.attn.qkv_proj",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.blocks.3.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.blocks.3.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.blocks.4.attn.proj",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.blocks.4.attn.qkv",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.blocks.4.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.blocks.4.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.blocks.4.attn.proj",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.blocks.4.attn.qkv_proj",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.blocks.4.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.blocks.4.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.blocks.5.attn.proj",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.blocks.5.attn.qkv",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.blocks.5.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.blocks.5.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.blocks.5.attn.proj",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.blocks.5.attn.qkv_proj",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.blocks.5.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.blocks.5.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.blocks.6.attn.proj",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.blocks.6.attn.qkv",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.blocks.6.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.blocks.6.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.blocks.6.attn.proj",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.blocks.6.attn.qkv_proj",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.blocks.6.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.blocks.6.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.blocks.7.attn.proj",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.blocks.7.attn.qkv",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.blocks.7.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.blocks.7.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.blocks.7.attn.proj",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.blocks.7.attn.qkv_proj",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.blocks.7.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.blocks.7.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.blocks.8.attn.proj",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.blocks.8.attn.qkv",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.blocks.8.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.blocks.8.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.blocks.8.attn.proj",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.blocks.8.attn.qkv_proj",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.blocks.8.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.blocks.8.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.blocks.9.attn.proj",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.blocks.9.attn.qkv",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.blocks.9.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.blocks.9.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.blocks.9.attn.proj",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.blocks.9.attn.qkv_proj",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.blocks.9.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.blocks.9.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.blocks.10.attn.proj",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.blocks.10.attn.qkv",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.blocks.10.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.blocks.10.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.blocks.10.attn.proj",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.blocks.10.attn.qkv_proj",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.blocks.10.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.blocks.10.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.blocks.11.attn.proj",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.blocks.11.attn.qkv",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.blocks.11.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.blocks.11.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.blocks.11.attn.proj",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.blocks.11.attn.qkv_proj",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.blocks.11.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.blocks.11.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.blocks.12.attn.proj",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.blocks.12.attn.qkv",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.blocks.12.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.blocks.12.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.blocks.12.attn.proj",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.blocks.12.attn.qkv_proj",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.blocks.12.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.blocks.12.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.blocks.13.attn.proj",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.blocks.13.attn.qkv",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.blocks.13.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.blocks.13.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.blocks.13.attn.proj",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.blocks.13.attn.qkv_proj",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.blocks.13.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.blocks.13.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.blocks.14.attn.proj",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.blocks.14.attn.qkv",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.blocks.14.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.blocks.14.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.blocks.14.attn.proj",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.blocks.14.attn.qkv_proj",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.blocks.14.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.blocks.14.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.blocks.15.attn.proj",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.blocks.15.attn.qkv",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.blocks.15.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.blocks.15.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.blocks.15.attn.proj",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.blocks.15.attn.qkv_proj",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.blocks.15.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.blocks.15.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.blocks.16.attn.proj",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.blocks.16.attn.qkv",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.blocks.16.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.blocks.16.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.blocks.16.attn.proj",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.blocks.16.attn.qkv_proj",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.blocks.16.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.blocks.16.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.blocks.17.attn.proj",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.blocks.17.attn.qkv",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.blocks.17.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.blocks.17.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.blocks.17.attn.proj",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.blocks.17.attn.qkv_proj",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.blocks.17.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.blocks.17.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.blocks.18.attn.proj",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.blocks.18.attn.qkv",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.blocks.18.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.blocks.18.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.blocks.18.attn.proj",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.blocks.18.attn.qkv_proj",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.blocks.18.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.blocks.18.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.blocks.19.attn.proj",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.blocks.19.attn.qkv",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.blocks.19.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.blocks.19.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.blocks.19.attn.proj",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.blocks.19.attn.qkv_proj",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.blocks.19.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.blocks.19.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.blocks.20.attn.proj",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.blocks.20.attn.qkv",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.blocks.20.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.blocks.20.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.blocks.20.attn.proj",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.blocks.20.attn.qkv_proj",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.blocks.20.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.blocks.20.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.blocks.21.attn.proj",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.blocks.21.attn.qkv",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.blocks.21.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.blocks.21.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.blocks.21.attn.proj",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.blocks.21.attn.qkv_proj",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.blocks.21.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.blocks.21.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.blocks.22.attn.proj",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.blocks.22.attn.qkv",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.blocks.22.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.blocks.22.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.blocks.22.attn.proj",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.blocks.22.attn.qkv_proj",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.blocks.22.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.blocks.22.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.blocks.23.attn.proj",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.blocks.23.attn.qkv",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.blocks.23.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.blocks.23.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.blocks.23.attn.proj",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.blocks.23.attn.qkv_proj",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.blocks.23.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.blocks.23.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.blocks.24.attn.proj",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.blocks.24.attn.qkv",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.blocks.24.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.blocks.24.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.blocks.24.attn.proj",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.blocks.24.attn.qkv_proj",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.blocks.24.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.blocks.24.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.blocks.25.attn.proj",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.blocks.25.attn.qkv",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.blocks.25.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.blocks.25.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.blocks.25.attn.proj",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.blocks.25.attn.qkv_proj",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.blocks.25.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.blocks.25.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.blocks.26.attn.proj",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.blocks.26.attn.qkv",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.blocks.26.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.blocks.26.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.blocks.26.attn.proj",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.blocks.26.attn.qkv_proj",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.blocks.26.mlp.linear_fc1",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.blocks.26.mlp.linear_fc2",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.deepstack_merger_list.0.linear_fc1",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.deepstack_merger_list.0.linear_fc2",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.deepstack_merger_list.0.norm",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.deepstack_merger_list.0.linear_fc1",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.deepstack_merger_list.0.linear_fc2",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.deepstack_merger_list.0.norm",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.deepstack_merger_list.1.linear_fc1",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.deepstack_merger_list.1.linear_fc2",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.deepstack_merger_list.1.norm",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.deepstack_merger_list.1.linear_fc1",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.deepstack_merger_list.1.linear_fc2",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.deepstack_merger_list.1.norm",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.deepstack_merger_list.2.linear_fc1",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.deepstack_merger_list.2.linear_fc2",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "model.visual.deepstack_merger_list.2.norm",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.deepstack_merger_list.2.linear_fc1",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.deepstack_merger_list.2.linear_fc2",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "visual.deepstack_merger_list.2.norm"
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]     ],
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]     "quant_method": "fp8",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]     "weight_block_size": [
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       128,
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       128
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]     ]
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]   },
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]   "text_config": {
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]     "attention_bias": false,
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]     "attention_dropout": 0.0,
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]     "bos_token_id": 151643,
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]     "dtype": "bfloat16",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]     "eos_token_id": 151645,
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]     "head_dim": 128,
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]     "hidden_act": "silu",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]     "hidden_size": 5120,
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]     "initializer_range": 0.02,
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]     "intermediate_size": 25600,
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]     "max_position_embeddings": 262144,
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]     "model_type": "qwen3_vl_text",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]     "num_attention_heads": 64,
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]     "num_hidden_layers": 64,
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]     "num_key_value_heads": 8,
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]     "rms_norm_eps": 1e-06,
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]     "rope_parameters": {
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "mrope_interleaved": true,
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "mrope_section": [
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]         24,
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]         20,
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]         20
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       ],
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "rope_theta": 5000000,
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "rope_type": "default"
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]     },
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]     "rope_scaling": {
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "mrope_interleaved": true,
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "mrope_section": [
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]         24,
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]         20,
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]         20
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       ],
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "rope_theta": 5000000,
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       "rope_type": "default"
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]     },
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]     "rope_theta": 5000000,
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]     "use_cache": true,
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]     "vocab_size": 151936
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]   },
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]   "tie_word_embeddings": false,
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]   "transformers_version": "4.57.6",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]   "video_token_id": 151656,
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]   "vision_config": {
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]     "deepstack_visual_indexes": [
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       8,
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       16,
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       24
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]     ],
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]     "depth": 27,
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]     "hidden_act": "gelu_pytorch_tanh",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]     "hidden_size": 1152,
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]     "in_channels": 3,
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]     "initializer_range": 0.02,
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]     "intermediate_size": 4304,
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]     "model_type": "qwen3_vl",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]     "num_heads": 16,
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]     "num_position_embeddings": 2304,
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]     "out_hidden_size": 5120,
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]     "patch_size": 16,
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]     "spatial_merge_size": 2,
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]     "temporal_patch_size": 2
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]   },
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]   "vision_end_token_id": 151653,
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]   "vision_start_token_id": 151652
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700] }
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700] , hf_text_config=Qwen3VLTextConfig {
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]   "attention_bias": false,
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]   "attention_dropout": 0.0,
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]   "bos_token_id": 151643,
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]   "dtype": "bfloat16",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]   "eos_token_id": 151645,
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]   "head_dim": 128,
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]   "hidden_act": "silu",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]   "hidden_size": 5120,
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]   "initializer_range": 0.02,
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]   "intermediate_size": 25600,
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]   "max_position_embeddings": 262144,
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]   "model_type": "qwen3_vl_text",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]   "num_attention_heads": 64,
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]   "num_hidden_layers": 64,
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]   "num_key_value_heads": 8,
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]   "rms_norm_eps": 1e-06,
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]   "rope_parameters": {
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]     "mrope_interleaved": true,
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]     "mrope_section": [
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       24,
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       20,
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       20
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]     ],
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]     "rope_theta": 5000000,
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]     "rope_type": "default"
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]   },
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]   "rope_scaling": {
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]     "mrope_interleaved": true,
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]     "mrope_section": [
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       24,
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       20,
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]       20
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]     ],
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]     "rope_theta": 5000000,
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]     "rope_type": "default"
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]   },
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]   "rope_theta": 5000000,
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]   "tie_word_embeddings": false,
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]   "transformers_version": "4.57.6",
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]   "use_cache": true,
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700]   "vocab_size": 151936
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700] }
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [hpu_model_runner.py:700] , hf_config_path=None, allowed_local_media_path='', allowed_media_domains=None, revision=None, code_revision=None, tokenizer_revision=None, max_model_len=32768, spec_target_max_model_len=None, quantization='fp8', allow_deprecated_quantization=False, enforce_eager=False, enable_return_routed_experts=False, max_logprobs=20, logprobs_mode='raw_logprobs', disable_sliding_window=False, disable_cascade_attn=False, skip_tokenizer_init=False, enable_prompt_embeds=False, served_model_name='/root/.cache/huggingface/hub/models--Qwen--Qwen3-VL-32B-Instruct-FP8/snapshots/4bf2c2f39c37c0fede78bede4056e1f18cdf8109/', config_format='auto', hf_token=None, hf_overrides={}, logits_processor_pattern=None, generation_config='auto', override_generation_config={}, enable_sleep_mode=False, model_impl='auto', override_attention_dtype=None, logits_processors=None, io_processor_plugin=None, pooler_config=None, multimodal_config=MultiModalConfig(limit_per_prompt={'image': ImageDummyOptions(count=100, width=None, height=None)}, enable_mm_embeds=False, media_io_kwargs={}, mm_processor_kwargs={'size': {'shortest_edge': 65536, 'longest_edge': 1048576}}, mm_processor_cache_gb=4.0, mm_processor_cache_type='lru', mm_shm_cache_max_object_size_mb=128, mm_encoder_tp_mode='weights', mm_encoder_attn_backend=None, interleave_mm_strings=False, skip_mm_profiling=False, video_pruning_rate=None))
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:06:38 [platform.py:65] Using HPUAttentionV1 backend.
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [v1/sample/logits_processor/__init__.py:63] No logitsprocs plugins installed (group vllm.logits_processors).
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:06:38 [hpu_model_runner.py:803] Bucketing is ON.
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:06:38 [hpu_model_runner.py:3700] Starting to load model /root/.cache/huggingface/hub/models--Qwen--Qwen3-VL-32B-Instruct-FP8/snapshots/4bf2c2f39c37c0fede78bede4056e1f18cdf8109/...
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: Conv3dLayer using <class 'vllm_gaudi.ops.hpu_conv.HPUConv3dLayer'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RotaryEmbedding using <class 'vllm_gaudi.ops.hpu_rotary_embedding.HPURotaryEmbedding'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:06:38 [platforms/interface.py:267] Using default backend AttentionBackendEnum.TORCH_SDPA for vit attention
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:06:38 [model_executor/.../attention/mm_encoder_attention.py:86] Using AttentionBackendEnum.TORCH_SDPA for MMEncoderAttention.
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [utils/deep_gemm.py:86] DeepGEMM E8M0 disabled: DeepGEMM not supported on this system.
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: MRotaryEmbedding using <class 'vllm_gaudi.ops.hpu_rotary_embedding.HPUMRotaryEmbedding'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:06:38 [platform.py:65] Using HPUAttentionV1 backend.
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: RMSNorm using <class 'vllm_gaudi.ops.hpu_layernorm.HPURMSNorm'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: Conv3dLayer using <class 'vllm_gaudi.ops.hpu_conv.HPUConv3dLayer'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/custom_op.py:34] Instantiating custom op: MMEncoderAttention using <class 'vllm_gaudi.ops.hpu_mm_encoder_attention.HpuMMEncoderAttention'>
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [config/compilation.py:1035] enabled custom ops: Counter({'column_parallel_linear': 325, 'row_parallel_linear': 325, 'RMSNorm': 257, 'quant_fp8': 256, 'apply_rotary_emb': 137, 'MMEncoderAttention': 108, 'silu_and_mul': 64, 'Conv3dLayer': 2, 'RotaryEmbedding': 1, 'vocab_parallel_embedding': 1, 'MRotaryEmbedding': 1, 'parallel_lm_head': 1, 'logits_processor': 1})
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [config/compilation.py:1036] disabled custom ops: Counter()
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:38 [model_executor/model_loader/base_loader.py:56] Loading weights on hpu ...
[0;36m(EngineCore_DP0 pid=381139)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/7 [00:00<?, ?it/s]
[0;36m(EngineCore_DP0 pid=381139)[0;0m Loading safetensors checkpoint shards:  14% Completed | 1/7 [00:00<00:04,  1.46it/s]
[0;36m(EngineCore_DP0 pid=381139)[0;0m Loading safetensors checkpoint shards:  29% Completed | 2/7 [00:01<00:04,  1.08it/s]
[0;36m(EngineCore_DP0 pid=381139)[0;0m Loading safetensors checkpoint shards:  43% Completed | 3/7 [00:02<00:03,  1.03it/s]
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:06:42 [model_executor/models/utils.py:220] Loaded weight lm_head.weight with shape torch.Size([151936, 5120])
[0;36m(EngineCore_DP0 pid=381139)[0;0m Loading safetensors checkpoint shards:  57% Completed | 4/7 [00:03<00:03,  1.05s/it]
[0;36m(EngineCore_DP0 pid=381139)[0;0m Loading safetensors checkpoint shards:  71% Completed | 5/7 [00:04<00:02,  1.02s/it]
[0;36m(EngineCore_DP0 pid=381139)[0;0m Loading safetensors checkpoint shards:  86% Completed | 6/7 [00:06<00:01,  1.06s/it]
[0;36m(EngineCore_DP0 pid=381139)[0;0m Loading safetensors checkpoint shards: 100% Completed | 7/7 [00:07<00:00,  1.11s/it]
[0;36m(EngineCore_DP0 pid=381139)[0;0m Loading safetensors checkpoint shards: 100% Completed | 7/7 [00:07<00:00,  1.04s/it]
[0;36m(EngineCore_DP0 pid=381139)[0;0m 
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:06:45 [model_executor/model_loader/default_loader.py:291] Loading weights took 7.37 seconds
[0;36m(APIServer pid=380742)[0;0m DEBUG 01-27 22:06:46 [v1/engine/utils.py:970] Waiting for 1 local, 0 remote core engine proc(s) to start.
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:06:46 [hpu_model_runner.py:3706] Loading model weights took 34.7600 GB
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:06:46 [hpu_model_runner.py:3748] Wrapping in HPUGraph took 0.0000 GB
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:06:47 [hpu_model_runner.py:3776] Compilation took 0.0000 GB
[0;36m(EngineCore_DP0 pid=381139)[0;0m WARNING 01-27 22:06:47 [common.py:245] Prompt bucket for (1, 32768, 0) was not prepared. Adding new bucket: (1, 32768, 0)
[0;36m(EngineCore_DP0 pid=381139)[0;0m /usr/local/lib/python3.12/dist-packages/torch/_dynamo/variables/functions.py:1692: UserWarning: Dynamo detected a call to a `functools.lru_cache`-wrapped function. Dynamo ignores the cache wrapper and directly traces the wrapped function. Silent incorrectness is only a *potential* risk, not something we have observed. Enable TORCH_LOGS="+dynamo" for a DEBUG stack trace.
[0;36m(EngineCore_DP0 pid=381139)[0;0m   torch._dynamo.utils.warn_once(msg)
[0;36m(APIServer pid=380742)[0;0m DEBUG 01-27 22:06:56 [v1/engine/utils.py:970] Waiting for 1 local, 0 remote core engine proc(s) to start.
[0;36m(APIServer pid=380742)[0;0m DEBUG 01-27 22:07:06 [v1/engine/utils.py:970] Waiting for 1 local, 0 remote core engine proc(s) to start.
[0;36m(APIServer pid=380742)[0;0m DEBUG 01-27 22:07:16 [v1/engine/utils.py:970] Waiting for 1 local, 0 remote core engine proc(s) to start.
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:07:25 [hpu_worker.py:236] Model profiling run took 9.042 GiB of device memory (43.84 GiB/126.5 GiB used) and 5.39 GiB of host memory (90.88 GiB/1007 GiB used)
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:07:25 [hpu_worker.py:260] Free device memory: 82.7 GiB, 62.03 GiB usable (gpu_memory_utilization=0.75), 24.81 GiB reserved for HPUGraphs (VLLM_GRAPH_RESERVED_MEM=0.4), 32 MiB reserved for KV cache dummy block 37.18 GiB reserved for usable KV cache
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:07:26 [v1/core/kv_cache_utils.py:1305] GPU KV cache size: 152,192 tokens
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:07:26 [v1/core/kv_cache_utils.py:1310] Maximum concurrency for 32,768 tokens per request: 4.64x
[0;36m(APIServer pid=380742)[0;0m DEBUG 01-27 22:07:26 [v1/engine/utils.py:970] Waiting for 1 local, 0 remote core engine proc(s) to start.
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:07:26 [hpu_worker.py:288] Usable num_blocks: 1189, actual allocated num_blocks: 152320 (_PAD_BLOCK_ID=0, _PAD_SLOT_ID=-1)
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:07:26 [hpu_worker.py:291] Initializing cache engine took 37.19 GiB of device memory (81 GiB/126.5 GiB used) and 82.79 MiB of host memory (91 GiB/1007 GiB used)
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:07:26 [linear.py:116] VLLM_PROMPT_BS_BUCKET_MIN=1 (default:1)
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:07:26 [linear.py:116] VLLM_PROMPT_BS_BUCKET_STEP=1 (default:1)
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:07:26 [linear.py:116] VLLM_PROMPT_BS_BUCKET_MAX=1 (default:1)
[0;36m(EngineCore_DP0 pid=381139)[0;0m WARNING 01-27 22:07:26 [linear.py:113] VLLM_PROMPT_QUERY_BUCKET_MIN not set, using VLLM_PROMPT_SEQ_BUCKET_MIN value (5120) instead. This fallback behavior is deprecated and will be removed in v0.12.0.
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:07:26 [linear.py:116] VLLM_PROMPT_QUERY_BUCKET_MIN=5120 (default:128)
[0;36m(EngineCore_DP0 pid=381139)[0;0m WARNING 01-27 22:07:26 [linear.py:113] VLLM_PROMPT_QUERY_BUCKET_STEP not set, using VLLM_PROMPT_SEQ_BUCKET_STEP value (256) instead. This fallback behavior is deprecated and will be removed in v0.12.0.
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:07:26 [linear.py:116] VLLM_PROMPT_QUERY_BUCKET_STEP=256 (default:128)
[0;36m(EngineCore_DP0 pid=381139)[0;0m WARNING 01-27 22:07:26 [linear.py:113] VLLM_PROMPT_QUERY_BUCKET_MAX not set, using VLLM_PROMPT_SEQ_BUCKET_MAX value (6400) instead. This fallback behavior is deprecated and will be removed in v0.12.0.
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:07:26 [linear.py:116] VLLM_PROMPT_QUERY_BUCKET_MAX=6400 (default:32768)
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:07:26 [linear.py:116] VLLM_PROMPT_CTX_BUCKET_MIN=0 (default:0)
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:07:26 [linear.py:116] VLLM_PROMPT_CTX_BUCKET_STEP=12 (default:1)
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:07:26 [linear.py:116] VLLM_PROMPT_CTX_BUCKET_MAX=24 (default:216)
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:07:26 [linear.py:52] Prompt bucket config (min, step, max_warmup) bs:[1, 1, 1], query:[5120, 256, 6400], blocks:[0, 12, 24]
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:07:26 [common.py:220] Generated 18 prompt buckets [bs, query, num_blocks]: [(1, 5120, 0), (1, 5120, 12), (1, 5120, 216), (1, 5376, 0), (1, 5376, 12), (1, 5376, 214), (1, 5632, 0), (1, 5632, 12), (1, 5632, 212), (1, 5888, 0), (1, 5888, 12), (1, 5888, 210), (1, 6144, 0), (1, 6144, 12), (1, 6144, 208), (1, 6400, 0), (1, 6400, 12), (1, 6400, 206)]
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:07:26 [linear.py:116] VLLM_DECODE_BS_BUCKET_MIN=1 (default:1)
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:07:26 [linear.py:116] VLLM_DECODE_BS_BUCKET_STEP=4 (default:32)
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:07:26 [linear.py:116] VLLM_DECODE_BS_BUCKET_MAX=64 (default:256)
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:07:26 [linear.py:116] VLLM_DECODE_BLOCK_BUCKET_MIN=48 (default:1)
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:07:26 [linear.py:116] VLLM_DECODE_BLOCK_BUCKET_STEP=16 (default:128)
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:07:26 [linear.py:116] VLLM_DECODE_BLOCK_BUCKET_MAX=64 (default:65536)
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:07:26 [linear.py:81] Decode bucket config (min, step, max_warmup) bs:[1, 4, 64], blocks:[48, 16, 64]
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:07:26 [common.py:220] Generated 32 decode buckets [bs, query, num_blocks]: [(1, 1, 48), (1, 1, 64), (2, 1, 48), (2, 1, 64), (4, 1, 48), (4, 1, 64), (8, 1, 48), (8, 1, 64), (12, 1, 48), (12, 1, 64), (16, 1, 48), (16, 1, 64), (20, 1, 48), (20, 1, 64), (24, 1, 48), (24, 1, 64), (28, 1, 48), (28, 1, 64), (32, 1, 48), (32, 1, 64), (36, 1, 48), (36, 1, 64), (40, 1, 48), (40, 1, 64), (44, 1, 48), (44, 1, 64), (48, 1, 48), (48, 1, 64), (52, 1, 64), (56, 1, 64), (60, 1, 64), (64, 1, 64)]
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:07:26 [hpu_model_runner.py:4725] Multimodal bucket : [256, 480, 512, 660, 900, 1024, 1200, 1590, 2048, 3520]
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:07:26 [hpu_model_runner.py:4773] Skipping warmup...
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:07:26 [linear.py:116] VLLM_PROMPT_BS_BUCKET_MIN=1 (default:1)
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:07:26 [linear.py:116] VLLM_PROMPT_BS_BUCKET_STEP=1 (default:1)
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:07:26 [linear.py:116] VLLM_PROMPT_BS_BUCKET_MAX=1 (default:1)
[0;36m(EngineCore_DP0 pid=381139)[0;0m WARNING 01-27 22:07:26 [linear.py:113] VLLM_PROMPT_QUERY_BUCKET_MIN not set, using VLLM_PROMPT_SEQ_BUCKET_MIN value (5120) instead. This fallback behavior is deprecated and will be removed in v0.12.0.
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:07:26 [linear.py:116] VLLM_PROMPT_QUERY_BUCKET_MIN=5120 (default:128)
[0;36m(EngineCore_DP0 pid=381139)[0;0m WARNING 01-27 22:07:26 [linear.py:113] VLLM_PROMPT_QUERY_BUCKET_STEP not set, using VLLM_PROMPT_SEQ_BUCKET_STEP value (256) instead. This fallback behavior is deprecated and will be removed in v0.12.0.
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:07:26 [linear.py:116] VLLM_PROMPT_QUERY_BUCKET_STEP=256 (default:128)
[0;36m(EngineCore_DP0 pid=381139)[0;0m WARNING 01-27 22:07:26 [linear.py:113] VLLM_PROMPT_QUERY_BUCKET_MAX not set, using VLLM_PROMPT_SEQ_BUCKET_MAX value (6400) instead. This fallback behavior is deprecated and will be removed in v0.12.0.
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:07:26 [linear.py:116] VLLM_PROMPT_QUERY_BUCKET_MAX=6400 (default:32768)
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:07:26 [linear.py:116] VLLM_PROMPT_CTX_BUCKET_MIN=0 (default:0)
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:07:26 [linear.py:116] VLLM_PROMPT_CTX_BUCKET_STEP=12 (default:1)
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:07:26 [linear.py:116] VLLM_PROMPT_CTX_BUCKET_MAX=24 (default:216)
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:07:26 [linear.py:52] Prompt bucket config (min, step, max_warmup) bs:[1, 1, 1], query:[5120, 256, 6400], blocks:[0, 12, 24]
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:07:26 [common.py:220] Generated 18 prompt buckets [bs, query, num_blocks]: [(1, 5120, 0), (1, 5120, 12), (1, 5120, 216), (1, 5376, 0), (1, 5376, 12), (1, 5376, 214), (1, 5632, 0), (1, 5632, 12), (1, 5632, 212), (1, 5888, 0), (1, 5888, 12), (1, 5888, 210), (1, 6144, 0), (1, 6144, 12), (1, 6144, 208), (1, 6400, 0), (1, 6400, 12), (1, 6400, 206)]
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:07:26 [linear.py:116] VLLM_DECODE_BS_BUCKET_MIN=1 (default:1)
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:07:26 [linear.py:116] VLLM_DECODE_BS_BUCKET_STEP=4 (default:32)
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:07:26 [linear.py:116] VLLM_DECODE_BS_BUCKET_MAX=64 (default:256)
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:07:26 [linear.py:116] VLLM_DECODE_BLOCK_BUCKET_MIN=48 (default:1)
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:07:26 [linear.py:116] VLLM_DECODE_BLOCK_BUCKET_STEP=16 (default:128)
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:07:26 [linear.py:116] VLLM_DECODE_BLOCK_BUCKET_MAX=64 (default:65536)
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:07:26 [linear.py:81] Decode bucket config (min, step, max_warmup) bs:[1, 4, 64], blocks:[48, 16, 64]
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:07:26 [common.py:220] Generated 32 decode buckets [bs, query, num_blocks]: [(1, 1, 48), (1, 1, 64), (2, 1, 48), (2, 1, 64), (4, 1, 48), (4, 1, 64), (8, 1, 48), (8, 1, 64), (12, 1, 48), (12, 1, 64), (16, 1, 48), (16, 1, 64), (20, 1, 48), (20, 1, 64), (24, 1, 48), (24, 1, 64), (28, 1, 48), (28, 1, 64), (32, 1, 48), (32, 1, 64), (36, 1, 48), (36, 1, 64), (40, 1, 48), (40, 1, 64), (44, 1, 48), (44, 1, 64), (48, 1, 48), (48, 1, 64), (52, 1, 64), (56, 1, 64), (60, 1, 64), (64, 1, 64)]
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:07:26 [hpu_model_runner.py:4725] Multimodal bucket : [256, 480, 512, 660, 900, 1024, 1200, 1590, 2048, 3520]
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:07:26 [hpu_model_runner.py:4773] Skipping warmup...
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:07:26 [v1/engine/core.py:273] init engine (profile, create kv cache, warmup model) took 39.27 seconds
[0;36m(EngineCore_DP0 pid=381139)[0;0m loading configuration file /root/.cache/huggingface/hub/models--Qwen--Qwen3-VL-32B-Instruct-FP8/snapshots/4bf2c2f39c37c0fede78bede4056e1f18cdf8109/preprocessor_config.json
[0;36m(EngineCore_DP0 pid=381139)[0;0m Image processor Qwen2VLImageProcessorFast {
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "crop_size": null,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "data_format": "channels_first",
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "default_to_square": true,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "device": null,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "disable_grouping": null,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "do_center_crop": null,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "do_convert_rgb": true,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "do_normalize": true,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "do_pad": null,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "do_rescale": true,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "do_resize": true,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "image_mean": [
[0;36m(EngineCore_DP0 pid=381139)[0;0m     0.5,
[0;36m(EngineCore_DP0 pid=381139)[0;0m     0.5,
[0;36m(EngineCore_DP0 pid=381139)[0;0m     0.5
[0;36m(EngineCore_DP0 pid=381139)[0;0m   ],
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "image_processor_type": "Qwen2VLImageProcessorFast",
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "image_std": [
[0;36m(EngineCore_DP0 pid=381139)[0;0m     0.5,
[0;36m(EngineCore_DP0 pid=381139)[0;0m     0.5,
[0;36m(EngineCore_DP0 pid=381139)[0;0m     0.5
[0;36m(EngineCore_DP0 pid=381139)[0;0m   ],
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "input_data_format": null,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "max_pixels": null,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "merge_size": 2,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "min_pixels": null,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "pad_size": null,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "patch_size": 16,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "processor_class": "Qwen3VLProcessor",
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "resample": 3,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "rescale_factor": 0.00392156862745098,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "return_tensors": null,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "size": {
[0;36m(EngineCore_DP0 pid=381139)[0;0m     "longest_edge": 16777216,
[0;36m(EngineCore_DP0 pid=381139)[0;0m     "shortest_edge": 65536
[0;36m(EngineCore_DP0 pid=381139)[0;0m   },
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "temporal_patch_size": 2
[0;36m(EngineCore_DP0 pid=381139)[0;0m }
[0;36m(EngineCore_DP0 pid=381139)[0;0m 
[0;36m(EngineCore_DP0 pid=381139)[0;0m loading file vocab.json
[0;36m(EngineCore_DP0 pid=381139)[0;0m loading file merges.txt
[0;36m(EngineCore_DP0 pid=381139)[0;0m loading file tokenizer.json
[0;36m(EngineCore_DP0 pid=381139)[0;0m loading file added_tokens.json
[0;36m(EngineCore_DP0 pid=381139)[0;0m loading file special_tokens_map.json
[0;36m(EngineCore_DP0 pid=381139)[0;0m loading file tokenizer_config.json
[0;36m(EngineCore_DP0 pid=381139)[0;0m loading file chat_template.jinja
[0;36m(EngineCore_DP0 pid=381139)[0;0m Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[0;36m(EngineCore_DP0 pid=381139)[0;0m loading configuration file /root/.cache/huggingface/hub/models--Qwen--Qwen3-VL-32B-Instruct-FP8/snapshots/4bf2c2f39c37c0fede78bede4056e1f18cdf8109/video_preprocessor_config.json
[0;36m(EngineCore_DP0 pid=381139)[0;0m Video processor Qwen3VLVideoProcessor {
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "crop_size": null,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "data_format": "channels_first",
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "default_to_square": true,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "device": null,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "do_center_crop": null,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "do_convert_rgb": true,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "do_normalize": true,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "do_rescale": true,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "do_resize": true,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "do_sample_frames": true,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "fps": 2,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "image_mean": [
[0;36m(EngineCore_DP0 pid=381139)[0;0m     0.5,
[0;36m(EngineCore_DP0 pid=381139)[0;0m     0.5,
[0;36m(EngineCore_DP0 pid=381139)[0;0m     0.5
[0;36m(EngineCore_DP0 pid=381139)[0;0m   ],
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "image_std": [
[0;36m(EngineCore_DP0 pid=381139)[0;0m     0.5,
[0;36m(EngineCore_DP0 pid=381139)[0;0m     0.5,
[0;36m(EngineCore_DP0 pid=381139)[0;0m     0.5
[0;36m(EngineCore_DP0 pid=381139)[0;0m   ],
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "input_data_format": null,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "max_frames": 768,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "merge_size": 2,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "min_frames": 4,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "num_frames": null,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "pad_size": null,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "patch_size": 16,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "processor_class": "Qwen3VLProcessor",
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "resample": 3,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "rescale_factor": 0.00392156862745098,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "return_metadata": false,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "size": {
[0;36m(EngineCore_DP0 pid=381139)[0;0m     "longest_edge": 25165824,
[0;36m(EngineCore_DP0 pid=381139)[0;0m     "shortest_edge": 4096
[0;36m(EngineCore_DP0 pid=381139)[0;0m   },
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "temporal_patch_size": 2,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "video_metadata": null,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "video_processor_type": "Qwen3VLVideoProcessor"
[0;36m(EngineCore_DP0 pid=381139)[0;0m }
[0;36m(EngineCore_DP0 pid=381139)[0;0m 
[0;36m(EngineCore_DP0 pid=381139)[0;0m loading configuration file None
[0;36m(EngineCore_DP0 pid=381139)[0;0m Processor Qwen3VLProcessor:
[0;36m(EngineCore_DP0 pid=381139)[0;0m - image_processor: Qwen2VLImageProcessorFast {
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "crop_size": null,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "data_format": "channels_first",
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "default_to_square": true,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "device": null,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "disable_grouping": null,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "do_center_crop": null,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "do_convert_rgb": true,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "do_normalize": true,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "do_pad": null,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "do_rescale": true,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "do_resize": true,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "image_mean": [
[0;36m(EngineCore_DP0 pid=381139)[0;0m     0.5,
[0;36m(EngineCore_DP0 pid=381139)[0;0m     0.5,
[0;36m(EngineCore_DP0 pid=381139)[0;0m     0.5
[0;36m(EngineCore_DP0 pid=381139)[0;0m   ],
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "image_processor_type": "Qwen2VLImageProcessorFast",
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "image_std": [
[0;36m(EngineCore_DP0 pid=381139)[0;0m     0.5,
[0;36m(EngineCore_DP0 pid=381139)[0;0m     0.5,
[0;36m(EngineCore_DP0 pid=381139)[0;0m     0.5
[0;36m(EngineCore_DP0 pid=381139)[0;0m   ],
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "input_data_format": null,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "max_pixels": null,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "merge_size": 2,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "min_pixels": null,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "pad_size": null,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "patch_size": 16,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "processor_class": "Qwen3VLProcessor",
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "resample": 3,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "rescale_factor": 0.00392156862745098,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "return_tensors": null,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "size": {
[0;36m(EngineCore_DP0 pid=381139)[0;0m     "longest_edge": 16777216,
[0;36m(EngineCore_DP0 pid=381139)[0;0m     "shortest_edge": 65536
[0;36m(EngineCore_DP0 pid=381139)[0;0m   },
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "temporal_patch_size": 2
[0;36m(EngineCore_DP0 pid=381139)[0;0m }
[0;36m(EngineCore_DP0 pid=381139)[0;0m 
[0;36m(EngineCore_DP0 pid=381139)[0;0m - tokenizer: Qwen2TokenizerFast(name_or_path='/root/.cache/huggingface/hub/models--Qwen--Qwen3-VL-32B-Instruct-FP8/snapshots/4bf2c2f39c37c0fede78bede4056e1f18cdf8109/', vocab_size=151643, model_max_length=262144, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
[0;36m(EngineCore_DP0 pid=381139)[0;0m 	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
[0;36m(EngineCore_DP0 pid=381139)[0;0m 	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
[0;36m(EngineCore_DP0 pid=381139)[0;0m 	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
[0;36m(EngineCore_DP0 pid=381139)[0;0m 	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
[0;36m(EngineCore_DP0 pid=381139)[0;0m 	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
[0;36m(EngineCore_DP0 pid=381139)[0;0m 	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
[0;36m(EngineCore_DP0 pid=381139)[0;0m 	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
[0;36m(EngineCore_DP0 pid=381139)[0;0m 	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
[0;36m(EngineCore_DP0 pid=381139)[0;0m 	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
[0;36m(EngineCore_DP0 pid=381139)[0;0m 	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
[0;36m(EngineCore_DP0 pid=381139)[0;0m 	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
[0;36m(EngineCore_DP0 pid=381139)[0;0m 	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
[0;36m(EngineCore_DP0 pid=381139)[0;0m 	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
[0;36m(EngineCore_DP0 pid=381139)[0;0m 	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
[0;36m(EngineCore_DP0 pid=381139)[0;0m 	151657: AddedToken("<tool_call>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
[0;36m(EngineCore_DP0 pid=381139)[0;0m 	151658: AddedToken("</tool_call>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
[0;36m(EngineCore_DP0 pid=381139)[0;0m 	151659: AddedToken("<|fim_prefix|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
[0;36m(EngineCore_DP0 pid=381139)[0;0m 	151660: AddedToken("<|fim_middle|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
[0;36m(EngineCore_DP0 pid=381139)[0;0m 	151661: AddedToken("<|fim_suffix|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
[0;36m(EngineCore_DP0 pid=381139)[0;0m 	151662: AddedToken("<|fim_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
[0;36m(EngineCore_DP0 pid=381139)[0;0m 	151663: AddedToken("<|repo_name|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
[0;36m(EngineCore_DP0 pid=381139)[0;0m 	151664: AddedToken("<|file_sep|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
[0;36m(EngineCore_DP0 pid=381139)[0;0m 	151665: AddedToken("<tool_response>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
[0;36m(EngineCore_DP0 pid=381139)[0;0m 	151666: AddedToken("</tool_response>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
[0;36m(EngineCore_DP0 pid=381139)[0;0m 	151667: AddedToken("<think>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
[0;36m(EngineCore_DP0 pid=381139)[0;0m 	151668: AddedToken("</think>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
[0;36m(EngineCore_DP0 pid=381139)[0;0m }
[0;36m(EngineCore_DP0 pid=381139)[0;0m )
[0;36m(EngineCore_DP0 pid=381139)[0;0m - video_processor: Qwen3VLVideoProcessor {
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "crop_size": null,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "data_format": "channels_first",
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "default_to_square": true,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "device": null,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "do_center_crop": null,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "do_convert_rgb": true,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "do_normalize": true,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "do_rescale": true,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "do_resize": true,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "do_sample_frames": true,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "fps": 2,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "image_mean": [
[0;36m(EngineCore_DP0 pid=381139)[0;0m     0.5,
[0;36m(EngineCore_DP0 pid=381139)[0;0m     0.5,
[0;36m(EngineCore_DP0 pid=381139)[0;0m     0.5
[0;36m(EngineCore_DP0 pid=381139)[0;0m   ],
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "image_std": [
[0;36m(EngineCore_DP0 pid=381139)[0;0m     0.5,
[0;36m(EngineCore_DP0 pid=381139)[0;0m     0.5,
[0;36m(EngineCore_DP0 pid=381139)[0;0m     0.5
[0;36m(EngineCore_DP0 pid=381139)[0;0m   ],
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "input_data_format": null,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "max_frames": 768,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "merge_size": 2,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "min_frames": 4,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "num_frames": null,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "pad_size": null,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "patch_size": 16,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "processor_class": "Qwen3VLProcessor",
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "resample": 3,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "rescale_factor": 0.00392156862745098,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "return_metadata": false,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "size": {
[0;36m(EngineCore_DP0 pid=381139)[0;0m     "longest_edge": 25165824,
[0;36m(EngineCore_DP0 pid=381139)[0;0m     "shortest_edge": 4096
[0;36m(EngineCore_DP0 pid=381139)[0;0m   },
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "temporal_patch_size": 2,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "video_metadata": null,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "video_processor_type": "Qwen3VLVideoProcessor"
[0;36m(EngineCore_DP0 pid=381139)[0;0m }
[0;36m(EngineCore_DP0 pid=381139)[0;0m 
[0;36m(EngineCore_DP0 pid=381139)[0;0m 
[0;36m(EngineCore_DP0 pid=381139)[0;0m {
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "processor_class": "Qwen3VLProcessor"
[0;36m(EngineCore_DP0 pid=381139)[0;0m }
[0;36m(EngineCore_DP0 pid=381139)[0;0m 
[0;36m(EngineCore_DP0 pid=381139)[0;0m loading configuration file /root/.cache/huggingface/hub/models--Qwen--Qwen3-VL-32B-Instruct-FP8/snapshots/4bf2c2f39c37c0fede78bede4056e1f18cdf8109/preprocessor_config.json
[0;36m(EngineCore_DP0 pid=381139)[0;0m Image processor Qwen2VLImageProcessorFast {
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "crop_size": null,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "data_format": "channels_first",
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "default_to_square": true,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "device": null,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "disable_grouping": null,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "do_center_crop": null,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "do_convert_rgb": true,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "do_normalize": true,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "do_pad": null,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "do_rescale": true,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "do_resize": true,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "image_mean": [
[0;36m(EngineCore_DP0 pid=381139)[0;0m     0.5,
[0;36m(EngineCore_DP0 pid=381139)[0;0m     0.5,
[0;36m(EngineCore_DP0 pid=381139)[0;0m     0.5
[0;36m(EngineCore_DP0 pid=381139)[0;0m   ],
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "image_processor_type": "Qwen2VLImageProcessorFast",
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "image_std": [
[0;36m(EngineCore_DP0 pid=381139)[0;0m     0.5,
[0;36m(EngineCore_DP0 pid=381139)[0;0m     0.5,
[0;36m(EngineCore_DP0 pid=381139)[0;0m     0.5
[0;36m(EngineCore_DP0 pid=381139)[0;0m   ],
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "input_data_format": null,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "max_pixels": null,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "merge_size": 2,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "min_pixels": null,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "pad_size": null,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "patch_size": 16,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "processor_class": "Qwen3VLProcessor",
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "resample": 3,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "rescale_factor": 0.00392156862745098,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "return_tensors": null,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "size": {
[0;36m(EngineCore_DP0 pid=381139)[0;0m     "longest_edge": 1048576,
[0;36m(EngineCore_DP0 pid=381139)[0;0m     "shortest_edge": 65536
[0;36m(EngineCore_DP0 pid=381139)[0;0m   },
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "temporal_patch_size": 2
[0;36m(EngineCore_DP0 pid=381139)[0;0m }
[0;36m(EngineCore_DP0 pid=381139)[0;0m 
[0;36m(EngineCore_DP0 pid=381139)[0;0m loading file vocab.json
[0;36m(EngineCore_DP0 pid=381139)[0;0m loading file merges.txt
[0;36m(EngineCore_DP0 pid=381139)[0;0m loading file tokenizer.json
[0;36m(EngineCore_DP0 pid=381139)[0;0m loading file added_tokens.json
[0;36m(EngineCore_DP0 pid=381139)[0;0m loading file special_tokens_map.json
[0;36m(EngineCore_DP0 pid=381139)[0;0m loading file tokenizer_config.json
[0;36m(EngineCore_DP0 pid=381139)[0;0m loading file chat_template.jinja
[0;36m(EngineCore_DP0 pid=381139)[0;0m Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[0;36m(EngineCore_DP0 pid=381139)[0;0m loading configuration file /root/.cache/huggingface/hub/models--Qwen--Qwen3-VL-32B-Instruct-FP8/snapshots/4bf2c2f39c37c0fede78bede4056e1f18cdf8109/video_preprocessor_config.json
[0;36m(EngineCore_DP0 pid=381139)[0;0m Video processor Qwen3VLVideoProcessor {
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "crop_size": null,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "data_format": "channels_first",
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "default_to_square": true,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "device": null,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "do_center_crop": null,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "do_convert_rgb": true,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "do_normalize": true,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "do_rescale": true,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "do_resize": true,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "do_sample_frames": true,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "fps": 2,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "image_mean": [
[0;36m(EngineCore_DP0 pid=381139)[0;0m     0.5,
[0;36m(EngineCore_DP0 pid=381139)[0;0m     0.5,
[0;36m(EngineCore_DP0 pid=381139)[0;0m     0.5
[0;36m(EngineCore_DP0 pid=381139)[0;0m   ],
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "image_std": [
[0;36m(EngineCore_DP0 pid=381139)[0;0m     0.5,
[0;36m(EngineCore_DP0 pid=381139)[0;0m     0.5,
[0;36m(EngineCore_DP0 pid=381139)[0;0m     0.5
[0;36m(EngineCore_DP0 pid=381139)[0;0m   ],
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "input_data_format": null,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "max_frames": 768,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "merge_size": 2,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "min_frames": 4,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "num_frames": null,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "pad_size": null,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "patch_size": 16,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "processor_class": "Qwen3VLProcessor",
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "resample": 3,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "rescale_factor": 0.00392156862745098,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "return_metadata": false,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "size": {
[0;36m(EngineCore_DP0 pid=381139)[0;0m     "longest_edge": 1048576,
[0;36m(EngineCore_DP0 pid=381139)[0;0m     "shortest_edge": 65536
[0;36m(EngineCore_DP0 pid=381139)[0;0m   },
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "temporal_patch_size": 2,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "video_metadata": null,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "video_processor_type": "Qwen3VLVideoProcessor"
[0;36m(EngineCore_DP0 pid=381139)[0;0m }
[0;36m(EngineCore_DP0 pid=381139)[0;0m 
[0;36m(EngineCore_DP0 pid=381139)[0;0m loading configuration file None
[0;36m(EngineCore_DP0 pid=381139)[0;0m Processor Qwen3VLProcessor:
[0;36m(EngineCore_DP0 pid=381139)[0;0m - image_processor: Qwen2VLImageProcessorFast {
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "crop_size": null,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "data_format": "channels_first",
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "default_to_square": true,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "device": null,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "disable_grouping": null,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "do_center_crop": null,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "do_convert_rgb": true,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "do_normalize": true,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "do_pad": null,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "do_rescale": true,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "do_resize": true,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "image_mean": [
[0;36m(EngineCore_DP0 pid=381139)[0;0m     0.5,
[0;36m(EngineCore_DP0 pid=381139)[0;0m     0.5,
[0;36m(EngineCore_DP0 pid=381139)[0;0m     0.5
[0;36m(EngineCore_DP0 pid=381139)[0;0m   ],
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "image_processor_type": "Qwen2VLImageProcessorFast",
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "image_std": [
[0;36m(EngineCore_DP0 pid=381139)[0;0m     0.5,
[0;36m(EngineCore_DP0 pid=381139)[0;0m     0.5,
[0;36m(EngineCore_DP0 pid=381139)[0;0m     0.5
[0;36m(EngineCore_DP0 pid=381139)[0;0m   ],
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "input_data_format": null,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "max_pixels": null,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "merge_size": 2,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "min_pixels": null,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "pad_size": null,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "patch_size": 16,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "processor_class": "Qwen3VLProcessor",
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "resample": 3,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "rescale_factor": 0.00392156862745098,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "return_tensors": null,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "size": {
[0;36m(EngineCore_DP0 pid=381139)[0;0m     "longest_edge": 1048576,
[0;36m(EngineCore_DP0 pid=381139)[0;0m     "shortest_edge": 65536
[0;36m(EngineCore_DP0 pid=381139)[0;0m   },
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "temporal_patch_size": 2
[0;36m(EngineCore_DP0 pid=381139)[0;0m }
[0;36m(EngineCore_DP0 pid=381139)[0;0m 
[0;36m(EngineCore_DP0 pid=381139)[0;0m - tokenizer: CachedQwen2TokenizerFast(name_or_path='/root/.cache/huggingface/hub/models--Qwen--Qwen3-VL-32B-Instruct-FP8/snapshots/4bf2c2f39c37c0fede78bede4056e1f18cdf8109/', vocab_size=151643, model_max_length=262144, is_fast=True, padding_side='right', truncation_side='left', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
[0;36m(EngineCore_DP0 pid=381139)[0;0m 	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
[0;36m(EngineCore_DP0 pid=381139)[0;0m 	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
[0;36m(EngineCore_DP0 pid=381139)[0;0m 	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
[0;36m(EngineCore_DP0 pid=381139)[0;0m 	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
[0;36m(EngineCore_DP0 pid=381139)[0;0m 	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
[0;36m(EngineCore_DP0 pid=381139)[0;0m 	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
[0;36m(EngineCore_DP0 pid=381139)[0;0m 	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
[0;36m(EngineCore_DP0 pid=381139)[0;0m 	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
[0;36m(EngineCore_DP0 pid=381139)[0;0m 	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
[0;36m(EngineCore_DP0 pid=381139)[0;0m 	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
[0;36m(EngineCore_DP0 pid=381139)[0;0m 	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
[0;36m(EngineCore_DP0 pid=381139)[0;0m 	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
[0;36m(EngineCore_DP0 pid=381139)[0;0m 	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
[0;36m(EngineCore_DP0 pid=381139)[0;0m 	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
[0;36m(EngineCore_DP0 pid=381139)[0;0m 	151657: AddedToken("<tool_call>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
[0;36m(EngineCore_DP0 pid=381139)[0;0m 	151658: AddedToken("</tool_call>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
[0;36m(EngineCore_DP0 pid=381139)[0;0m 	151659: AddedToken("<|fim_prefix|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
[0;36m(EngineCore_DP0 pid=381139)[0;0m 	151660: AddedToken("<|fim_middle|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
[0;36m(EngineCore_DP0 pid=381139)[0;0m 	151661: AddedToken("<|fim_suffix|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
[0;36m(EngineCore_DP0 pid=381139)[0;0m 	151662: AddedToken("<|fim_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
[0;36m(EngineCore_DP0 pid=381139)[0;0m 	151663: AddedToken("<|repo_name|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
[0;36m(EngineCore_DP0 pid=381139)[0;0m 	151664: AddedToken("<|file_sep|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
[0;36m(EngineCore_DP0 pid=381139)[0;0m 	151665: AddedToken("<tool_response>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
[0;36m(EngineCore_DP0 pid=381139)[0;0m 	151666: AddedToken("</tool_response>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
[0;36m(EngineCore_DP0 pid=381139)[0;0m 	151667: AddedToken("<think>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
[0;36m(EngineCore_DP0 pid=381139)[0;0m 	151668: AddedToken("</think>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
[0;36m(EngineCore_DP0 pid=381139)[0;0m }
[0;36m(EngineCore_DP0 pid=381139)[0;0m )
[0;36m(EngineCore_DP0 pid=381139)[0;0m - video_processor: Qwen3VLVideoProcessor {
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "crop_size": null,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "data_format": "channels_first",
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "default_to_square": true,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "device": null,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "do_center_crop": null,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "do_convert_rgb": true,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "do_normalize": true,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "do_rescale": true,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "do_resize": true,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "do_sample_frames": true,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "fps": 2,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "image_mean": [
[0;36m(EngineCore_DP0 pid=381139)[0;0m     0.5,
[0;36m(EngineCore_DP0 pid=381139)[0;0m     0.5,
[0;36m(EngineCore_DP0 pid=381139)[0;0m     0.5
[0;36m(EngineCore_DP0 pid=381139)[0;0m   ],
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "image_std": [
[0;36m(EngineCore_DP0 pid=381139)[0;0m     0.5,
[0;36m(EngineCore_DP0 pid=381139)[0;0m     0.5,
[0;36m(EngineCore_DP0 pid=381139)[0;0m     0.5
[0;36m(EngineCore_DP0 pid=381139)[0;0m   ],
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "input_data_format": null,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "max_frames": 768,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "merge_size": 2,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "min_frames": 4,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "num_frames": null,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "pad_size": null,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "patch_size": 16,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "processor_class": "Qwen3VLProcessor",
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "resample": 3,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "rescale_factor": 0.00392156862745098,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "return_metadata": false,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "size": {
[0;36m(EngineCore_DP0 pid=381139)[0;0m     "longest_edge": 1048576,
[0;36m(EngineCore_DP0 pid=381139)[0;0m     "shortest_edge": 65536
[0;36m(EngineCore_DP0 pid=381139)[0;0m   },
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "temporal_patch_size": 2,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "video_metadata": null,
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "video_processor_type": "Qwen3VLVideoProcessor"
[0;36m(EngineCore_DP0 pid=381139)[0;0m }
[0;36m(EngineCore_DP0 pid=381139)[0;0m 
[0;36m(EngineCore_DP0 pid=381139)[0;0m 
[0;36m(EngineCore_DP0 pid=381139)[0;0m {
[0;36m(EngineCore_DP0 pid=381139)[0;0m   "processor_class": "Qwen3VLProcessor"
[0;36m(EngineCore_DP0 pid=381139)[0;0m }
[0;36m(EngineCore_DP0 pid=381139)[0;0m 
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:07:28 [v1/engine/core.py:186] Batch queue is enabled with size 2
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:07:28 [utils/gc_utils.py:40] GC Debug Config. enabled:False,top_objects:-1
[0;36m(APIServer pid=380742)[0;0m DEBUG 01-27 22:07:28 [v1/engine/utils.py:1081] READY from local core engine process 0.
[0;36m(EngineCore_DP0 pid=381139)[0;0m INFO 01-27 22:07:28 [config/vllm.py:630] Asynchronous scheduling is enabled.
[0;36m(EngineCore_DP0 pid=381139)[0;0m WARNING 01-27 22:07:28 [config/vllm.py:672] Inductor compilation was disabled by user settings, optimizations settings that are only active during inductor compilation will be ignored.
[0;36m(EngineCore_DP0 pid=381139)[0;0m =========compilation_config.custom_ops=['all']===========
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:07:28 [v1/engine/core.py:972] EngineCore waiting for work.
[0;36m(APIServer pid=380742)[0;0m DEBUG 01-27 22:07:29 [v1/metrics/loggers.py:271] Engine 000: vllm cache_config_info with initialization after num_gpu_blocks is: 1189
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:07:29 [v1/engine/core.py:972] EngineCore waiting for work.
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:07:29 [v1/engine/core.py:972] EngineCore waiting for work.
[0;36m(APIServer pid=380742)[0;0m INFO 01-27 22:07:29 [entrypoints/openai/api_server.py:1014] Supported tasks: ['generate']
[0;36m(APIServer pid=380742)[0;0m loading configuration file /root/.cache/huggingface/hub/models--Qwen--Qwen3-VL-32B-Instruct-FP8/snapshots/4bf2c2f39c37c0fede78bede4056e1f18cdf8109/generation_config.json
[0;36m(APIServer pid=380742)[0;0m Generate config GenerationConfig {
[0;36m(APIServer pid=380742)[0;0m   "bos_token_id": 151643,
[0;36m(APIServer pid=380742)[0;0m   "do_sample": true,
[0;36m(APIServer pid=380742)[0;0m   "eos_token_id": [
[0;36m(APIServer pid=380742)[0;0m     151645,
[0;36m(APIServer pid=380742)[0;0m     151643
[0;36m(APIServer pid=380742)[0;0m   ],
[0;36m(APIServer pid=380742)[0;0m   "pad_token_id": 151643,
[0;36m(APIServer pid=380742)[0;0m   "temperature": 0.7,
[0;36m(APIServer pid=380742)[0;0m   "top_k": 20,
[0;36m(APIServer pid=380742)[0;0m   "top_p": 0.8
[0;36m(APIServer pid=380742)[0;0m }
[0;36m(APIServer pid=380742)[0;0m 
[0;36m(APIServer pid=380742)[0;0m WARNING 01-27 22:07:29 [config/model.py:1358] Default sampling parameters have been overridden by the model's Hugging Face generation config recommended from the model creator. If this is not intended, please relaunch vLLM instance with `--generation-config vllm`.
[0;36m(APIServer pid=380742)[0;0m INFO 01-27 22:07:29 [entrypoints/openai/serving_responses.py:224] Using default chat sampling params from model: {'temperature': 0.7, 'top_k': 20, 'top_p': 0.8}
[0;36m(APIServer pid=380742)[0;0m loading configuration file /root/.cache/huggingface/hub/models--Qwen--Qwen3-VL-32B-Instruct-FP8/snapshots/4bf2c2f39c37c0fede78bede4056e1f18cdf8109/generation_config.json
[0;36m(APIServer pid=380742)[0;0m Generate config GenerationConfig {
[0;36m(APIServer pid=380742)[0;0m   "bos_token_id": 151643,
[0;36m(APIServer pid=380742)[0;0m   "do_sample": true,
[0;36m(APIServer pid=380742)[0;0m   "eos_token_id": [
[0;36m(APIServer pid=380742)[0;0m     151645,
[0;36m(APIServer pid=380742)[0;0m     151643
[0;36m(APIServer pid=380742)[0;0m   ],
[0;36m(APIServer pid=380742)[0;0m   "pad_token_id": 151643,
[0;36m(APIServer pid=380742)[0;0m   "temperature": 0.7,
[0;36m(APIServer pid=380742)[0;0m   "top_k": 20,
[0;36m(APIServer pid=380742)[0;0m   "top_p": 0.8
[0;36m(APIServer pid=380742)[0;0m }
[0;36m(APIServer pid=380742)[0;0m 
[0;36m(APIServer pid=380742)[0;0m INFO 01-27 22:07:29 [entrypoints/openai/serving_chat.py:146] Using default chat sampling params from model: {'temperature': 0.7, 'top_k': 20, 'top_p': 0.8}
[0;36m(APIServer pid=380742)[0;0m INFO 01-27 22:07:29 [entrypoints/openai/serving_chat.py:182] Warming up chat template processing...
[0;36m(APIServer pid=380742)[0;0m loading configuration file /root/.cache/huggingface/hub/models--Qwen--Qwen3-VL-32B-Instruct-FP8/snapshots/4bf2c2f39c37c0fede78bede4056e1f18cdf8109/preprocessor_config.json
[0;36m(APIServer pid=380742)[0;0m loading configuration file /root/.cache/huggingface/hub/models--Qwen--Qwen3-VL-32B-Instruct-FP8/snapshots/4bf2c2f39c37c0fede78bede4056e1f18cdf8109/preprocessor_config.json
[0;36m(APIServer pid=380742)[0;0m Image processor Qwen2VLImageProcessorFast {
[0;36m(APIServer pid=380742)[0;0m   "crop_size": null,
[0;36m(APIServer pid=380742)[0;0m   "data_format": "channels_first",
[0;36m(APIServer pid=380742)[0;0m   "default_to_square": true,
[0;36m(APIServer pid=380742)[0;0m   "device": null,
[0;36m(APIServer pid=380742)[0;0m   "disable_grouping": null,
[0;36m(APIServer pid=380742)[0;0m   "do_center_crop": null,
[0;36m(APIServer pid=380742)[0;0m   "do_convert_rgb": true,
[0;36m(APIServer pid=380742)[0;0m   "do_normalize": true,
[0;36m(APIServer pid=380742)[0;0m   "do_pad": null,
[0;36m(APIServer pid=380742)[0;0m   "do_rescale": true,
[0;36m(APIServer pid=380742)[0;0m   "do_resize": true,
[0;36m(APIServer pid=380742)[0;0m   "image_mean": [
[0;36m(APIServer pid=380742)[0;0m     0.5,
[0;36m(APIServer pid=380742)[0;0m     0.5,
[0;36m(APIServer pid=380742)[0;0m     0.5
[0;36m(APIServer pid=380742)[0;0m   ],
[0;36m(APIServer pid=380742)[0;0m   "image_processor_type": "Qwen2VLImageProcessorFast",
[0;36m(APIServer pid=380742)[0;0m   "image_std": [
[0;36m(APIServer pid=380742)[0;0m     0.5,
[0;36m(APIServer pid=380742)[0;0m     0.5,
[0;36m(APIServer pid=380742)[0;0m     0.5
[0;36m(APIServer pid=380742)[0;0m   ],
[0;36m(APIServer pid=380742)[0;0m   "input_data_format": null,
[0;36m(APIServer pid=380742)[0;0m   "max_pixels": null,
[0;36m(APIServer pid=380742)[0;0m   "merge_size": 2,
[0;36m(APIServer pid=380742)[0;0m   "min_pixels": null,
[0;36m(APIServer pid=380742)[0;0m   "pad_size": null,
[0;36m(APIServer pid=380742)[0;0m   "patch_size": 16,
[0;36m(APIServer pid=380742)[0;0m   "processor_class": "Qwen3VLProcessor",
[0;36m(APIServer pid=380742)[0;0m   "resample": 3,
[0;36m(APIServer pid=380742)[0;0m   "rescale_factor": 0.00392156862745098,
[0;36m(APIServer pid=380742)[0;0m   "return_tensors": null,
[0;36m(APIServer pid=380742)[0;0m   "size": {
[0;36m(APIServer pid=380742)[0;0m     "longest_edge": 16777216,
[0;36m(APIServer pid=380742)[0;0m     "shortest_edge": 65536
[0;36m(APIServer pid=380742)[0;0m   },
[0;36m(APIServer pid=380742)[0;0m   "temporal_patch_size": 2
[0;36m(APIServer pid=380742)[0;0m }
[0;36m(APIServer pid=380742)[0;0m 
[0;36m(APIServer pid=380742)[0;0m loading file vocab.json
[0;36m(APIServer pid=380742)[0;0m loading file merges.txt
[0;36m(APIServer pid=380742)[0;0m loading file tokenizer.json
[0;36m(APIServer pid=380742)[0;0m loading file added_tokens.json
[0;36m(APIServer pid=380742)[0;0m loading file special_tokens_map.json
[0;36m(APIServer pid=380742)[0;0m loading file tokenizer_config.json
[0;36m(APIServer pid=380742)[0;0m loading file chat_template.jinja
[0;36m(APIServer pid=380742)[0;0m Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[0;36m(APIServer pid=380742)[0;0m loading configuration file /root/.cache/huggingface/hub/models--Qwen--Qwen3-VL-32B-Instruct-FP8/snapshots/4bf2c2f39c37c0fede78bede4056e1f18cdf8109/video_preprocessor_config.json
[0;36m(APIServer pid=380742)[0;0m Video processor Qwen3VLVideoProcessor {
[0;36m(APIServer pid=380742)[0;0m   "crop_size": null,
[0;36m(APIServer pid=380742)[0;0m   "data_format": "channels_first",
[0;36m(APIServer pid=380742)[0;0m   "default_to_square": true,
[0;36m(APIServer pid=380742)[0;0m   "device": null,
[0;36m(APIServer pid=380742)[0;0m   "do_center_crop": null,
[0;36m(APIServer pid=380742)[0;0m   "do_convert_rgb": true,
[0;36m(APIServer pid=380742)[0;0m   "do_normalize": true,
[0;36m(APIServer pid=380742)[0;0m   "do_rescale": true,
[0;36m(APIServer pid=380742)[0;0m   "do_resize": true,
[0;36m(APIServer pid=380742)[0;0m   "do_sample_frames": true,
[0;36m(APIServer pid=380742)[0;0m   "fps": 2,
[0;36m(APIServer pid=380742)[0;0m   "image_mean": [
[0;36m(APIServer pid=380742)[0;0m     0.5,
[0;36m(APIServer pid=380742)[0;0m     0.5,
[0;36m(APIServer pid=380742)[0;0m     0.5
[0;36m(APIServer pid=380742)[0;0m   ],
[0;36m(APIServer pid=380742)[0;0m   "image_std": [
[0;36m(APIServer pid=380742)[0;0m     0.5,
[0;36m(APIServer pid=380742)[0;0m     0.5,
[0;36m(APIServer pid=380742)[0;0m     0.5
[0;36m(APIServer pid=380742)[0;0m   ],
[0;36m(APIServer pid=380742)[0;0m   "input_data_format": null,
[0;36m(APIServer pid=380742)[0;0m   "max_frames": 768,
[0;36m(APIServer pid=380742)[0;0m   "merge_size": 2,
[0;36m(APIServer pid=380742)[0;0m   "min_frames": 4,
[0;36m(APIServer pid=380742)[0;0m   "num_frames": null,
[0;36m(APIServer pid=380742)[0;0m   "pad_size": null,
[0;36m(APIServer pid=380742)[0;0m   "patch_size": 16,
[0;36m(APIServer pid=380742)[0;0m   "processor_class": "Qwen3VLProcessor",
[0;36m(APIServer pid=380742)[0;0m   "resample": 3,
[0;36m(APIServer pid=380742)[0;0m   "rescale_factor": 0.00392156862745098,
[0;36m(APIServer pid=380742)[0;0m   "return_metadata": false,
[0;36m(APIServer pid=380742)[0;0m   "size": {
[0;36m(APIServer pid=380742)[0;0m     "longest_edge": 25165824,
[0;36m(APIServer pid=380742)[0;0m     "shortest_edge": 4096
[0;36m(APIServer pid=380742)[0;0m   },
[0;36m(APIServer pid=380742)[0;0m   "temporal_patch_size": 2,
[0;36m(APIServer pid=380742)[0;0m   "video_metadata": null,
[0;36m(APIServer pid=380742)[0;0m   "video_processor_type": "Qwen3VLVideoProcessor"
[0;36m(APIServer pid=380742)[0;0m }
[0;36m(APIServer pid=380742)[0;0m 
[0;36m(APIServer pid=380742)[0;0m loading configuration file None
[0;36m(APIServer pid=380742)[0;0m Processor Qwen3VLProcessor:
[0;36m(APIServer pid=380742)[0;0m - image_processor: Qwen2VLImageProcessorFast {
[0;36m(APIServer pid=380742)[0;0m   "crop_size": null,
[0;36m(APIServer pid=380742)[0;0m   "data_format": "channels_first",
[0;36m(APIServer pid=380742)[0;0m   "default_to_square": true,
[0;36m(APIServer pid=380742)[0;0m   "device": null,
[0;36m(APIServer pid=380742)[0;0m   "disable_grouping": null,
[0;36m(APIServer pid=380742)[0;0m   "do_center_crop": null,
[0;36m(APIServer pid=380742)[0;0m   "do_convert_rgb": true,
[0;36m(APIServer pid=380742)[0;0m   "do_normalize": true,
[0;36m(APIServer pid=380742)[0;0m   "do_pad": null,
[0;36m(APIServer pid=380742)[0;0m   "do_rescale": true,
[0;36m(APIServer pid=380742)[0;0m   "do_resize": true,
[0;36m(APIServer pid=380742)[0;0m   "image_mean": [
[0;36m(APIServer pid=380742)[0;0m     0.5,
[0;36m(APIServer pid=380742)[0;0m     0.5,
[0;36m(APIServer pid=380742)[0;0m     0.5
[0;36m(APIServer pid=380742)[0;0m   ],
[0;36m(APIServer pid=380742)[0;0m   "image_processor_type": "Qwen2VLImageProcessorFast",
[0;36m(APIServer pid=380742)[0;0m   "image_std": [
[0;36m(APIServer pid=380742)[0;0m     0.5,
[0;36m(APIServer pid=380742)[0;0m     0.5,
[0;36m(APIServer pid=380742)[0;0m     0.5
[0;36m(APIServer pid=380742)[0;0m   ],
[0;36m(APIServer pid=380742)[0;0m   "input_data_format": null,
[0;36m(APIServer pid=380742)[0;0m   "max_pixels": null,
[0;36m(APIServer pid=380742)[0;0m   "merge_size": 2,
[0;36m(APIServer pid=380742)[0;0m   "min_pixels": null,
[0;36m(APIServer pid=380742)[0;0m   "pad_size": null,
[0;36m(APIServer pid=380742)[0;0m   "patch_size": 16,
[0;36m(APIServer pid=380742)[0;0m   "processor_class": "Qwen3VLProcessor",
[0;36m(APIServer pid=380742)[0;0m   "resample": 3,
[0;36m(APIServer pid=380742)[0;0m   "rescale_factor": 0.00392156862745098,
[0;36m(APIServer pid=380742)[0;0m   "return_tensors": null,
[0;36m(APIServer pid=380742)[0;0m   "size": {
[0;36m(APIServer pid=380742)[0;0m     "longest_edge": 16777216,
[0;36m(APIServer pid=380742)[0;0m     "shortest_edge": 65536
[0;36m(APIServer pid=380742)[0;0m   },
[0;36m(APIServer pid=380742)[0;0m   "temporal_patch_size": 2
[0;36m(APIServer pid=380742)[0;0m }
[0;36m(APIServer pid=380742)[0;0m 
[0;36m(APIServer pid=380742)[0;0m - tokenizer: Qwen2TokenizerFast(name_or_path='/root/.cache/huggingface/hub/models--Qwen--Qwen3-VL-32B-Instruct-FP8/snapshots/4bf2c2f39c37c0fede78bede4056e1f18cdf8109/', vocab_size=151643, model_max_length=262144, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
[0;36m(APIServer pid=380742)[0;0m 	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
[0;36m(APIServer pid=380742)[0;0m 	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
[0;36m(APIServer pid=380742)[0;0m 	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
[0;36m(APIServer pid=380742)[0;0m 	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
[0;36m(APIServer pid=380742)[0;0m 	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
[0;36m(APIServer pid=380742)[0;0m 	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
[0;36m(APIServer pid=380742)[0;0m 	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
[0;36m(APIServer pid=380742)[0;0m 	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
[0;36m(APIServer pid=380742)[0;0m 	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
[0;36m(APIServer pid=380742)[0;0m 	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
[0;36m(APIServer pid=380742)[0;0m 	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
[0;36m(APIServer pid=380742)[0;0m 	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
[0;36m(APIServer pid=380742)[0;0m 	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
[0;36m(APIServer pid=380742)[0;0m 	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
[0;36m(APIServer pid=380742)[0;0m 	151657: AddedToken("<tool_call>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
[0;36m(APIServer pid=380742)[0;0m 	151658: AddedToken("</tool_call>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
[0;36m(APIServer pid=380742)[0;0m 	151659: AddedToken("<|fim_prefix|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
[0;36m(APIServer pid=380742)[0;0m 	151660: AddedToken("<|fim_middle|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
[0;36m(APIServer pid=380742)[0;0m 	151661: AddedToken("<|fim_suffix|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
[0;36m(APIServer pid=380742)[0;0m 	151662: AddedToken("<|fim_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
[0;36m(APIServer pid=380742)[0;0m 	151663: AddedToken("<|repo_name|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
[0;36m(APIServer pid=380742)[0;0m 	151664: AddedToken("<|file_sep|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
[0;36m(APIServer pid=380742)[0;0m 	151665: AddedToken("<tool_response>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
[0;36m(APIServer pid=380742)[0;0m 	151666: AddedToken("</tool_response>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
[0;36m(APIServer pid=380742)[0;0m 	151667: AddedToken("<think>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
[0;36m(APIServer pid=380742)[0;0m 	151668: AddedToken("</think>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
[0;36m(APIServer pid=380742)[0;0m }
[0;36m(APIServer pid=380742)[0;0m )
[0;36m(APIServer pid=380742)[0;0m - video_processor: Qwen3VLVideoProcessor {
[0;36m(APIServer pid=380742)[0;0m   "crop_size": null,
[0;36m(APIServer pid=380742)[0;0m   "data_format": "channels_first",
[0;36m(APIServer pid=380742)[0;0m   "default_to_square": true,
[0;36m(APIServer pid=380742)[0;0m   "device": null,
[0;36m(APIServer pid=380742)[0;0m   "do_center_crop": null,
[0;36m(APIServer pid=380742)[0;0m   "do_convert_rgb": true,
[0;36m(APIServer pid=380742)[0;0m   "do_normalize": true,
[0;36m(APIServer pid=380742)[0;0m   "do_rescale": true,
[0;36m(APIServer pid=380742)[0;0m   "do_resize": true,
[0;36m(APIServer pid=380742)[0;0m   "do_sample_frames": true,
[0;36m(APIServer pid=380742)[0;0m   "fps": 2,
[0;36m(APIServer pid=380742)[0;0m   "image_mean": [
[0;36m(APIServer pid=380742)[0;0m     0.5,
[0;36m(APIServer pid=380742)[0;0m     0.5,
[0;36m(APIServer pid=380742)[0;0m     0.5
[0;36m(APIServer pid=380742)[0;0m   ],
[0;36m(APIServer pid=380742)[0;0m   "image_std": [
[0;36m(APIServer pid=380742)[0;0m     0.5,
[0;36m(APIServer pid=380742)[0;0m     0.5,
[0;36m(APIServer pid=380742)[0;0m     0.5
[0;36m(APIServer pid=380742)[0;0m   ],
[0;36m(APIServer pid=380742)[0;0m   "input_data_format": null,
[0;36m(APIServer pid=380742)[0;0m   "max_frames": 768,
[0;36m(APIServer pid=380742)[0;0m   "merge_size": 2,
[0;36m(APIServer pid=380742)[0;0m   "min_frames": 4,
[0;36m(APIServer pid=380742)[0;0m   "num_frames": null,
[0;36m(APIServer pid=380742)[0;0m   "pad_size": null,
[0;36m(APIServer pid=380742)[0;0m   "patch_size": 16,
[0;36m(APIServer pid=380742)[0;0m   "processor_class": "Qwen3VLProcessor",
[0;36m(APIServer pid=380742)[0;0m   "resample": 3,
[0;36m(APIServer pid=380742)[0;0m   "rescale_factor": 0.00392156862745098,
[0;36m(APIServer pid=380742)[0;0m   "return_metadata": false,
[0;36m(APIServer pid=380742)[0;0m   "size": {
[0;36m(APIServer pid=380742)[0;0m     "longest_edge": 25165824,
[0;36m(APIServer pid=380742)[0;0m     "shortest_edge": 4096
[0;36m(APIServer pid=380742)[0;0m   },
[0;36m(APIServer pid=380742)[0;0m   "temporal_patch_size": 2,
[0;36m(APIServer pid=380742)[0;0m   "video_metadata": null,
[0;36m(APIServer pid=380742)[0;0m   "video_processor_type": "Qwen3VLVideoProcessor"
[0;36m(APIServer pid=380742)[0;0m }
[0;36m(APIServer pid=380742)[0;0m 
[0;36m(APIServer pid=380742)[0;0m 
[0;36m(APIServer pid=380742)[0;0m {
[0;36m(APIServer pid=380742)[0;0m   "processor_class": "Qwen3VLProcessor"
[0;36m(APIServer pid=380742)[0;0m }
[0;36m(APIServer pid=380742)[0;0m 
[0;36m(APIServer pid=380742)[0;0m INFO 01-27 22:07:29 [entrypoints/chat_utils.py:599] Detected the chat template content format to be 'openai'. You can set `--chat-template-content-format` to override this.
[0;36m(APIServer pid=380742)[0;0m INFO 01-27 22:07:29 [entrypoints/openai/serving_chat.py:218] Chat template warmup completed in 441.5ms
[0;36m(APIServer pid=380742)[0;0m loading configuration file /root/.cache/huggingface/hub/models--Qwen--Qwen3-VL-32B-Instruct-FP8/snapshots/4bf2c2f39c37c0fede78bede4056e1f18cdf8109/generation_config.json
[0;36m(APIServer pid=380742)[0;0m Generate config GenerationConfig {
[0;36m(APIServer pid=380742)[0;0m   "bos_token_id": 151643,
[0;36m(APIServer pid=380742)[0;0m   "do_sample": true,
[0;36m(APIServer pid=380742)[0;0m   "eos_token_id": [
[0;36m(APIServer pid=380742)[0;0m     151645,
[0;36m(APIServer pid=380742)[0;0m     151643
[0;36m(APIServer pid=380742)[0;0m   ],
[0;36m(APIServer pid=380742)[0;0m   "pad_token_id": 151643,
[0;36m(APIServer pid=380742)[0;0m   "temperature": 0.7,
[0;36m(APIServer pid=380742)[0;0m   "top_k": 20,
[0;36m(APIServer pid=380742)[0;0m   "top_p": 0.8
[0;36m(APIServer pid=380742)[0;0m }
[0;36m(APIServer pid=380742)[0;0m 
[0;36m(APIServer pid=380742)[0;0m INFO 01-27 22:07:29 [entrypoints/openai/serving_completion.py:78] Using default completion sampling params from model: {'temperature': 0.7, 'top_k': 20, 'top_p': 0.8}
[0;36m(APIServer pid=380742)[0;0m loading configuration file /root/.cache/huggingface/hub/models--Qwen--Qwen3-VL-32B-Instruct-FP8/snapshots/4bf2c2f39c37c0fede78bede4056e1f18cdf8109/generation_config.json
[0;36m(APIServer pid=380742)[0;0m Generate config GenerationConfig {
[0;36m(APIServer pid=380742)[0;0m   "bos_token_id": 151643,
[0;36m(APIServer pid=380742)[0;0m   "do_sample": true,
[0;36m(APIServer pid=380742)[0;0m   "eos_token_id": [
[0;36m(APIServer pid=380742)[0;0m     151645,
[0;36m(APIServer pid=380742)[0;0m     151643
[0;36m(APIServer pid=380742)[0;0m   ],
[0;36m(APIServer pid=380742)[0;0m   "pad_token_id": 151643,
[0;36m(APIServer pid=380742)[0;0m   "temperature": 0.7,
[0;36m(APIServer pid=380742)[0;0m   "top_k": 20,
[0;36m(APIServer pid=380742)[0;0m   "top_p": 0.8
[0;36m(APIServer pid=380742)[0;0m }
[0;36m(APIServer pid=380742)[0;0m 
[0;36m(APIServer pid=380742)[0;0m INFO 01-27 22:07:29 [entrypoints/openai/serving_chat.py:146] Using default chat sampling params from model: {'temperature': 0.7, 'top_k': 20, 'top_p': 0.8}
[0;36m(APIServer pid=380742)[0;0m INFO 01-27 22:07:29 [entrypoints/openai/api_server.py:1346] Starting vLLM API server 0 on http://localhost:12346
[0;36m(APIServer pid=380742)[0;0m INFO 01-27 22:07:29 [entrypoints/launcher.py:38] Available routes are:
[0;36m(APIServer pid=380742)[0;0m INFO 01-27 22:07:29 [entrypoints/launcher.py:46] Route: /openapi.json, Methods: GET, HEAD
[0;36m(APIServer pid=380742)[0;0m INFO 01-27 22:07:29 [entrypoints/launcher.py:46] Route: /docs, Methods: GET, HEAD
[0;36m(APIServer pid=380742)[0;0m INFO 01-27 22:07:29 [entrypoints/launcher.py:46] Route: /docs/oauth2-redirect, Methods: GET, HEAD
[0;36m(APIServer pid=380742)[0;0m INFO 01-27 22:07:29 [entrypoints/launcher.py:46] Route: /redoc, Methods: GET, HEAD
[0;36m(APIServer pid=380742)[0;0m INFO 01-27 22:07:29 [entrypoints/launcher.py:46] Route: /scale_elastic_ep, Methods: POST
[0;36m(APIServer pid=380742)[0;0m INFO 01-27 22:07:29 [entrypoints/launcher.py:46] Route: /is_scaling_elastic_ep, Methods: POST
[0;36m(APIServer pid=380742)[0;0m INFO 01-27 22:07:29 [entrypoints/launcher.py:46] Route: /tokenize, Methods: POST
[0;36m(APIServer pid=380742)[0;0m INFO 01-27 22:07:29 [entrypoints/launcher.py:46] Route: /detokenize, Methods: POST
[0;36m(APIServer pid=380742)[0;0m INFO 01-27 22:07:29 [entrypoints/launcher.py:46] Route: /inference/v1/generate, Methods: POST
[0;36m(APIServer pid=380742)[0;0m INFO 01-27 22:07:29 [entrypoints/launcher.py:46] Route: /pause, Methods: POST
[0;36m(APIServer pid=380742)[0;0m INFO 01-27 22:07:29 [entrypoints/launcher.py:46] Route: /resume, Methods: POST
[0;36m(APIServer pid=380742)[0;0m INFO 01-27 22:07:29 [entrypoints/launcher.py:46] Route: /is_paused, Methods: GET
[0;36m(APIServer pid=380742)[0;0m INFO 01-27 22:07:29 [entrypoints/launcher.py:46] Route: /metrics, Methods: GET
[0;36m(APIServer pid=380742)[0;0m INFO 01-27 22:07:29 [entrypoints/launcher.py:46] Route: /health, Methods: GET
[0;36m(APIServer pid=380742)[0;0m INFO 01-27 22:07:29 [entrypoints/launcher.py:46] Route: /load, Methods: GET
[0;36m(APIServer pid=380742)[0;0m INFO 01-27 22:07:29 [entrypoints/launcher.py:46] Route: /v1/models, Methods: GET
[0;36m(APIServer pid=380742)[0;0m INFO 01-27 22:07:29 [entrypoints/launcher.py:46] Route: /version, Methods: GET
[0;36m(APIServer pid=380742)[0;0m INFO 01-27 22:07:29 [entrypoints/launcher.py:46] Route: /v1/responses, Methods: POST
[0;36m(APIServer pid=380742)[0;0m INFO 01-27 22:07:29 [entrypoints/launcher.py:46] Route: /v1/responses/{response_id}, Methods: GET
[0;36m(APIServer pid=380742)[0;0m INFO 01-27 22:07:29 [entrypoints/launcher.py:46] Route: /v1/responses/{response_id}/cancel, Methods: POST
[0;36m(APIServer pid=380742)[0;0m INFO 01-27 22:07:29 [entrypoints/launcher.py:46] Route: /v1/messages, Methods: POST
[0;36m(APIServer pid=380742)[0;0m INFO 01-27 22:07:29 [entrypoints/launcher.py:46] Route: /v1/chat/completions, Methods: POST
[0;36m(APIServer pid=380742)[0;0m INFO 01-27 22:07:29 [entrypoints/launcher.py:46] Route: /v1/completions, Methods: POST
[0;36m(APIServer pid=380742)[0;0m INFO 01-27 22:07:29 [entrypoints/launcher.py:46] Route: /v1/audio/transcriptions, Methods: POST
[0;36m(APIServer pid=380742)[0;0m INFO 01-27 22:07:29 [entrypoints/launcher.py:46] Route: /v1/audio/translations, Methods: POST
[0;36m(APIServer pid=380742)[0;0m INFO 01-27 22:07:29 [entrypoints/launcher.py:46] Route: /ping, Methods: GET
[0;36m(APIServer pid=380742)[0;0m INFO 01-27 22:07:29 [entrypoints/launcher.py:46] Route: /ping, Methods: POST
[0;36m(APIServer pid=380742)[0;0m INFO 01-27 22:07:29 [entrypoints/launcher.py:46] Route: /invocations, Methods: POST
[0;36m(APIServer pid=380742)[0;0m INFO 01-27 22:07:29 [entrypoints/launcher.py:46] Route: /classify, Methods: POST
[0;36m(APIServer pid=380742)[0;0m INFO 01-27 22:07:29 [entrypoints/launcher.py:46] Route: /v1/embeddings, Methods: POST
[0;36m(APIServer pid=380742)[0;0m INFO 01-27 22:07:29 [entrypoints/launcher.py:46] Route: /score, Methods: POST
[0;36m(APIServer pid=380742)[0;0m INFO 01-27 22:07:29 [entrypoints/launcher.py:46] Route: /v1/score, Methods: POST
[0;36m(APIServer pid=380742)[0;0m INFO 01-27 22:07:29 [entrypoints/launcher.py:46] Route: /rerank, Methods: POST
[0;36m(APIServer pid=380742)[0;0m INFO 01-27 22:07:29 [entrypoints/launcher.py:46] Route: /v1/rerank, Methods: POST
[0;36m(APIServer pid=380742)[0;0m INFO 01-27 22:07:29 [entrypoints/launcher.py:46] Route: /v2/rerank, Methods: POST
[0;36m(APIServer pid=380742)[0;0m INFO 01-27 22:07:29 [entrypoints/launcher.py:46] Route: /pooling, Methods: POST
[0;36m(APIServer pid=380742)[0;0m INFO:     Started server process [380742]
[0;36m(APIServer pid=380742)[0;0m INFO:     Waiting for application startup.
[0;36m(APIServer pid=380742)[0;0m INFO:     Application startup complete.
[0;36m(APIServer pid=380742)[0;0m DEBUG 01-27 22:07:39 [v1/metrics/loggers.py:257] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=380742)[0;0m INFO:     127.0.0.1:40100 - "GET /metrics HTTP/1.1" 200 OK
[0;36m(APIServer pid=380742)[0;0m DEBUG 01-27 22:07:49 [v1/sample/logits_processor/__init__.py:63] No logitsprocs plugins installed (group vllm.logits_processors).
[0;36m(APIServer pid=380742)[0;0m DEBUG 01-27 22:07:49 [v1/engine/input_processor.py:504] OMP_NUM_THREADS is not set; defaulting Torch threads to 1 for input preprocessing.
[0;36m(APIServer pid=380742)[0;0m loading configuration file /root/.cache/huggingface/hub/models--Qwen--Qwen3-VL-32B-Instruct-FP8/snapshots/4bf2c2f39c37c0fede78bede4056e1f18cdf8109/preprocessor_config.json
[0;36m(APIServer pid=380742)[0;0m Image processor Qwen2VLImageProcessorFast {
[0;36m(APIServer pid=380742)[0;0m   "crop_size": null,
[0;36m(APIServer pid=380742)[0;0m   "data_format": "channels_first",
[0;36m(APIServer pid=380742)[0;0m   "default_to_square": true,
[0;36m(APIServer pid=380742)[0;0m   "device": null,
[0;36m(APIServer pid=380742)[0;0m   "disable_grouping": null,
[0;36m(APIServer pid=380742)[0;0m   "do_center_crop": null,
[0;36m(APIServer pid=380742)[0;0m   "do_convert_rgb": true,
[0;36m(APIServer pid=380742)[0;0m   "do_normalize": true,
[0;36m(APIServer pid=380742)[0;0m   "do_pad": null,
[0;36m(APIServer pid=380742)[0;0m   "do_rescale": true,
[0;36m(APIServer pid=380742)[0;0m   "do_resize": true,
[0;36m(APIServer pid=380742)[0;0m   "image_mean": [
[0;36m(APIServer pid=380742)[0;0m     0.5,
[0;36m(APIServer pid=380742)[0;0m     0.5,
[0;36m(APIServer pid=380742)[0;0m     0.5
[0;36m(APIServer pid=380742)[0;0m   ],
[0;36m(APIServer pid=380742)[0;0m   "image_processor_type": "Qwen2VLImageProcessorFast",
[0;36m(APIServer pid=380742)[0;0m   "image_std": [
[0;36m(APIServer pid=380742)[0;0m     0.5,
[0;36m(APIServer pid=380742)[0;0m     0.5,
[0;36m(APIServer pid=380742)[0;0m     0.5
[0;36m(APIServer pid=380742)[0;0m   ],
[0;36m(APIServer pid=380742)[0;0m   "input_data_format": null,
[0;36m(APIServer pid=380742)[0;0m   "max_pixels": null,
[0;36m(APIServer pid=380742)[0;0m   "merge_size": 2,
[0;36m(APIServer pid=380742)[0;0m   "min_pixels": null,
[0;36m(APIServer pid=380742)[0;0m   "pad_size": null,
[0;36m(APIServer pid=380742)[0;0m   "patch_size": 16,
[0;36m(APIServer pid=380742)[0;0m   "processor_class": "Qwen3VLProcessor",
[0;36m(APIServer pid=380742)[0;0m   "resample": 3,
[0;36m(APIServer pid=380742)[0;0m   "rescale_factor": 0.00392156862745098,
[0;36m(APIServer pid=380742)[0;0m   "return_tensors": null,
[0;36m(APIServer pid=380742)[0;0m   "size": {
[0;36m(APIServer pid=380742)[0;0m     "longest_edge": 16777216,
[0;36m(APIServer pid=380742)[0;0m     "shortest_edge": 65536
[0;36m(APIServer pid=380742)[0;0m   },
[0;36m(APIServer pid=380742)[0;0m   "temporal_patch_size": 2
[0;36m(APIServer pid=380742)[0;0m }
[0;36m(APIServer pid=380742)[0;0m 
[0;36m(APIServer pid=380742)[0;0m loading file vocab.json
[0;36m(APIServer pid=380742)[0;0m loading file merges.txt
[0;36m(APIServer pid=380742)[0;0m loading file tokenizer.json
[0;36m(APIServer pid=380742)[0;0m loading file added_tokens.json
[0;36m(APIServer pid=380742)[0;0m loading file special_tokens_map.json
[0;36m(APIServer pid=380742)[0;0m loading file tokenizer_config.json
[0;36m(APIServer pid=380742)[0;0m loading file chat_template.jinja
[0;36m(APIServer pid=380742)[0;0m Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[0;36m(APIServer pid=380742)[0;0m loading configuration file /root/.cache/huggingface/hub/models--Qwen--Qwen3-VL-32B-Instruct-FP8/snapshots/4bf2c2f39c37c0fede78bede4056e1f18cdf8109/video_preprocessor_config.json
[0;36m(APIServer pid=380742)[0;0m Video processor Qwen3VLVideoProcessor {
[0;36m(APIServer pid=380742)[0;0m   "crop_size": null,
[0;36m(APIServer pid=380742)[0;0m   "data_format": "channels_first",
[0;36m(APIServer pid=380742)[0;0m   "default_to_square": true,
[0;36m(APIServer pid=380742)[0;0m   "device": null,
[0;36m(APIServer pid=380742)[0;0m   "do_center_crop": null,
[0;36m(APIServer pid=380742)[0;0m   "do_convert_rgb": true,
[0;36m(APIServer pid=380742)[0;0m   "do_normalize": true,
[0;36m(APIServer pid=380742)[0;0m   "do_rescale": true,
[0;36m(APIServer pid=380742)[0;0m   "do_resize": true,
[0;36m(APIServer pid=380742)[0;0m   "do_sample_frames": true,
[0;36m(APIServer pid=380742)[0;0m   "fps": 2,
[0;36m(APIServer pid=380742)[0;0m   "image_mean": [
[0;36m(APIServer pid=380742)[0;0m     0.5,
[0;36m(APIServer pid=380742)[0;0m     0.5,
[0;36m(APIServer pid=380742)[0;0m     0.5
[0;36m(APIServer pid=380742)[0;0m   ],
[0;36m(APIServer pid=380742)[0;0m   "image_std": [
[0;36m(APIServer pid=380742)[0;0m     0.5,
[0;36m(APIServer pid=380742)[0;0m     0.5,
[0;36m(APIServer pid=380742)[0;0m     0.5
[0;36m(APIServer pid=380742)[0;0m   ],
[0;36m(APIServer pid=380742)[0;0m   "input_data_format": null,
[0;36m(APIServer pid=380742)[0;0m   "max_frames": 768,
[0;36m(APIServer pid=380742)[0;0m   "merge_size": 2,
[0;36m(APIServer pid=380742)[0;0m   "min_frames": 4,
[0;36m(APIServer pid=380742)[0;0m   "num_frames": null,
[0;36m(APIServer pid=380742)[0;0m   "pad_size": null,
[0;36m(APIServer pid=380742)[0;0m   "patch_size": 16,
[0;36m(APIServer pid=380742)[0;0m   "processor_class": "Qwen3VLProcessor",
[0;36m(APIServer pid=380742)[0;0m   "resample": 3,
[0;36m(APIServer pid=380742)[0;0m   "rescale_factor": 0.00392156862745098,
[0;36m(APIServer pid=380742)[0;0m   "return_metadata": false,
[0;36m(APIServer pid=380742)[0;0m   "size": {
[0;36m(APIServer pid=380742)[0;0m     "longest_edge": 25165824,
[0;36m(APIServer pid=380742)[0;0m     "shortest_edge": 4096
[0;36m(APIServer pid=380742)[0;0m   },
[0;36m(APIServer pid=380742)[0;0m   "temporal_patch_size": 2,
[0;36m(APIServer pid=380742)[0;0m   "video_metadata": null,
[0;36m(APIServer pid=380742)[0;0m   "video_processor_type": "Qwen3VLVideoProcessor"
[0;36m(APIServer pid=380742)[0;0m }
[0;36m(APIServer pid=380742)[0;0m 
[0;36m(APIServer pid=380742)[0;0m loading configuration file None
[0;36m(APIServer pid=380742)[0;0m Processor Qwen3VLProcessor:
[0;36m(APIServer pid=380742)[0;0m - image_processor: Qwen2VLImageProcessorFast {
[0;36m(APIServer pid=380742)[0;0m   "crop_size": null,
[0;36m(APIServer pid=380742)[0;0m   "data_format": "channels_first",
[0;36m(APIServer pid=380742)[0;0m   "default_to_square": true,
[0;36m(APIServer pid=380742)[0;0m   "device": null,
[0;36m(APIServer pid=380742)[0;0m   "disable_grouping": null,
[0;36m(APIServer pid=380742)[0;0m   "do_center_crop": null,
[0;36m(APIServer pid=380742)[0;0m   "do_convert_rgb": true,
[0;36m(APIServer pid=380742)[0;0m   "do_normalize": true,
[0;36m(APIServer pid=380742)[0;0m   "do_pad": null,
[0;36m(APIServer pid=380742)[0;0m   "do_rescale": true,
[0;36m(APIServer pid=380742)[0;0m   "do_resize": true,
[0;36m(APIServer pid=380742)[0;0m   "image_mean": [
[0;36m(APIServer pid=380742)[0;0m     0.5,
[0;36m(APIServer pid=380742)[0;0m     0.5,
[0;36m(APIServer pid=380742)[0;0m     0.5
[0;36m(APIServer pid=380742)[0;0m   ],
[0;36m(APIServer pid=380742)[0;0m   "image_processor_type": "Qwen2VLImageProcessorFast",
[0;36m(APIServer pid=380742)[0;0m   "image_std": [
[0;36m(APIServer pid=380742)[0;0m     0.5,
[0;36m(APIServer pid=380742)[0;0m     0.5,
[0;36m(APIServer pid=380742)[0;0m     0.5
[0;36m(APIServer pid=380742)[0;0m   ],
[0;36m(APIServer pid=380742)[0;0m   "input_data_format": null,
[0;36m(APIServer pid=380742)[0;0m   "max_pixels": null,
[0;36m(APIServer pid=380742)[0;0m   "merge_size": 2,
[0;36m(APIServer pid=380742)[0;0m   "min_pixels": null,
[0;36m(APIServer pid=380742)[0;0m   "pad_size": null,
[0;36m(APIServer pid=380742)[0;0m   "patch_size": 16,
[0;36m(APIServer pid=380742)[0;0m   "processor_class": "Qwen3VLProcessor",
[0;36m(APIServer pid=380742)[0;0m   "resample": 3,
[0;36m(APIServer pid=380742)[0;0m   "rescale_factor": 0.00392156862745098,
[0;36m(APIServer pid=380742)[0;0m   "return_tensors": null,
[0;36m(APIServer pid=380742)[0;0m   "size": {
[0;36m(APIServer pid=380742)[0;0m     "longest_edge": 16777216,
[0;36m(APIServer pid=380742)[0;0m     "shortest_edge": 65536
[0;36m(APIServer pid=380742)[0;0m   },
[0;36m(APIServer pid=380742)[0;0m   "temporal_patch_size": 2
[0;36m(APIServer pid=380742)[0;0m }
[0;36m(APIServer pid=380742)[0;0m 
[0;36m(APIServer pid=380742)[0;0m - tokenizer: Qwen2TokenizerFast(name_or_path='/root/.cache/huggingface/hub/models--Qwen--Qwen3-VL-32B-Instruct-FP8/snapshots/4bf2c2f39c37c0fede78bede4056e1f18cdf8109/', vocab_size=151643, model_max_length=262144, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
[0;36m(APIServer pid=380742)[0;0m 	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
[0;36m(APIServer pid=380742)[0;0m 	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
[0;36m(APIServer pid=380742)[0;0m 	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
[0;36m(APIServer pid=380742)[0;0m 	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
[0;36m(APIServer pid=380742)[0;0m 	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
[0;36m(APIServer pid=380742)[0;0m 	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
[0;36m(APIServer pid=380742)[0;0m 	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
[0;36m(APIServer pid=380742)[0;0m 	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
[0;36m(APIServer pid=380742)[0;0m 	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
[0;36m(APIServer pid=380742)[0;0m 	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
[0;36m(APIServer pid=380742)[0;0m 	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
[0;36m(APIServer pid=380742)[0;0m 	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
[0;36m(APIServer pid=380742)[0;0m 	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
[0;36m(APIServer pid=380742)[0;0m 	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
[0;36m(APIServer pid=380742)[0;0m 	151657: AddedToken("<tool_call>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
[0;36m(APIServer pid=380742)[0;0m 	151658: AddedToken("</tool_call>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
[0;36m(APIServer pid=380742)[0;0m 	151659: AddedToken("<|fim_prefix|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
[0;36m(APIServer pid=380742)[0;0m 	151660: AddedToken("<|fim_middle|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
[0;36m(APIServer pid=380742)[0;0m 	151661: AddedToken("<|fim_suffix|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
[0;36m(APIServer pid=380742)[0;0m 	151662: AddedToken("<|fim_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
[0;36m(APIServer pid=380742)[0;0m 	151663: AddedToken("<|repo_name|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
[0;36m(APIServer pid=380742)[0;0m 	151664: AddedToken("<|file_sep|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
[0;36m(APIServer pid=380742)[0;0m 	151665: AddedToken("<tool_response>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
[0;36m(APIServer pid=380742)[0;0m 	151666: AddedToken("</tool_response>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
[0;36m(APIServer pid=380742)[0;0m 	151667: AddedToken("<think>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
[0;36m(APIServer pid=380742)[0;0m 	151668: AddedToken("</think>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
[0;36m(APIServer pid=380742)[0;0m }
[0;36m(APIServer pid=380742)[0;0m )
[0;36m(APIServer pid=380742)[0;0m - video_processor: Qwen3VLVideoProcessor {
[0;36m(APIServer pid=380742)[0;0m   "crop_size": null,
[0;36m(APIServer pid=380742)[0;0m   "data_format": "channels_first",
[0;36m(APIServer pid=380742)[0;0m   "default_to_square": true,
[0;36m(APIServer pid=380742)[0;0m   "device": null,
[0;36m(APIServer pid=380742)[0;0m   "do_center_crop": null,
[0;36m(APIServer pid=380742)[0;0m   "do_convert_rgb": true,
[0;36m(APIServer pid=380742)[0;0m   "do_normalize": true,
[0;36m(APIServer pid=380742)[0;0m   "do_rescale": true,
[0;36m(APIServer pid=380742)[0;0m   "do_resize": true,
[0;36m(APIServer pid=380742)[0;0m   "do_sample_frames": true,
[0;36m(APIServer pid=380742)[0;0m   "fps": 2,
[0;36m(APIServer pid=380742)[0;0m   "image_mean": [
[0;36m(APIServer pid=380742)[0;0m     0.5,
[0;36m(APIServer pid=380742)[0;0m     0.5,
[0;36m(APIServer pid=380742)[0;0m     0.5
[0;36m(APIServer pid=380742)[0;0m   ],
[0;36m(APIServer pid=380742)[0;0m   "image_std": [
[0;36m(APIServer pid=380742)[0;0m     0.5,
[0;36m(APIServer pid=380742)[0;0m     0.5,
[0;36m(APIServer pid=380742)[0;0m     0.5
[0;36m(APIServer pid=380742)[0;0m   ],
[0;36m(APIServer pid=380742)[0;0m   "input_data_format": null,
[0;36m(APIServer pid=380742)[0;0m   "max_frames": 768,
[0;36m(APIServer pid=380742)[0;0m   "merge_size": 2,
[0;36m(APIServer pid=380742)[0;0m   "min_frames": 4,
[0;36m(APIServer pid=380742)[0;0m   "num_frames": null,
[0;36m(APIServer pid=380742)[0;0m   "pad_size": null,
[0;36m(APIServer pid=380742)[0;0m   "patch_size": 16,
[0;36m(APIServer pid=380742)[0;0m   "processor_class": "Qwen3VLProcessor",
[0;36m(APIServer pid=380742)[0;0m   "resample": 3,
[0;36m(APIServer pid=380742)[0;0m   "rescale_factor": 0.00392156862745098,
[0;36m(APIServer pid=380742)[0;0m   "return_metadata": false,
[0;36m(APIServer pid=380742)[0;0m   "size": {
[0;36m(APIServer pid=380742)[0;0m     "longest_edge": 25165824,
[0;36m(APIServer pid=380742)[0;0m     "shortest_edge": 4096
[0;36m(APIServer pid=380742)[0;0m   },
[0;36m(APIServer pid=380742)[0;0m   "temporal_patch_size": 2,
[0;36m(APIServer pid=380742)[0;0m   "video_metadata": null,
[0;36m(APIServer pid=380742)[0;0m   "video_processor_type": "Qwen3VLVideoProcessor"
[0;36m(APIServer pid=380742)[0;0m }
[0;36m(APIServer pid=380742)[0;0m 
[0;36m(APIServer pid=380742)[0;0m 
[0;36m(APIServer pid=380742)[0;0m {
[0;36m(APIServer pid=380742)[0;0m   "processor_class": "Qwen3VLProcessor"
[0;36m(APIServer pid=380742)[0;0m }
[0;36m(APIServer pid=380742)[0;0m 
[0;36m(APIServer pid=380742)[0;0m loading configuration file /root/.cache/huggingface/hub/models--Qwen--Qwen3-VL-32B-Instruct-FP8/snapshots/4bf2c2f39c37c0fede78bede4056e1f18cdf8109/preprocessor_config.json
[0;36m(APIServer pid=380742)[0;0m Image processor Qwen2VLImageProcessorFast {
[0;36m(APIServer pid=380742)[0;0m   "crop_size": null,
[0;36m(APIServer pid=380742)[0;0m   "data_format": "channels_first",
[0;36m(APIServer pid=380742)[0;0m   "default_to_square": true,
[0;36m(APIServer pid=380742)[0;0m   "device": null,
[0;36m(APIServer pid=380742)[0;0m   "disable_grouping": null,
[0;36m(APIServer pid=380742)[0;0m   "do_center_crop": null,
[0;36m(APIServer pid=380742)[0;0m   "do_convert_rgb": true,
[0;36m(APIServer pid=380742)[0;0m   "do_normalize": true,
[0;36m(APIServer pid=380742)[0;0m   "do_pad": null,
[0;36m(APIServer pid=380742)[0;0m   "do_rescale": true,
[0;36m(APIServer pid=380742)[0;0m   "do_resize": true,
[0;36m(APIServer pid=380742)[0;0m   "image_mean": [
[0;36m(APIServer pid=380742)[0;0m     0.5,
[0;36m(APIServer pid=380742)[0;0m     0.5,
[0;36m(APIServer pid=380742)[0;0m     0.5
[0;36m(APIServer pid=380742)[0;0m   ],
[0;36m(APIServer pid=380742)[0;0m   "image_processor_type": "Qwen2VLImageProcessorFast",
[0;36m(APIServer pid=380742)[0;0m   "image_std": [
[0;36m(APIServer pid=380742)[0;0m     0.5,
[0;36m(APIServer pid=380742)[0;0m     0.5,
[0;36m(APIServer pid=380742)[0;0m     0.5
[0;36m(APIServer pid=380742)[0;0m   ],
[0;36m(APIServer pid=380742)[0;0m   "input_data_format": null,
[0;36m(APIServer pid=380742)[0;0m   "max_pixels": null,
[0;36m(APIServer pid=380742)[0;0m   "merge_size": 2,
[0;36m(APIServer pid=380742)[0;0m   "min_pixels": null,
[0;36m(APIServer pid=380742)[0;0m   "pad_size": null,
[0;36m(APIServer pid=380742)[0;0m   "patch_size": 16,
[0;36m(APIServer pid=380742)[0;0m   "processor_class": "Qwen3VLProcessor",
[0;36m(APIServer pid=380742)[0;0m   "resample": 3,
[0;36m(APIServer pid=380742)[0;0m   "rescale_factor": 0.00392156862745098,
[0;36m(APIServer pid=380742)[0;0m   "return_tensors": null,
[0;36m(APIServer pid=380742)[0;0m   "size": {
[0;36m(APIServer pid=380742)[0;0m     "longest_edge": 1048576,
[0;36m(APIServer pid=380742)[0;0m     "shortest_edge": 65536
[0;36m(APIServer pid=380742)[0;0m   },
[0;36m(APIServer pid=380742)[0;0m   "temporal_patch_size": 2
[0;36m(APIServer pid=380742)[0;0m }
[0;36m(APIServer pid=380742)[0;0m 
[0;36m(APIServer pid=380742)[0;0m loading file vocab.json
[0;36m(APIServer pid=380742)[0;0m loading file merges.txt
[0;36m(APIServer pid=380742)[0;0m loading file tokenizer.json
[0;36m(APIServer pid=380742)[0;0m loading file added_tokens.json
[0;36m(APIServer pid=380742)[0;0m loading file special_tokens_map.json
[0;36m(APIServer pid=380742)[0;0m loading file tokenizer_config.json
[0;36m(APIServer pid=380742)[0;0m loading file chat_template.jinja
[0;36m(APIServer pid=380742)[0;0m Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[0;36m(APIServer pid=380742)[0;0m loading configuration file /root/.cache/huggingface/hub/models--Qwen--Qwen3-VL-32B-Instruct-FP8/snapshots/4bf2c2f39c37c0fede78bede4056e1f18cdf8109/video_preprocessor_config.json
[0;36m(APIServer pid=380742)[0;0m Video processor Qwen3VLVideoProcessor {
[0;36m(APIServer pid=380742)[0;0m   "crop_size": null,
[0;36m(APIServer pid=380742)[0;0m   "data_format": "channels_first",
[0;36m(APIServer pid=380742)[0;0m   "default_to_square": true,
[0;36m(APIServer pid=380742)[0;0m   "device": null,
[0;36m(APIServer pid=380742)[0;0m   "do_center_crop": null,
[0;36m(APIServer pid=380742)[0;0m   "do_convert_rgb": true,
[0;36m(APIServer pid=380742)[0;0m   "do_normalize": true,
[0;36m(APIServer pid=380742)[0;0m   "do_rescale": true,
[0;36m(APIServer pid=380742)[0;0m   "do_resize": true,
[0;36m(APIServer pid=380742)[0;0m   "do_sample_frames": true,
[0;36m(APIServer pid=380742)[0;0m   "fps": 2,
[0;36m(APIServer pid=380742)[0;0m   "image_mean": [
[0;36m(APIServer pid=380742)[0;0m     0.5,
[0;36m(APIServer pid=380742)[0;0m     0.5,
[0;36m(APIServer pid=380742)[0;0m     0.5
[0;36m(APIServer pid=380742)[0;0m   ],
[0;36m(APIServer pid=380742)[0;0m   "image_std": [
[0;36m(APIServer pid=380742)[0;0m     0.5,
[0;36m(APIServer pid=380742)[0;0m     0.5,
[0;36m(APIServer pid=380742)[0;0m     0.5
[0;36m(APIServer pid=380742)[0;0m   ],
[0;36m(APIServer pid=380742)[0;0m   "input_data_format": null,
[0;36m(APIServer pid=380742)[0;0m   "max_frames": 768,
[0;36m(APIServer pid=380742)[0;0m   "merge_size": 2,
[0;36m(APIServer pid=380742)[0;0m   "min_frames": 4,
[0;36m(APIServer pid=380742)[0;0m   "num_frames": null,
[0;36m(APIServer pid=380742)[0;0m   "pad_size": null,
[0;36m(APIServer pid=380742)[0;0m   "patch_size": 16,
[0;36m(APIServer pid=380742)[0;0m   "processor_class": "Qwen3VLProcessor",
[0;36m(APIServer pid=380742)[0;0m   "resample": 3,
[0;36m(APIServer pid=380742)[0;0m   "rescale_factor": 0.00392156862745098,
[0;36m(APIServer pid=380742)[0;0m   "return_metadata": false,
[0;36m(APIServer pid=380742)[0;0m   "size": {
[0;36m(APIServer pid=380742)[0;0m     "longest_edge": 1048576,
[0;36m(APIServer pid=380742)[0;0m     "shortest_edge": 65536
[0;36m(APIServer pid=380742)[0;0m   },
[0;36m(APIServer pid=380742)[0;0m   "temporal_patch_size": 2,
[0;36m(APIServer pid=380742)[0;0m   "video_metadata": null,
[0;36m(APIServer pid=380742)[0;0m   "video_processor_type": "Qwen3VLVideoProcessor"
[0;36m(APIServer pid=380742)[0;0m }
[0;36m(APIServer pid=380742)[0;0m 
[0;36m(APIServer pid=380742)[0;0m loading configuration file None
[0;36m(APIServer pid=380742)[0;0m Processor Qwen3VLProcessor:
[0;36m(APIServer pid=380742)[0;0m - image_processor: Qwen2VLImageProcessorFast {
[0;36m(APIServer pid=380742)[0;0m   "crop_size": null,
[0;36m(APIServer pid=380742)[0;0m   "data_format": "channels_first",
[0;36m(APIServer pid=380742)[0;0m   "default_to_square": true,
[0;36m(APIServer pid=380742)[0;0m   "device": null,
[0;36m(APIServer pid=380742)[0;0m   "disable_grouping": null,
[0;36m(APIServer pid=380742)[0;0m   "do_center_crop": null,
[0;36m(APIServer pid=380742)[0;0m   "do_convert_rgb": true,
[0;36m(APIServer pid=380742)[0;0m   "do_normalize": true,
[0;36m(APIServer pid=380742)[0;0m   "do_pad": null,
[0;36m(APIServer pid=380742)[0;0m   "do_rescale": true,
[0;36m(APIServer pid=380742)[0;0m   "do_resize": true,
[0;36m(APIServer pid=380742)[0;0m   "image_mean": [
[0;36m(APIServer pid=380742)[0;0m     0.5,
[0;36m(APIServer pid=380742)[0;0m     0.5,
[0;36m(APIServer pid=380742)[0;0m     0.5
[0;36m(APIServer pid=380742)[0;0m   ],
[0;36m(APIServer pid=380742)[0;0m   "image_processor_type": "Qwen2VLImageProcessorFast",
[0;36m(APIServer pid=380742)[0;0m   "image_std": [
[0;36m(APIServer pid=380742)[0;0m     0.5,
[0;36m(APIServer pid=380742)[0;0m     0.5,
[0;36m(APIServer pid=380742)[0;0m     0.5
[0;36m(APIServer pid=380742)[0;0m   ],
[0;36m(APIServer pid=380742)[0;0m   "input_data_format": null,
[0;36m(APIServer pid=380742)[0;0m   "max_pixels": null,
[0;36m(APIServer pid=380742)[0;0m   "merge_size": 2,
[0;36m(APIServer pid=380742)[0;0m   "min_pixels": null,
[0;36m(APIServer pid=380742)[0;0m   "pad_size": null,
[0;36m(APIServer pid=380742)[0;0m   "patch_size": 16,
[0;36m(APIServer pid=380742)[0;0m   "processor_class": "Qwen3VLProcessor",
[0;36m(APIServer pid=380742)[0;0m   "resample": 3,
[0;36m(APIServer pid=380742)[0;0m   "rescale_factor": 0.00392156862745098,
[0;36m(APIServer pid=380742)[0;0m   "return_tensors": null,
[0;36m(APIServer pid=380742)[0;0m   "size": {
[0;36m(APIServer pid=380742)[0;0m     "longest_edge": 1048576,
[0;36m(APIServer pid=380742)[0;0m     "shortest_edge": 65536
[0;36m(APIServer pid=380742)[0;0m   },
[0;36m(APIServer pid=380742)[0;0m   "temporal_patch_size": 2
[0;36m(APIServer pid=380742)[0;0m }
[0;36m(APIServer pid=380742)[0;0m 
[0;36m(APIServer pid=380742)[0;0m - tokenizer: CachedQwen2TokenizerFast(name_or_path='/root/.cache/huggingface/hub/models--Qwen--Qwen3-VL-32B-Instruct-FP8/snapshots/4bf2c2f39c37c0fede78bede4056e1f18cdf8109/', vocab_size=151643, model_max_length=262144, is_fast=True, padding_side='right', truncation_side='left', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
[0;36m(APIServer pid=380742)[0;0m 	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
[0;36m(APIServer pid=380742)[0;0m 	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
[0;36m(APIServer pid=380742)[0;0m 	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
[0;36m(APIServer pid=380742)[0;0m 	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
[0;36m(APIServer pid=380742)[0;0m 	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
[0;36m(APIServer pid=380742)[0;0m 	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
[0;36m(APIServer pid=380742)[0;0m 	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
[0;36m(APIServer pid=380742)[0;0m 	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
[0;36m(APIServer pid=380742)[0;0m 	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
[0;36m(APIServer pid=380742)[0;0m 	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
[0;36m(APIServer pid=380742)[0;0m 	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
[0;36m(APIServer pid=380742)[0;0m 	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
[0;36m(APIServer pid=380742)[0;0m 	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
[0;36m(APIServer pid=380742)[0;0m 	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
[0;36m(APIServer pid=380742)[0;0m 	151657: AddedToken("<tool_call>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
[0;36m(APIServer pid=380742)[0;0m 	151658: AddedToken("</tool_call>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
[0;36m(APIServer pid=380742)[0;0m 	151659: AddedToken("<|fim_prefix|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
[0;36m(APIServer pid=380742)[0;0m 	151660: AddedToken("<|fim_middle|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
[0;36m(APIServer pid=380742)[0;0m 	151661: AddedToken("<|fim_suffix|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
[0;36m(APIServer pid=380742)[0;0m 	151662: AddedToken("<|fim_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
[0;36m(APIServer pid=380742)[0;0m 	151663: AddedToken("<|repo_name|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
[0;36m(APIServer pid=380742)[0;0m 	151664: AddedToken("<|file_sep|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
[0;36m(APIServer pid=380742)[0;0m 	151665: AddedToken("<tool_response>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
[0;36m(APIServer pid=380742)[0;0m 	151666: AddedToken("</tool_response>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
[0;36m(APIServer pid=380742)[0;0m 	151667: AddedToken("<think>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
[0;36m(APIServer pid=380742)[0;0m 	151668: AddedToken("</think>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
[0;36m(APIServer pid=380742)[0;0m }
[0;36m(APIServer pid=380742)[0;0m )
[0;36m(APIServer pid=380742)[0;0m - video_processor: Qwen3VLVideoProcessor {
[0;36m(APIServer pid=380742)[0;0m   "crop_size": null,
[0;36m(APIServer pid=380742)[0;0m   "data_format": "channels_first",
[0;36m(APIServer pid=380742)[0;0m   "default_to_square": true,
[0;36m(APIServer pid=380742)[0;0m   "device": null,
[0;36m(APIServer pid=380742)[0;0m   "do_center_crop": null,
[0;36m(APIServer pid=380742)[0;0m   "do_convert_rgb": true,
[0;36m(APIServer pid=380742)[0;0m   "do_normalize": true,
[0;36m(APIServer pid=380742)[0;0m   "do_rescale": true,
[0;36m(APIServer pid=380742)[0;0m   "do_resize": true,
[0;36m(APIServer pid=380742)[0;0m   "do_sample_frames": true,
[0;36m(APIServer pid=380742)[0;0m   "fps": 2,
[0;36m(APIServer pid=380742)[0;0m   "image_mean": [
[0;36m(APIServer pid=380742)[0;0m     0.5,
[0;36m(APIServer pid=380742)[0;0m     0.5,
[0;36m(APIServer pid=380742)[0;0m     0.5
[0;36m(APIServer pid=380742)[0;0m   ],
[0;36m(APIServer pid=380742)[0;0m   "image_std": [
[0;36m(APIServer pid=380742)[0;0m     0.5,
[0;36m(APIServer pid=380742)[0;0m     0.5,
[0;36m(APIServer pid=380742)[0;0m     0.5
[0;36m(APIServer pid=380742)[0;0m   ],
[0;36m(APIServer pid=380742)[0;0m   "input_data_format": null,
[0;36m(APIServer pid=380742)[0;0m   "max_frames": 768,
[0;36m(APIServer pid=380742)[0;0m   "merge_size": 2,
[0;36m(APIServer pid=380742)[0;0m   "min_frames": 4,
[0;36m(APIServer pid=380742)[0;0m   "num_frames": null,
[0;36m(APIServer pid=380742)[0;0m   "pad_size": null,
[0;36m(APIServer pid=380742)[0;0m   "patch_size": 16,
[0;36m(APIServer pid=380742)[0;0m   "processor_class": "Qwen3VLProcessor",
[0;36m(APIServer pid=380742)[0;0m   "resample": 3,
[0;36m(APIServer pid=380742)[0;0m   "rescale_factor": 0.00392156862745098,
[0;36m(APIServer pid=380742)[0;0m   "return_metadata": false,
[0;36m(APIServer pid=380742)[0;0m   "size": {
[0;36m(APIServer pid=380742)[0;0m     "longest_edge": 1048576,
[0;36m(APIServer pid=380742)[0;0m     "shortest_edge": 65536
[0;36m(APIServer pid=380742)[0;0m   },
[0;36m(APIServer pid=380742)[0;0m   "temporal_patch_size": 2,
[0;36m(APIServer pid=380742)[0;0m   "video_metadata": null,
[0;36m(APIServer pid=380742)[0;0m   "video_processor_type": "Qwen3VLVideoProcessor"
[0;36m(APIServer pid=380742)[0;0m }
[0;36m(APIServer pid=380742)[0;0m 
[0;36m(APIServer pid=380742)[0;0m 
[0;36m(APIServer pid=380742)[0;0m {
[0;36m(APIServer pid=380742)[0;0m   "processor_class": "Qwen3VLProcessor"
[0;36m(APIServer pid=380742)[0;0m }
[0;36m(APIServer pid=380742)[0;0m 
[0;36m(APIServer pid=380742)[0;0m DEBUG 01-27 22:07:52 [v1/metrics/loggers.py:257] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=380742)[0;0m INFO:     127.0.0.1:40100 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:07:52 [v1/engine/core.py:978] EngineCore loop active.
[0;36m(EngineCore_DP0 pid=381139)[0;0m WARNING 01-27 22:07:52 [common.py:245] Prompt bucket for (1, 31978, 0) was not prepared. Adding new bucket: (1, 32768, 0)
[0;36m(APIServer pid=380742)[0;0m INFO:     127.0.0.1:40104 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[0;36m(APIServer pid=380742)[0;0m DEBUG 01-27 22:08:02 [v1/metrics/loggers.py:257] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=380742)[0;0m DEBUG 01-27 22:08:12 [v1/metrics/loggers.py:257] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=380742)[0;0m DEBUG 01-27 22:08:22 [v1/metrics/loggers.py:257] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=380742)[0;0m DEBUG 01-27 22:08:32 [v1/metrics/loggers.py:257] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=380742)[0;0m DEBUG 01-27 22:08:42 [v1/metrics/loggers.py:257] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=380742)[0;0m DEBUG 01-27 22:08:52 [v1/metrics/loggers.py:257] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
[0;36m(EngineCore_DP0 pid=381139)[0;0m ************************
[0;36m(EngineCore_DP0 pid=381139)[0;0m pixel_values.shape[0]
[0;36m(EngineCore_DP0 pid=381139)[0;0m 102000
[0;36m(EngineCore_DP0 pid=381139)[0;0m grid_thw.shape[0]
[0;36m(EngineCore_DP0 pid=381139)[0;0m 85
[0;36m(EngineCore_DP0 pid=381139)[0;0m ******In here***************
[0;36m(EngineCore_DP0 pid=381139)[0;0m WARNING 01-27 22:08:54 [common.py:264] Decode bucket for (1, 1, 250) was not prepared. Adding new bucket: (1, 1, 448)
[0;36m(APIServer pid=380742)[0;0m DEBUG 01-27 22:09:02 [v1/metrics/loggers.py:257] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=380742)[0;0m DEBUG 01-27 22:09:12 [v1/metrics/loggers.py:257] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=380742)[0;0m DEBUG 01-27 22:09:22 [v1/metrics/loggers.py:257] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=380742)[0;0m DEBUG 01-27 22:09:32 [v1/metrics/loggers.py:257] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
[0;36m(EngineCore_DP0 pid=381139)[0;0m ************************
[0;36m(EngineCore_DP0 pid=381139)[0;0m pixel_values.shape[0]
[0;36m(EngineCore_DP0 pid=381139)[0;0m 102000
[0;36m(EngineCore_DP0 pid=381139)[0;0m grid_thw.shape[0]
[0;36m(EngineCore_DP0 pid=381139)[0;0m 85
[0;36m(EngineCore_DP0 pid=381139)[0;0m ******In here***************
[0;36m(EngineCore_DP0 pid=381139)[0;0m WARNING 01-27 22:09:35 [hpu_model_runner.py:2572] Configuration: ('decode', 1, 1, 448) was not warmed-up!
[0;36m(EngineCore_DP0 pid=381139)[0;0m WARNING 01-27 22:09:39 [common.py:264] Decode bucket for (2, 1, 500) was not prepared. Adding new bucket: (4, 1, 512)
[0;36m(EngineCore_DP0 pid=381139)[0;0m WARNING 01-27 22:09:39 [hpu_model_runner.py:2572] Configuration: ('decode', 4, 1, 512) was not warmed-up!
[0;36m(APIServer pid=380742)[0;0m INFO 01-27 22:09:42 [v1/metrics/loggers.py:257] Engine 000: Avg prompt throughput: 3197.5 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 2 reqs, Waiting: 0 reqs, GPU KV cache usage: 42.1%, Prefix cache hit rate: 0.0%, MM cache hit rate: 0.0%
[0;36m(APIServer pid=380742)[0;0m INFO 01-27 22:09:52 [v1/metrics/loggers.py:257] Engine 000: Avg prompt throughput: 3197.2 tokens/s, Avg generation throughput: 28.8 tokens/s, Running: 2 reqs, Waiting: 0 reqs, GPU KV cache usage: 42.3%, Prefix cache hit rate: 0.0%, MM cache hit rate: 0.0%
[0;36m(EngineCore_DP0 pid=381139)[0;0m DEBUG 01-27 22:10:01 [v1/engine/core.py:972] EngineCore waiting for work.
[0;36m(APIServer pid=380742)[0;0m INFO:     127.0.0.1:40100 - "GET /metrics HTTP/1.1" 200 OK
[0;36m(APIServer pid=380742)[0;0m INFO 01-27 22:10:02 [v1/metrics/loggers.py:257] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 47.1 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%, MM cache hit rate: 0.0%
[0;36m(APIServer pid=380742)[0;0m INFO 01-27 22:10:12 [v1/metrics/loggers.py:257] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%, MM cache hit rate: 0.0%
[0;36m(APIServer pid=380742)[0;0m DEBUG 01-27 22:10:22 [v1/metrics/loggers.py:257] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%, MM cache hit rate: 0.0%
[0;36m(APIServer pid=380742)[0;0m DEBUG 01-27 22:10:32 [v1/metrics/loggers.py:257] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%, MM cache hit rate: 0.0%
[0;36m(APIServer pid=380742)[0;0m DEBUG 01-27 22:10:42 [v1/metrics/loggers.py:257] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%, MM cache hit rate: 0.0%
[0;36m(APIServer pid=380742)[0;0m DEBUG 01-27 22:10:52 [v1/metrics/loggers.py:257] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%, MM cache hit rate: 0.0%
[0;36m(APIServer pid=380742)[0;0m DEBUG 01-27 22:11:02 [v1/metrics/loggers.py:257] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%, MM cache hit rate: 0.0%
[0;36m(APIServer pid=380742)[0;0m DEBUG 01-27 22:11:12 [v1/metrics/loggers.py:257] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%, MM cache hit rate: 0.0%
[0;36m(APIServer pid=380742)[0;0m DEBUG 01-27 22:11:22 [v1/metrics/loggers.py:257] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%, MM cache hit rate: 0.0%
[0;36m(APIServer pid=380742)[0;0m DEBUG 01-27 22:11:32 [v1/metrics/loggers.py:257] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%, MM cache hit rate: 0.0%
